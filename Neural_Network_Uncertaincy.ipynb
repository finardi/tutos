{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Network Uncertaincy.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/tutos/blob/master/Neural_Network_Uncertaincy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GaGq24sXUah"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebooks deeply delves into exploration of neural network uncertaincy. It shows how networks tend to be overconfident and how we can resolve these issues by well known methods like Temperature Scaling. For further study I recommend looking into [this](https://arxiv.org/pdf/1706.04599.pdf) paper intuitively explaining the backgrounds.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01YiFyLhKsAk"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD5EsjkaLzR3"
      },
      "source": [
        "# Use the GPU provided by Google Colab\n",
        "device = 'cuda:0'\n",
        "\n",
        "# Allow reproducability\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr-Zkv7dKtlx"
      },
      "source": [
        "# Normalize the images by the imagenet mean/std since the nets are pretrained\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [45000, 5000])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Vx8rTGYyPC"
      },
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "num_classes = 10\n",
        "net = models.resnet101(pretrained=True)\n",
        "net.fc = nn.Linear(2048, num_classes)\n",
        "net = net.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kt7Z-PrKz2g"
      },
      "source": [
        "# Training loop\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "\n",
        "NUM_EPOCHS = 2\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    net.train()\n",
        "    print(f'Training iteration {epoch}')\n",
        "    for i, data in enumerate(tqdm(train_loader, 0)):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "    corrects = []\n",
        "    net.eval()\n",
        "    classified_right = 0\n",
        "    print('Evaluating on validation set')\n",
        "    for i, data in enumerate(tqdm(val_loader, 0)):\n",
        "        with torch.no_grad():\n",
        "          inputs, labels = data[0].to(device), data[1].to(device)\n",
        "          outputs = net(inputs)\n",
        "          _, pred_classes = torch.max(outputs, 1)\n",
        "\n",
        "          loss = criterion(outputs, labels)\n",
        "          classified_right += (pred_classes == labels).sum().item()\n",
        "          \n",
        "    acc = classified_right / len(val_set)\n",
        "\n",
        "    print(f'Epoch {epoch}  Acc: {acc}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPjnu0HZyhd5"
      },
      "source": [
        "################### Testing ######################\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Use kwags for calibration method specific parameters\n",
        "def test(calibration_method=None, **kwargs):\n",
        "  preds = []\n",
        "  labels_oneh = []\n",
        "  correct = 0\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "      for data in tqdm(test_loader):\n",
        "          images, labels = data[0].to('cuda:0'), data[1].to('cuda:0')\n",
        "\n",
        "          pred = net(images)\n",
        "          \n",
        "          if calibration_method:\n",
        "            pred = calibration_method(pred, kwargs)\n",
        "\n",
        "          # Get softmax values for net input and resulting class predictions\n",
        "          sm = nn.Softmax(dim=1)\n",
        "          pred = sm(pred)\n",
        "\n",
        "          _, predicted_cl = torch.max(pred.data, 1)\n",
        "          pred = pred.cpu().detach().numpy()\n",
        "\n",
        "          # Convert labels to one hot encoding\n",
        "          label_oneh = torch.nn.functional.one_hot(labels, num_classes=num_classes)\n",
        "          label_oneh = label_oneh.cpu().detach().numpy()\n",
        "\n",
        "          preds.extend(pred)\n",
        "          labels_oneh.extend(label_oneh)\n",
        "\n",
        "          # Count correctly classified samples for accuracy\n",
        "          correct += sum(predicted_cl == labels).item()\n",
        "\n",
        "  preds = np.array(preds).flatten()\n",
        "  labels_oneh = np.array(labels_oneh).flatten()\n",
        "\n",
        "  correct_perc = correct / len(test_set)\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct_perc))\n",
        "  print(correct_perc)\n",
        "  \n",
        "  return preds, labels_oneh\n",
        "\n",
        "preds, labels_oneh = test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1SAqFR7wPvs"
      },
      "source": [
        "def calc_bins(preds):\n",
        "  # Assign each prediction to a bin\n",
        "  num_bins = 10\n",
        "  bins = np.linspace(0.1, 1, num_bins)\n",
        "  binned = np.digitize(preds, bins)\n",
        "\n",
        "  # Save the accuracy, confidence and size of each bin\n",
        "  bin_accs = np.zeros(num_bins)\n",
        "  bin_confs = np.zeros(num_bins)\n",
        "  bin_sizes = np.zeros(num_bins)\n",
        "\n",
        "  for bin in range(num_bins):\n",
        "    bin_sizes[bin] = len(preds[binned == bin])\n",
        "    if bin_sizes[bin] > 0:\n",
        "      bin_accs[bin] = (labels_oneh[binned==bin]).sum() / bin_sizes[bin]\n",
        "      bin_confs[bin] = (preds[binned==bin]).sum() / bin_sizes[bin]\n",
        "\n",
        "  return bins, binned, bin_accs, bin_confs, bin_sizes\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsD0hviuaQwY"
      },
      "source": [
        "# Visualizations and metrics\n",
        "\n",
        "The Reliability Diagram as figured below intuitively show the relation between expected sample accuracy per bin and confidence.\n",
        "\n",
        "$acc(B_m) = \\frac{1}{|B_m|} \\sum_{i \\in B_m} \\mathbf{1}(\\hat{y}_i = y_i)$\n",
        "\n",
        "$conf(B_m) = \\frac{1}{|B_m|} \\sum_{i \\in B_m} \\hat{p}_i$\n",
        "\n",
        "For the figure I chose $M=10$, describing the number of seperate bins where the predictions are put in their respective bin based on their magnitude ($Bin 1 = [0.0, 0.1), Bin 2 = [0.1, 0.2), ...)$).\n",
        "\n",
        "For a perfectly calibrated model is defined as $P(\\hat{Y} = Y | \\hat{P} = p) = p, \\forall p \\in [0, 1]$. For Example: Given 100 predictions, each with confidence of 0.8, we expect 80 to be correctly classified. Bars under the identity line show underconfident behavior while bars above it signal overconfidence.\n",
        "\n",
        "\n",
        "The Expected Calibration Error (ECE) is taking the weighted average of the bins' accuracy/cofidence differences.\n",
        "\n",
        "$ECE = \\sum_{m=1}^{M} \\frac{|B_m|}{n} |acc(B_m) + conf(B_m)|$\n",
        "\n",
        "The Maximum Calibration Error (MCE) focuses more on high risk applications where the maximum accuracy/confidence difference is more important than just the average.\n",
        "\n",
        "$MCE = \\max_m |acc(B_m) + conf(B_m)|$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XldU3fNbOuSu"
      },
      "source": [
        "def get_metrics(preds):\n",
        "  ECE = 0\n",
        "  MCE = 0\n",
        "  bins, _, bin_accs, bin_confs, bin_sizes = calc_bins(preds)\n",
        "\n",
        "  for i in range(len(bins)):\n",
        "    abs_conf_dif = abs(bin_accs[i] - bin_confs[i])\n",
        "    ECE += (bin_sizes[i] / sum(bin_sizes)) * abs_conf_dif\n",
        "    MCE = max(MCE, abs_conf_dif)\n",
        "\n",
        "  return ECE, MCE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx_FB6_1oT3r"
      },
      "source": [
        "import matplotlib.patches as mpatches\n",
        "\n",
        "def draw_reliability_graph(preds):\n",
        "  ECE, MCE = get_metrics(preds)\n",
        "  bins, _, bin_accs, _, _ = calc_bins(preds)\n",
        "\n",
        "  fig = plt.figure(figsize=(8, 8))\n",
        "  ax = fig.gca()\n",
        "\n",
        "  # x/y limits\n",
        "  ax.set_xlim(0, 1.05)\n",
        "  ax.set_ylim(0, 1)\n",
        "\n",
        "  # x/y labels\n",
        "  plt.xlabel('Confidence')\n",
        "  plt.ylabel('Accuracy')\n",
        "\n",
        "  # Create grid\n",
        "  ax.set_axisbelow(True) \n",
        "  ax.grid(color='gray', linestyle='dashed')\n",
        "\n",
        "  # Error bars\n",
        "  plt.bar(bins, bins,  width=0.1, alpha=0.3, edgecolor='black', color='r', hatch='\\\\')\n",
        "\n",
        "  # Draw bars and identity line\n",
        "  plt.bar(bins, bin_accs, width=0.1, alpha=1, edgecolor='black', color='b')\n",
        "  plt.plot([0,1],[0,1], '--', color='gray', linewidth=2)\n",
        "\n",
        "  # Equally spaced axes\n",
        "  plt.gca().set_aspect('equal', adjustable='box')\n",
        "\n",
        "  # ECE and MCE legend\n",
        "  ECE_patch = mpatches.Patch(color='green', label='ECE = {:.2f}%'.format(ECE*100))\n",
        "  MCE_patch = mpatches.Patch(color='red', label='MCE = {:.2f}%'.format(MCE*100))\n",
        "  plt.legend(handles=[ECE_patch, MCE_patch])\n",
        "\n",
        "  #plt.show()\n",
        "  \n",
        "  plt.savefig('calibrated_network.png', bbox_inches='tight')\n",
        "\n",
        "#draw_reliability_graph(preds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVj_GtOAJnA6"
      },
      "source": [
        "def T_scaling(logits, args):\n",
        "  temperature = args.get('temperature', None)\n",
        "  return torch.div(logits, temperature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RpTADOY3bAk"
      },
      "source": [
        "# Temperature Scaling\n",
        "\n",
        "Temperature Scaling is a parametric calibration approach on the validation set using the Negative-Log-Likelihood (NLL) los. It learns a single parameter $T$ for all classes to update the confidences to $\\hat{q}_i = max_k  \\sigma_{SM}(z_i/T)^{(k)}$\n",
        "\n",
        "\n",
        "\n",
        "More sample code can be found in [this](https://github.com/gpleiss/temperature_scaling) awesome GitHub repository by \"gpleis\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_hINSZC3faF"
      },
      "source": [
        "temperature = nn.Parameter(torch.ones(1).cuda())\n",
        "args = {'temperature': temperature}\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Removing strong_wolfe line search results in jump after 50 epochs\n",
        "optimizer = optim.LBFGS([temperature], lr=0.001, max_iter=10000, line_search_fn='strong_wolfe')\n",
        "\n",
        "logits_list = []\n",
        "labels_list = []\n",
        "temps = []\n",
        "losses = []\n",
        "\n",
        "for i, data in enumerate(tqdm(val_loader, 0)):\n",
        "    images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "      logits_list.append(net(images))\n",
        "      labels_list.append(labels)\n",
        "\n",
        "# Create tensors\n",
        "logits_list = torch.cat(logits_list).to(device)\n",
        "labels_list = torch.cat(labels_list).to(device)\n",
        "\n",
        "def _eval():\n",
        "  loss = criterion(T_scaling(logits_list, args), labels_list)\n",
        "  loss.backward()\n",
        "  temps.append(temperature.item())\n",
        "  losses.append(loss)\n",
        "  return loss\n",
        "\n",
        "\n",
        "optimizer.step(_eval)\n",
        "\n",
        "print('Final T_scaling factor: {:.2f}'.format(temperature.item()))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(list(range(len(temps))), temps)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(list(range(len(losses))), losses)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52ZMvNRc8az4"
      },
      "source": [
        "preds_original, _ = test()\n",
        "preds_calibrated, _ = test(T_scaling, temperature=temperature)\n",
        "\n",
        "draw_reliability_graph(preds_original)\n",
        "draw_reliability_graph(preds_calibrated)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}