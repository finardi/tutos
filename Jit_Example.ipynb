{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPm8buNxg7QZOioy82MbG2a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/tutos/blob/master/Jit_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ref: https://spell.ml/blog/pytorch-jit-YBmYuBEAACgAiv71"
      ],
      "metadata": {
        "id": "-5_kk-1S79bX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lOSoSfpCvf84"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# Poderia usar torch.nn.Conv2d, mas é fins didáticos\n",
        "# ====================================================\n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(\n",
        "        self, n_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.kernel_size_number = kernel_size * kernel_size\n",
        "        self.out_channels = out_channels\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.stride = stride\n",
        "        self.n_channels = n_channels\n",
        "        self.weights = nn.Parameter(\n",
        "            torch.Tensor(self.out_channels, self.n_channels, self.kernel_size**2)\n",
        "        )\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (\n",
        "            f\"Conv2d(n_channels={self.n_channels}, out_channels={self.out_channels}, \"\n",
        "            f\"kernel_size={self.kernel_size})\"\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        width = self.calculate_new_width(x)\n",
        "        height = self.calculate_new_height(x)\n",
        "        windows = self.calculate_windows(x)\n",
        "        \n",
        "        result = torch.zeros(\n",
        "            [x.shape[0] * self.out_channels, width, height],\n",
        "            dtype=torch.float32, device=x.device\n",
        "        )\n",
        "\n",
        "        for channel in range(x.shape[1]):\n",
        "            for i_conv_n in range(self.out_channels):\n",
        "                xx = torch.matmul(windows[channel], self.weights[i_conv_n][channel]) \n",
        "                xx = xx.view((-1, width, height))\n",
        "                \n",
        "                xx_stride = slice(i_conv_n * xx.shape[0], (i_conv_n + 1) * xx.shape[0])\n",
        "                result[xx_stride] += xx\n",
        "\n",
        "        result = result.view((x.shape[0], self.out_channels, width, height))\n",
        "        return result  \n",
        "\n",
        "    def calculate_windows(self, x):\n",
        "        windows = F.unfold(\n",
        "            x,\n",
        "            kernel_size=(self.kernel_size, self.kernel_size),\n",
        "            padding=(self.padding, self.padding),\n",
        "            dilation=(self.dilation, self.dilation),\n",
        "            stride=(self.stride, self.stride)\n",
        "        )\n",
        "\n",
        "        windows = (windows\n",
        "            .transpose(1, 2)\n",
        "            .contiguous().view((-1, x.shape[1], int(self.kernel_size**2)))\n",
        "            .transpose(0, 1)\n",
        "        )\n",
        "        return windows\n",
        "\n",
        "    def calculate_new_width(self, x):\n",
        "        return (\n",
        "            (x.shape[2] + 2 * self.padding - self.dilation * (self.kernel_size - 1) - 1)\n",
        "            // self.stride\n",
        "        ) + 1\n",
        "\n",
        "    def calculate_new_height(self, x):\n",
        "        return (\n",
        "            (x.shape[3] + 2 * self.padding - self.dilation * (self.kernel_size - 1) - 1)\n",
        "            // self.stride\n",
        "        ) + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "x = torch.randint(0, 255, (1, 3, 512, 512), device='cuda') / 255\n",
        "conv = Conv2d(3, 16, 3)\n",
        "conv.cuda()\n",
        "\n",
        "out = conv(x)\n",
        "out.mean().backward()\n",
        "\n",
        "end = time.time()\n",
        "elapsed = end-start\n",
        "\n",
        "print(f'elapsed time: {elapsed:.3}s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASxJJ2Edvo_7",
        "outputId": "0f646e0b-8fe7-4419-dc9a-0074be893501"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed time: 0.0259s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2d(torch.jit.ScriptModule): # <- OLD was class Conv2d(nn.Module)\n",
        "    def __init__(\n",
        "        self, n_channels, out_channels, kernel_size, dilation=1, padding=0, stride=1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.kernel_size_number = kernel_size * kernel_size\n",
        "        self.out_channels = out_channels\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.stride = stride\n",
        "        self.n_channels = n_channels\n",
        "        self.weights = nn.Parameter(\n",
        "            torch.Tensor(self.out_channels, self.n_channels, self.kernel_size**2)\n",
        "        )\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (\n",
        "            f\"Conv2d(n_channels={self.n_channels}, out_channels={self.out_channels}, \"\n",
        "            f\"kernel_size={self.kernel_size})\"\n",
        "        )\n",
        "    \n",
        "    @torch.jit.script_method # <- insert decorator\n",
        "    def forward(self, x):\n",
        "        width = self.calculate_new_width(x)\n",
        "        height = self.calculate_new_height(x)\n",
        "        windows = self.calculate_windows(x)\n",
        "        \n",
        "        result = torch.zeros(\n",
        "            [x.shape[0] * self.out_channels, width, height],\n",
        "            dtype=torch.float32, device=x.device\n",
        "        )\n",
        "\n",
        "        for channel in range(x.shape[1]):\n",
        "            for i_conv_n in range(self.out_channels):\n",
        "                xx = torch.matmul(windows[channel], self.weights[i_conv_n][channel]) \n",
        "                xx = xx.view((-1, width, height))\n",
        "                \n",
        "                xx_stride = slice(i_conv_n * xx.shape[0], (i_conv_n + 1) * xx.shape[0])\n",
        "                result[xx_stride] += xx\n",
        "\n",
        "        result = result.view((x.shape[0], self.out_channels, width, height))\n",
        "        return result  \n",
        "\n",
        "    def calculate_windows(self, x):\n",
        "        windows = F.unfold(\n",
        "            x,\n",
        "            kernel_size=(self.kernel_size, self.kernel_size),\n",
        "            padding=(self.padding, self.padding),\n",
        "            dilation=(self.dilation, self.dilation),\n",
        "            stride=(self.stride, self.stride)\n",
        "        )\n",
        "\n",
        "        windows = (windows\n",
        "            .transpose(1, 2)\n",
        "            .contiguous().view((-1, x.shape[1], int(self.kernel_size**2)))\n",
        "            .transpose(0, 1)\n",
        "        )\n",
        "        return windows\n",
        "\n",
        "    def calculate_new_width(self, x):\n",
        "        return (\n",
        "            (x.shape[2] + 2 * self.padding - self.dilation * (self.kernel_size - 1) - 1)\n",
        "            // self.stride\n",
        "        ) + 1\n",
        "\n",
        "    def calculate_new_height(self, x):\n",
        "        return (\n",
        "            (x.shape[3] + 2 * self.padding - self.dilation * (self.kernel_size - 1) - 1)\n",
        "            // self.stride\n",
        "        ) + 1"
      ],
      "metadata": {
        "id": "kaGtFNotvsDg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "x = torch.randint(0, 255, (1, 3, 512, 512), device='cuda') / 255\n",
        "conv = Conv2d(3, 16, 3)\n",
        "conv.cuda()\n",
        "\n",
        "out = conv(x)\n",
        "out.mean().backward()\n",
        "\n",
        "end = time.time()\n",
        "elapsed_jit = end-start\n",
        "\n",
        "print(f'elapsed time: {elapsed_jit:.3}s')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jkuw_hB7l21",
        "outputId": "bd7c97d3-1d21-426a-ab47-c2061c13aad0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed time: 0.0172s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'SpeedUp: {elapsed/elapsed_jit:.3}x')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6tWTTc77n1u",
        "outputId": "29051cde-f3eb-4421-d0c8-e2a8c36c22c2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpeedUp: 1.51x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch IR Graph"
      ],
      "metadata": {
        "id": "IIRv0w609zwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.jit.script\n",
        "def foo(len):\n",
        "    # type: (int) -> torch.Tensor\n",
        "    rv = torch.zeros(3, 4)\n",
        "    for i in range(len):\n",
        "        if i < 10:\n",
        "            rv = rv - 1.0\n",
        "        else:\n",
        "            rv = rv + 1.0\n",
        "    return rv\n",
        "\n",
        "print(foo.graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyc06CA093hG",
        "outputId": "f64caf8b-96cf-4ec4-aad4-53fed426fb44"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph(%len.1 : int):\n",
            "  %21 : int = prim::Constant[value=1]()\n",
            "  %13 : bool = prim::Constant[value=1]() # <ipython-input-24-8a34e03747f9>:5:4\n",
            "  %5 : NoneType = prim::Constant()\n",
            "  %1 : int = prim::Constant[value=3]() # <ipython-input-24-8a34e03747f9>:4:21\n",
            "  %2 : int = prim::Constant[value=4]() # <ipython-input-24-8a34e03747f9>:4:24\n",
            "  %16 : int = prim::Constant[value=10]() # <ipython-input-24-8a34e03747f9>:6:15\n",
            "  %20 : float = prim::Constant[value=1.]() # <ipython-input-24-8a34e03747f9>:7:22\n",
            "  %4 : int[] = prim::ListConstruct(%1, %2)\n",
            "  %rv.1 : Tensor = aten::zeros(%4, %5, %5, %5, %5) # <ipython-input-24-8a34e03747f9>:4:9\n",
            "  %rv : Tensor = prim::Loop(%len.1, %13, %rv.1) # <ipython-input-24-8a34e03747f9>:5:4\n",
            "    block0(%i.1 : int, %rv.29 : Tensor):\n",
            "      %17 : bool = aten::lt(%i.1, %16) # <ipython-input-24-8a34e03747f9>:6:11\n",
            "      %rv.27 : Tensor = prim::If(%17) # <ipython-input-24-8a34e03747f9>:6:8\n",
            "        block0():\n",
            "          %rv.5 : Tensor = aten::sub(%rv.29, %20, %21) # <ipython-input-24-8a34e03747f9>:7:17\n",
            "          -> (%rv.5)\n",
            "        block1():\n",
            "          %rv.11 : Tensor = aten::add(%rv.29, %20, %21) # <ipython-input-24-8a34e03747f9>:9:17\n",
            "          -> (%rv.11)\n",
            "      -> (%13, %rv.27)\n",
            "  return (%rv)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### %rv.1 : Tensor means we assign the output to a (unique) value named rv.1, that value is of Tensor type and that we do not know its concrete shape.\n",
        "\n",
        "#### aten::zeros is the operator (equivalent to torch.zeros) and the input list (%4, %6, %6, %10, %12) specifies which values in scope should be passed as inputs. The schema for built-in functions like aten::zeros can be found at Builtin Functions.\n",
        "\n"
      ],
      "metadata": {
        "id": "gfS5Blf4-BL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trace Example"
      ],
      "metadata": {
        "id": "MKTX912z-79A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_row_zero(x):\n",
        "    x[0] = torch.rand(*x.shape[1:2])\n",
        "    return x\n",
        "\n",
        "traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),))\n",
        "print(traced.graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkG52mTY-ln1",
        "outputId": "9e36f642-cb7a-4bfc-f7b2-a23d833dddd5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph(%x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
            "  %4 : int = prim::Constant[value=1]() # <ipython-input-35-9083ec5950df>:2:0\n",
            "  %5 : int = aten::size(%x, %4) # <ipython-input-35-9083ec5950df>:2:0\n",
            "  %6 : Long(device=cpu) = prim::NumToTensor(%5)\n",
            "  %7 : int = aten::Int(%6)\n",
            "  %8 : int[] = prim::ListConstruct(%7)\n",
            "  %9 : int = prim::Constant[value=6]() # <ipython-input-35-9083ec5950df>:2:0\n",
            "  %10 : NoneType = prim::Constant()\n",
            "  %11 : Device = prim::Constant[value=\"cpu\"]() # <ipython-input-35-9083ec5950df>:2:0\n",
            "  %12 : bool = prim::Constant[value=0]() # <ipython-input-35-9083ec5950df>:2:0\n",
            "  %13 : Float(4, strides=[1], requires_grad=0, device=cpu) = aten::rand(%8, %9, %10, %11, %12) # <ipython-input-35-9083ec5950df>:2:0\n",
            "  %14 : int = prim::Constant[value=0]() # <ipython-input-35-9083ec5950df>:2:0\n",
            "  %15 : int = prim::Constant[value=0]() # <ipython-input-35-9083ec5950df>:2:0\n",
            "  %16 : Float(4, strides=[1], requires_grad=0, device=cpu) = aten::select(%x, %14, %15) # <ipython-input-35-9083ec5950df>:2:0\n",
            "  %17 : bool = prim::Constant[value=0]()\n",
            "  %18 : Float(4, strides=[1], requires_grad=0, device=cpu) = aten::copy_(%16, %13, %17) # <ipython-input-35-9083ec5950df>:2:0\n",
            "  return (%x)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:827: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
            "\t%13 : Float(4, strides=[1], requires_grad=0, device=cpu) = aten::rand(%8, %9, %10, %11, %12) # <ipython-input-35-9083ec5950df>:2:0\n",
            "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
            "  _module_class,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:827: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Tensor-likes are not close!\n",
            "\n",
            "Mismatched elements: 4 / 12 (33.3%)\n",
            "Greatest absolute difference: 0.8664248585700989 at index (0, 0) (up to 1e-05 allowed)\n",
            "Greatest relative difference: 23.759565154853515 at index (0, 0) (up to 1e-05 allowed)\n",
            "  _module_class,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixing Warnings"
      ],
      "metadata": {
        "id": "CiaMZE5B-_pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_row_zero(x):\n",
        "    x = torch.cat((torch.rand(1, *x.shape[1:2]), x[1:2]), dim=0)\n",
        "    return x\n",
        "\n",
        "traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),))\n",
        "print(traced.graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wplJH55B_PZ1",
        "outputId": "ce2c3fbe-078c-4f31-e762-883a0d5d6460"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graph(%x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):\n",
            "  %4 : int = prim::Constant[value=1]() # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %5 : int = aten::size(%x, %4) # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %6 : Long(device=cpu) = prim::NumToTensor(%5)\n",
            "  %7 : int = aten::Int(%6)\n",
            "  %8 : int = prim::Constant[value=1]() # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %9 : int[] = prim::ListConstruct(%8, %7)\n",
            "  %10 : int = prim::Constant[value=6]() # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %11 : NoneType = prim::Constant()\n",
            "  %12 : Device = prim::Constant[value=\"cpu\"]() # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %13 : bool = prim::Constant[value=0]() # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %14 : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::rand(%9, %10, %11, %12, %13) # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %15 : int = prim::Constant[value=0]() # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %16 : int = prim::Constant[value=1]() # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %17 : int = prim::Constant[value=2]() # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %18 : int = prim::Constant[value=1]() # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %19 : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::slice(%x, %15, %16, %17, %18) # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %20 : Tensor[] = prim::ListConstruct(%14, %19)\n",
            "  %21 : int = prim::Constant[value=0]() # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  %22 : Float(2, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::cat(%20, %21) # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "  return (%22)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:827: TracerWarning: Trace had nondeterministic nodes. Did you forget call .eval() on your model? Nodes:\n",
            "\t%14 : Float(1, 4, strides=[4, 1], requires_grad=0, device=cpu) = aten::rand(%9, %10, %11, %12, %13) # <ipython-input-37-a0ec8869dac9>:2:0\n",
            "This may cause errors in trace checking. To disable trace checking, pass check_trace=False to torch.jit.trace()\n",
            "  _module_class,\n",
            "/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:827: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Tensor-likes are not close!\n",
            "\n",
            "Mismatched elements: 4 / 8 (50.0%)\n",
            "Greatest absolute difference: 0.7539458274841309 at index (0, 0) (up to 1e-05 allowed)\n",
            "Greatest relative difference: 15.360134189773595 at index (0, 2) (up to 1e-05 allowed)\n",
            "  _module_class,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## [Jit documentation](https://pytorch.org/docs/stable/jit.html)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZgLlllD295DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hqU3PrBmAT7h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}