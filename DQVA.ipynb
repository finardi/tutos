{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V8-DQVA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1GprDLq9Oe4R675qAZUfA9IHobG19BdU1",
      "authorship_tag": "ABX9TyNoVKymRglUOJYqT6wdtkhp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/tutos/blob/master/DQVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSruUD6mT-5X",
        "outputId": "dc957913-f15e-4a19-c989-f63b10a16064"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jan  6 09:39:02 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    23W / 300W |     10MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbYr6Eam-y_4"
      },
      "source": [
        "!tar -xf /content/drive/MyDrive/Colab\\ Notebooks/Final-project/train.tar.gz \n",
        "!tar -xf /content/drive/MyDrive/Colab\\ Notebooks/Final-project/val.tar.gz \n",
        "!tar -xf /content/drive/MyDrive/Colab\\ Notebooks/Final-project/test.tar.gz"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka8XiM-bicvy"
      },
      "source": [
        "!pip install -q \"transformers<4.0.0\"\n",
        "!pip install -q sentence_transformers"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b7BubuuiYRZ"
      },
      "source": [
        "# Python / Básics\n",
        "import os\n",
        "import gc\n",
        "import glob\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import numpy as np\n",
        "import collections\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PIL \n",
        "from PIL import Image\n",
        "\n",
        "# Torch\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from collections import OrderedDict\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Transformers / Sentence Transformers\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QafApgcKijGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f78e1a6-5fc2-49c2-a542-bb08668ffbc0"
      },
      "source": [
        "# ==================================== #\n",
        "# === Função que carregas as seeds === #\n",
        "# ==================================== #\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "manual_seed = 2357 # only primers ;)\n",
        "\n",
        "def deterministic(rep=True):\n",
        "    if rep:\n",
        "        np.random.seed(manual_seed)\n",
        "        torch.manual_seed(manual_seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(manual_seed)\n",
        "            torch.cuda.manual_seed_all(manual_seed)\n",
        "        torch.backends.cudnn.enabled = False \n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(f'Experimento deterministico, seed: {manual_seed} -- ', end = '')\n",
        "        print(f'Existe {torch.cuda.device_count()} GPU\\\n",
        " {torch.cuda.get_device_name(0)} disponível.')\n",
        "    else:\n",
        "        print('Experimento randomico')\n",
        "deterministic()        "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla V100-SXM2-16GB disponível.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c83siRCglAr2",
        "outputId": "33c3e134-dc02-4a71-e3e5-65dd7ec2b99b"
      },
      "source": [
        "# ======================================================= #\n",
        "# === Função que cria embeddings para OCR e Perguntas === #\n",
        "# ======================================================= #\n",
        "\n",
        "def create_embeddings(model, path_json, mode='ocr', phase='val', thrs=48, emb_size=512):\n",
        "    if mode == 'ocr':\n",
        "        \n",
        "        with open(path_json, 'rb') as handle:\n",
        "            dataset = json.loads(handle.read())\n",
        "\n",
        "        ocrs_list = []\n",
        "        for i, d in enumerate(dataset['data']):\n",
        "            ocr_file = d['image'].replace('documents', 'ocr_results').replace('.png', '.json')\n",
        "            with open(phase+'/'+ ocr_file, 'rb') as f:\n",
        "                ocr = json.loads(f.read())\n",
        "\n",
        "            lines = ocr['recognitionResults'][0]['lines']\n",
        "\n",
        "            text = ' '.join([w['text'] for l in lines for w in l['words']])\n",
        "            ocrs_list.append(lines)\n",
        "\n",
        "        doc_list_item = []\n",
        "        Embeddings = np.zeros((len(ocrs_list), thrs, emb_size), dtype=np.float32)\n",
        "        for i, doc in enumerate(ocrs_list):\n",
        "            test_list_item = []\n",
        "            for item in doc:\n",
        "                test_list_item.append(item['text'])\n",
        "\n",
        "\n",
        "            if len(test_list_item) > thrs:          \n",
        "                test_list_item = test_list_item[:thrs]\n",
        "                t = model.encode(test_list_item)\n",
        "            else:\n",
        "                t = model.encode(test_list_item)\n",
        "            if t.size == 0:\n",
        "                continue\n",
        "            Embeddings[i, :t.shape[0], :] = t[:,:]\n",
        "\n",
        "        return Embeddings\n",
        "    \n",
        "    else:\n",
        "        with open(path_json, 'rb') as handle:\n",
        "            dataset = json.loads(handle.read())\n",
        "        \n",
        "        questions = []\n",
        "        for d in dataset['data']:\n",
        "            questions.append(d['question'])\n",
        "\n",
        "        Embeddings_q = np.zeros((len(questions), thrs, emb_size), dtype=np.float32)\n",
        "\n",
        "        for i, q in enumerate(questions):\n",
        "            q_emb = model.encode(q)\n",
        "            Embeddings_q[i, 0, :] = q_emb\n",
        "        return  Embeddings_q           \n",
        "\n",
        "# ---------------------------------------------------------------------------------------\n",
        "model = SentenceTransformer('msmarco-distilroberta-base-v2')\n",
        "emb_size = model.get_sentence_embedding_dimension()\n",
        "model.max_seq_length = 256\n",
        "path_train = 'train/train_v1.0.json'\n",
        "path_val   = 'val/val_v1.0.json'\n",
        "\n",
        "start = time. time()\n",
        "Embeddings_OCR_train = create_embeddings(model, path_train, mode='ocr', phase='train', thrs=48, emb_size=emb_size)\n",
        "end = time. time()\n",
        "print(f'Embeddings_OCR_train:       {Embeddings_OCR_train.shape} -- Time: {(end - start)/60: .4}min')\n",
        "\n",
        "start = time. time()\n",
        "Embeddings_Q_train = create_embeddings(model, path_train, mode='q', phase='train', thrs=1, emb_size=emb_size)\n",
        "end = time. time()\n",
        "print(f'Embeddings_Questions_train: {Embeddings_Q_train.shape}  -- Time: {(end - start)/60: .4}min')\n",
        "\n",
        "start = time. time()\n",
        "Embeddings_OCR_val = create_embeddings(model, path_val, mode='ocr', phase='val', thrs=48, emb_size=emb_size)\n",
        "end = time. time()\n",
        "print(f'Embeddings_OCR_val:         {Embeddings_OCR_val.shape}  -- Time: {(end - start)/60: .4}min')\n",
        "\n",
        "start = time. time()\n",
        "Embeddings_Q_val = create_embeddings(model, path_val, mode='q', phase='val', thrs=1, emb_size=emb_size)\n",
        "end = time. time()\n",
        "print(f'Embeddings_Questions_val:   {Embeddings_Q_val.shape}   -- Time: {(end - start)/60: .4}min')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embeddings_OCR_train:       (39463, 48, 768) -- Time: 790.7727513313293\n",
            "Embeddings_Questions_train: (39463, 1, 768) -- Time: 351.23548913002014\n",
            "Embeddings_OCR_val:         (5349, 48, 768) -- Time: 107.45399713516235\n",
            "Embeddings_Questions_val:   (5349, 1, 768) -- Time: 47.866716623306274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lCWtq6jVB0i"
      },
      "source": [
        "# ====================== #\n",
        "# === Classe Dataset === #\n",
        "# ====================== #\n",
        "\n",
        "class DVQADataset(Dataset):\n",
        "    def __init__(self, path_dir, path_data, tokenizer, embeddings_ocr, embeddings_questions, target_max_len, transform):\n",
        "        super().__init__()\n",
        "\n",
        "        with open(path_data, 'rb') as handle:\n",
        "            dataset = json.loads(handle.read())\n",
        "        \n",
        "        self.data_dir = path_dir\n",
        "        self.data = dataset['data']\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.embeddings_ocr = embeddings_ocr\n",
        "        self.embeddings_questions = embeddings_questions\n",
        "        self.target_max_len = target_max_len\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _gen_image(self, idx):\n",
        "        img_file = Path(self.data[idx]['image'])\n",
        "        image = Image.open(self.data_dir / img_file).convert('RGB')\n",
        "        return image\n",
        "\n",
        "    def _gen_answer(self, idx):\n",
        "        answer = random.choice(self.data[idx]['answers'])\n",
        "        tokenization = self.tokenizer(\n",
        "            text=answer,\n",
        "            max_length=self.target_max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        answer_ids = tokenization['input_ids'].squeeze(0)\n",
        "\n",
        "        return answer_ids, answer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self._gen_image(idx)\n",
        "        img = self.transform(img)\n",
        "        \n",
        "        ocr_embeddings = self.embeddings_ocr[idx]        \n",
        "        questions_embeddings = self.embeddings_questions[idx]\n",
        "        \n",
        "        answer_ids, answer = self._gen_answer(idx)\n",
        "\n",
        "        return img, ocr_embeddings, questions_embeddings, answer_ids, answer"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNemDrUT4rQl",
        "outputId": "3d21f516-52f8-4039-8a39-0cd1224a627d"
      },
      "source": [
        "# ============================== #\n",
        "# === Datasets e Dataloaders === #\n",
        "# ============================== #\n",
        " \n",
        "BATCH_SZ = 10\n",
        "TARGET_MAX_LEN = 10\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "transforms_img = transforms.Compose([transforms.Resize((640, 480)), transforms.ToTensor()])\n",
        "\n",
        "ds_train = DVQADataset(\n",
        "    path_dir='train/', \n",
        "    path_data=path_train,\n",
        "    tokenizer=t5_tokenizer,\n",
        "    embeddings_ocr=Embeddings_OCR_train,\n",
        "    embeddings_questions=Embeddings_Q_train, \n",
        "    target_max_len=TARGET_MAX_LEN,\n",
        "    transform=transforms_img, \n",
        ")\n",
        "\n",
        "ds_val = DVQADataset(\n",
        "    path_dir='val/',\n",
        "    path_data=path_val,\n",
        "    tokenizer=t5_tokenizer,\n",
        "    embeddings_ocr=Embeddings_OCR_val,\n",
        "    embeddings_questions=Embeddings_Q_val, \n",
        "    target_max_len=TARGET_MAX_LEN,\n",
        "    transform=transforms_img, \n",
        ")\n",
        "\n",
        "dataloaders = {\n",
        "     'train': DataLoader(\n",
        "         ds_train,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=True,\n",
        "         num_workers=4,\n",
        "         pin_memory=True\n",
        "         ),\n",
        "               \n",
        "     'val': DataLoader(\n",
        "         ds_val,\n",
        "         batch_size=BATCH_SZ,\n",
        "         num_workers=4,\n",
        "         pin_memory=True\n",
        "         )\n",
        "}\n",
        " \n",
        "# Verificando os tamanhos dos dataloaders\n",
        "_ = {x: len(dataloaders[x]) for x in dataloaders.keys()}\n",
        "_"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 3947, 'val': 535}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3VmYas9TCYE",
        "outputId": "e0b15a42-4f23-4841-aa95-c7b439cb4ab8"
      },
      "source": [
        "# =========================== #\n",
        "# === Teste do Dataloader === #\n",
        "# =========================== #\n",
        " \n",
        "img, ocr_embeddings, questions_embeddings, answer_ids, answer = next(iter(dataloaders['train']))\n",
        " \n",
        "print('image.shape:                ', img.shape)\n",
        "print('ocr_embeddings.shape:       ', ocr_embeddings.shape)\n",
        "print('questions_embeddings.shape: ', questions_embeddings.shape)\n",
        "print('answer_ids.shape:           ', answer_ids.shape)\n",
        "print('answer:                     ', answer)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image.shape:                 torch.Size([10, 3, 640, 480])\n",
            "ocr_embeddings.shape:        torch.Size([10, 48, 768])\n",
            "questions_embeddings.shape:  torch.Size([10, 1, 768])\n",
            "answer_ids.shape:            torch.Size([10, 10])\n",
            "answer:                      ['CG1 - 1990 Flue Cured', 'John Quist', '17.9', 'Cincinnati, Ohio', '02/15/2009', '328.7', 'Paul Saltman', 'John E. Kilpatrick', '51,794', '410']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSb3SiHJrwJo"
      },
      "source": [
        "# ================ #\n",
        "# === Métricas === #\n",
        "# ================ #\n",
        " \n",
        "def normalize_answer(s):\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        " \n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        " \n",
        "    return white_space_fix(lower(s))\n",
        " \n",
        "def get_tokens(s):\n",
        "    if not s: return []\n",
        "    return normalize_answer(s).split()\n",
        " \n",
        "def compute_exact(a_gold, a_pred):\n",
        "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
        " \n",
        "def compute_f1(a_gold, a_pred):\n",
        "    gold_toks = get_tokens(a_gold)\n",
        "    pred_toks = get_tokens(a_pred)\n",
        "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "    num_same = sum(common.values())\n",
        "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
        "        return int(gold_toks == pred_toks)\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(pred_toks)\n",
        "    recall = 1.0 * num_same / len(gold_toks)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuOEL7zoDdTJ"
      },
      "source": [
        "path_save_model = '/content/drive/MyDrive/Colab Notebooks/Final-project/saved_epochs/'"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pWaLA0fqqG0"
      },
      "source": [
        "# ===================================== #\n",
        "# === Funções de Treino e Validação === #\n",
        "# ===================================== #\n",
        " \n",
        "def train_one_epoch(model, batch, device, optimizer):\n",
        "    batch_device = tuple(t.to(device) if type(t) != list else t for t in batch)\n",
        "    model.zero_grad()\n",
        "    loss = model(batch_device)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        " \n",
        "def train_model(model, device, dataloader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        total_loss += train_one_epoch(model, batch, device, optimizer)\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss\n",
        " \n",
        "# ------------------------------------------------------------------------------------\n",
        " \n",
        "def val_one_epoch(model, batch, device, tokenizer, compute_exact, compute_f1):\n",
        "    batch_device = tuple(t.to(device) if type(t) != list else t for t in batch)\n",
        "    img, ocr_embeddings, questions_embeddings, answer_ids, answers = batch  \n",
        "    \n",
        "    predicted_ids = model(batch_device)\n",
        "    preds = [tokenizer.decode(ids) for ids in predicted_ids]\n",
        "    \n",
        "    batch_size = img.shape[0]\n",
        "    exact = sum([compute_exact(ans, pred) for ans, pred in zip(answers, preds)]) / batch_size\n",
        "    f1 = sum([compute_f1(ans, pred) for ans, pred in zip(answers, preds)]) / batch_size\n",
        " \n",
        "    return exact, f1\n",
        " \n",
        "def val_model(model, device, tokenizer, dataloader, compute_exact, compute_f1, epoch_i):\n",
        "    model.eval()\n",
        "    total_exact, total_f1 = [],[]\n",
        "    for batch in dataloader:\n",
        "        exact, f1 = val_one_epoch(model, batch, device, tokenizer, compute_exact, compute_f1)\n",
        "        total_exact.append(exact)\n",
        "        total_f1.append(f1)\n",
        "    avg_exact = np.array(total_exact).mean()\n",
        "    avg_f1 = np.array(total_f1).mean()\n",
        "    \n",
        "    torch.save(model.state_dict(), path_save_model+'V8_'+str(epoch_i))\n",
        " \n",
        "    return avg_exact, avg_f1"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoLR2pjAjQc0"
      },
      "source": [
        "# =========================== #\n",
        "# === Modelo: Resnet + T5 === #\n",
        "# =========================== #\n",
        " \n",
        "class DQVA_Model(nn.Module):\n",
        "    def __init__(self, convnet, nlp_model, target_max_len):\n",
        "        super().__init__()\n",
        " \n",
        "        self.convnet = convnet\n",
        "        self.target_max_len = target_max_len\n",
        " \n",
        "        self.t5 = T5ForConditionalGeneration.from_pretrained(nlp_model)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        img, ocr_embeddings, questions_embeddings, answer_ids, answers = batch  \n",
        "        \n",
        "        img_embeds = self.convnet(img)\n",
        "        inputs_embeds = torch.cat((img_embeds, ocr_embeddings, questions_embeddings), dim=1)\n",
        "\n",
        "        if self.training:\n",
        "            outputs = self.t5(\n",
        "                inputs_embeds=inputs_embeds, \n",
        "                labels=answer_ids,\n",
        "                return_dict=True\n",
        "            )\n",
        "            return outputs.loss\n",
        " \n",
        "        else:\n",
        "            return self.generate(inputs_embeds)\n",
        " \n",
        "    def generate(self, inputs_embeds):\n",
        "        decoded_ids = torch.full(\n",
        "            size=(inputs_embeds.shape[0], 1), \n",
        "            fill_value=self.t5.config.decoder_start_token_id, \n",
        "            dtype=torch.long\n",
        "        ).to(inputs_embeds.device)\n",
        " \n",
        "        encoder_hidden_states = self.t5.get_encoder()(\n",
        "            inputs_embeds=inputs_embeds\n",
        "        )\n",
        " \n",
        "        for step in range(self.target_max_len):\n",
        "            logits = self.t5(decoder_input_ids=decoded_ids,\n",
        "                             encoder_outputs=encoder_hidden_states)[0]\n",
        "            next_token_logits = logits[:, -1, :]\n",
        "            next_token_id = next_token_logits.argmax(1).unsqueeze(-1)\n",
        "            if torch.eq(next_token_id[:, -1], self.tokenizer.eos_token_id).all():\n",
        "                break\n",
        " \n",
        "            decoded_ids = torch.cat([decoded_ids, next_token_id], dim=-1)\n",
        "        return decoded_ids\n",
        " \n",
        "class EncoderResnet(nn.Module):\n",
        "    def __init__(self, cnn, channels, embed_size):\n",
        "        super(EncoderResnet, self).__init__()\n",
        "        self.cnn = nn.Sequential(*list(cnn.children())[:-2])\n",
        "        self.conv1 = nn.Conv2d(channels, embed_size, 1)\n",
        "        self.adaptive = nn.AdaptiveAvgPool2d((12, 9))\n",
        "        self.embed_size = embed_size\n",
        "        \n",
        "    def forward(self, x):\n",
        "        output = self.cnn(x) # N, C=2048 H, W\n",
        "        output = self.conv1(output)\n",
        "        output = self.adaptive(output)\n",
        "        output = output.view(output.size(0), self.embed_size, -1)  \n",
        "        output = output.permute(0, 2, 1) \n",
        "        return output\n",
        " \n",
        "    def freeze(self):\n",
        "        for p in self.cnn.parameters():\n",
        "            p.requires_grad = False\n",
        "        for c in list(self.cnn.children()):\n",
        "            for p in c.parameters():\n",
        "                p.requires_grad = False"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7w4IwMAo76U"
      },
      "source": [
        "try:\n",
        "    del model\n",
        "    del resnet\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "except:\n",
        "    pass\n",
        " \n",
        "lr = 5e-5\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet_model = EncoderResnet(resnet, 4 * emb_size, emb_size).to(device)\n",
        "resnet_model.freeze()\n",
        " \n",
        "model = DQVA_Model(\n",
        "    convnet=resnet_model, \n",
        "    nlp_model='t5-base', \n",
        "    target_max_len=TARGET_MAX_LEN\n",
        "    ).to(device)\n",
        " \n",
        "optimizer = AdamW([p for p in model.parameters() if p.requires_grad], lr=lr)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lckbhykl5RK8",
        "outputId": "575dabd5-654e-4305-9f24-8445b20d55b8"
      },
      "source": [
        "# ========================= #\n",
        "# === Número de params. === #\n",
        "# ========================= #\n",
        " \n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        " \n",
        "print('\\n','#' * 54, f'\\n # Número de params. {count_parameters(model):,}' \\\n",
        "       ' trainable parameters #\\n', '#' * 54,'\\n')  \n",
        "# model"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ###################################################### \n",
            " # Número de params. 223,953,024 trainable parameters #\n",
            " ###################################################### \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKZ_3Q-Vvf_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aab4bf4-f3eb-4691-da46-05a55be30de3"
      },
      "source": [
        "# =================== #\n",
        "# === Treinamento === #\n",
        "# =================== #\n",
        " \n",
        "LOAD = False\n",
        "N_EPOCHS = 100\n",
        "deterministic()\n",
        " \n",
        "if LOAD:\n",
        "    model.load_state_dict(torch.load(path_save_model+'V8_'+str(30), \n",
        "                                     map_location=torch.device(device)))\n",
        " \n",
        "# ---------------------------------------------------------------------------------\n",
        "training_stats = []\n",
        "for epoch_i in range(1, N_EPOCHS+1):\n",
        "    loss_train =  train_model(model, device, dataloaders['train'], optimizer)\n",
        "    exact, f1 = val_model(model, device, t5_tokenizer, dataloaders['val'], \n",
        "                          compute_exact, compute_f1, epoch_i)\n",
        " \n",
        "    print(f'EPOCH_{epoch_i}: LOSS TRAIN: {loss_train:.4} -- EXACT_MATCH: {exact:.4}  --  F1: {f1:.4}')\n",
        " \n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i,\n",
        "            'Training Loss': loss_train,\n",
        "            'Exact match': exact,\n",
        "            'F1 score': f1,\n",
        "        }\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla V100-SXM2-16GB disponível.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SBsntbq64SF"
      },
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "pd.set_option('precision', 3)\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1YDFKUEqxG0"
      },
      "source": [
        "df_stats[['Exact match', 'F1 score']].plot(\n",
        "    figsize=(12, 5), \n",
        "    lw=2, \n",
        "    ylabel=\"Score\", \n",
        "    fontsize=16, \n",
        "    grid=True, \n",
        "    title='Scores em VAL split'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpwgaOnPEUHT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}