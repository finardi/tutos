{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT FIQA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cccbd88d0a514f3c80727df398f242cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7cc184ea343c44d2adf1dedf36a386bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e52c0d8b891a4904bd1f8416168b4eb6",
              "IPY_MODEL_1b627b5979ba4fc9a779b28d7b110898"
            ]
          }
        },
        "7cc184ea343c44d2adf1dedf36a386bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e52c0d8b891a4904bd1f8416168b4eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_12a2eb4de495477987cccaa491e2a24a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb1c06e048df47cd8867b88871be08dc"
          }
        },
        "1b627b5979ba4fc9a779b28d7b110898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ede1fe7ba4474a05a052c26c15d842bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 968kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8627393393ce4bafbf91bf5b15ce2f65"
          }
        },
        "12a2eb4de495477987cccaa491e2a24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb1c06e048df47cd8867b88871be08dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ede1fe7ba4474a05a052c26c15d842bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8627393393ce4bafbf91bf5b15ce2f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/tutos/blob/master/BERT_FIQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0aSsmftY7wz",
        "colab_type": "text"
      },
      "source": [
        "# Dataset FiQA\n",
        "> [Link do dataset](https://sites.google.com/view/fiqa/home?authuser=0)\n",
        "\n",
        "Inspirado no github:\n",
        "> [Yuanbit](https://github.com/yuanbit/FinBERT-QA/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYZP7bc84ar3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3456d9b7-d41a-47f1-824a-0e40757469b9"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 890kB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 17.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 60.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 50.8MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYk-8I2xZCDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b9b9f67b-eced-469b-f4dd-23b1f97eb45c"
      },
      "source": [
        "# basic\n",
        "import os\n",
        "import math \n",
        "import pickle\n",
        "import random\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statistics import mean\n",
        "from itertools import combinations\n",
        "\n",
        "# plot\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "from torch.utils.data import random_split, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "# transformers\n",
        "from transformers import (BertTokenizer, BertForSequenceClassification, \n",
        "                          AdamW, get_linear_schedule_with_warmup, BertConfig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsAqDQ3wt7Gy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7550aad-5dcf-4413-a62f-837d1ae8c240"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "manual_seed = 2357\n",
        "\n",
        "def deterministic(rep=True):\n",
        "    if rep:\n",
        "        np.random.seed(manual_seed)\n",
        "        torch.manual_seed(manual_seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(manual_seed)\n",
        "            torch.cuda.manual_seed_all(manual_seed)\n",
        "        torch.backends.cudnn.enabled = False \n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(f'Experimento deterministico, seed: {manual_seed} -- ', end = '')\n",
        "        print(f'Existe {torch.cuda.device_count()} GPU {torch.cuda.get_device_name(0)} disponível.')\n",
        "    else:\n",
        "        print('Experimento randomico')\n",
        "\n",
        "deterministic()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla T4 disponível.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2ltuOvUisG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "cccbd88d0a514f3c80727df398f242cf",
            "7cc184ea343c44d2adf1dedf36a386bf",
            "e52c0d8b891a4904bd1f8416168b4eb6",
            "1b627b5979ba4fc9a779b28d7b110898",
            "12a2eb4de495477987cccaa491e2a24a",
            "fb1c06e048df47cd8867b88871be08dc",
            "ede1fe7ba4474a05a052c26c15d842bc",
            "8627393393ce4bafbf91bf5b15ce2f65"
          ]
        },
        "outputId": "81be8f2d-a585-4996-eef2-1ee8ddfee0d2"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cccbd88d0a514f3c80727df398f242cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMh9iElXjvLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c1cb97e-6099-4a2d-bdc6-5fad5a81cead"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71tLRWFtZDEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "be29c771-2c35-45c2-b457-27ac38fe26a0"
      },
      "source": [
        "path_dataset = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/BERT/FinBERT/data/raw/'\n",
        "\n",
        "df_questions = pd.read_csv(path_dataset+'FiQA_train_question_final.tsv', sep='\\t', index_col=0)\n",
        "df_docs = pd.read_csv(path_dataset+'FiQA_train_doc_final.tsv', sep='\\t', index_col=0)\n",
        "df_labels = pd.read_csv(path_dataset+'FiQA_train_question_doc_final.tsv', sep='\\t', index_col=0)\n",
        "\n",
        "print(f'Shape do dataset das questions: {df_questions.shape:}')\n",
        "print(f'Shape do dataset dos docs:      {df_docs.shape}')\n",
        "print(f'Shape do dataset das labels:    {df_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape do dataset das questions: (6648, 3)\n",
            "Shape do dataset dos docs:      (57638, 3)\n",
            "Shape do dataset das labels:    (17110, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zQx21__amQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "83d9dc10-a9a0-4b4d-e3b5-ede68776e66b"
      },
      "source": [
        "df_questions.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What is considered a business expense on a bus...</td>\n",
              "      <td>Nov 8 '11 at 15:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Claiming business expenses for a business with...</td>\n",
              "      <td>May 13 '14 at 13:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Transferring money from One business checking ...</td>\n",
              "      <td>Jan 20 '16 at 20:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qid                                           question            timestamp\n",
              "0    0  What is considered a business expense on a bus...   Nov 8 '11 at 15:14\n",
              "1    1  Claiming business expenses for a business with...  May 13 '14 at 13:17\n",
              "2    2  Transferring money from One business checking ...  Jan 20 '16 at 20:31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5NZi9i-ZJQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "6a6382c3-ef6f-45ae-9f69-c256d0fe41e3"
      },
      "source": [
        "df_docs.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>doc</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>I'm not saying I don't like the idea of on-the...</td>\n",
              "      <td>Oct 03 '12 at 14:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31</td>\n",
              "      <td>So nothing preventing false ratings besides ad...</td>\n",
              "      <td>Sep 01 '17 at 13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56</td>\n",
              "      <td>You can never use a health FSA for individual ...</td>\n",
              "      <td>Jun 9 '14 at 17:37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   docid  ...            timestamp\n",
              "0      3  ...  Oct 03 '12 at 14:56\n",
              "1     31  ...  Sep 01 '17 at 13:36\n",
              "2     56  ...   Jun 9 '14 at 17:37\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxcBZYF5aeGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "1b87e984-e925-47ab-932f-102c044300fb"
      },
      "source": [
        "df_labels.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>14255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>308938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qid   docid\n",
              "0    0   18850\n",
              "1    1   14255\n",
              "2    2  308938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at_GmgPpmpdt",
        "colab_type": "text"
      },
      "source": [
        "# Subamostragem\n",
        "> um pedaço do dataset, motivo: conseguir treinar mais rápido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqYIDCfYpDvU",
        "colab_type": "text"
      },
      "source": [
        "### Subsamostragem das labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-JPB26smsmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "1f3af54a-8bb3-441d-c92d-a88798bb0616"
      },
      "source": [
        "df_labels_sub = df_labels[:300] \n",
        "\n",
        "questions_sub = list(set(df_labels_sub.qid.to_list()))\n",
        "docs_rel = list(set(df_labels_sub.docid.to_list()))\n",
        "print(f'Qtde de questions subsampling: {len(questions_sub)}')\n",
        "print(f'Qtde de docs rel. subsampling: {len(docs_rel)}')\n",
        "\n",
        "print(f'df_labels_sub shape: {df_labels_sub.shape}\\n')\n",
        "df_labels_sub.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Qtde de questions subsampling: 160\n",
            "Qtde de docs rel. subsampling: 300\n",
            "df_labels_sub shape: (300, 2)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>14255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>308938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qid   docid\n",
              "0    0   18850\n",
              "1    1   14255\n",
              "2    2  308938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifGodLsao9z5",
        "colab_type": "text"
      },
      "source": [
        "### Subsamostragem dos documentos/respostas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90vSst_emseW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "8f787f56-791b-4ca8-9c41-d9db042bb229"
      },
      "source": [
        "# docs irrelevantes (não é reposta de nenhum qid)\n",
        "noise_docs = df_docs[~df_docs.docid.isin(docs_rel)][:2000]\n",
        "\n",
        "# docs relevantes é reposta de alguma qid\n",
        "docs_with_answer = df_docs[df_docs.docid.isin(docs_rel)]\n",
        "\n",
        "# subsampling docs: (docs rel. + docs irrel.)\n",
        "df_docs_sub = pd.concat((docs_with_answer, noise_docs), axis=0)\n",
        "\n",
        "# dict com codid -> doc\n",
        "docid_to_text = {k:v for k,v in zip(df_docs.docid.to_list(), df_docs.doc.to_list())}\n",
        "print(f'df_docs_sub shape: {df_docs_sub.shape}')\n",
        "df_docs_sub.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_docs_sub shape: (2300, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>doc</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>13013</td>\n",
              "      <td>There are a number of mutual funds which claim...</td>\n",
              "      <td>Aug 25 '15 at 20:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1338</th>\n",
              "      <td>14255</td>\n",
              "      <td>Yes you can claim your business deductions if ...</td>\n",
              "      <td>May 14 '14 at 8:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>18792</td>\n",
              "      <td>You are confining the way you and the other co...</td>\n",
              "      <td>Feb 20 at 22:47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      docid  ...            timestamp\n",
              "1230  13013  ...  Aug 25 '15 at 20:04\n",
              "1338  14255  ...   May 14 '14 at 8:07\n",
              "1795  18792  ...      Feb 20 at 22:47\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G5hWPtiBqBpg"
      },
      "source": [
        "### Subsamostragem das questões"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D9eoOM9JqBpm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "044a46b3-f8a6-4d12-ab31-d6909fa93980"
      },
      "source": [
        "df_questions_sub = df_questions[df_questions.qid.isin(questions_sub)]\n",
        "\n",
        "# dict com qid -> question\n",
        "qid_to_text = {k:v for k,v in zip(df_questions.qid.to_list(), df_questions.question.to_list())}\n",
        "print(f'df_questions_sub shape: {df_questions_sub.shape}')\n",
        "df_questions_sub.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_questions_sub shape: (160, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What is considered a business expense on a bus...</td>\n",
              "      <td>Nov 8 '11 at 15:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Claiming business expenses for a business with...</td>\n",
              "      <td>May 13 '14 at 13:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Transferring money from One business checking ...</td>\n",
              "      <td>Jan 20 '16 at 20:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qid                                           question            timestamp\n",
              "0    0  What is considered a business expense on a bus...   Nov 8 '11 at 15:14\n",
              "1    1  Claiming business expenses for a business with...  May 13 '14 at 13:17\n",
              "2    2  Transferring money from One business checking ...  Jan 20 '16 at 20:31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPvKVKysmr_D",
        "colab_type": "text"
      },
      "source": [
        "# Prep data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d97wg7X-2iuu",
        "colab_type": "text"
      },
      "source": [
        "## Agrupando os labels por qid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IspWgUXY2imL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "779fecd3-f222-463c-ee81-493dce638a8d"
      },
      "source": [
        "df_labels_sub = df_labels_sub.assign(qid = df_labels_sub.qid.apply(lambda x: int(x)))\n",
        "df_labels_sub = df_labels_sub.assign(docid = df_labels_sub.docid.apply(lambda x: int(x)))\n",
        "\n",
        "labels_group = df_labels_sub.groupby(['qid']).agg(lambda x: tuple(x)).applymap(list).reset_index()\n",
        "\n",
        "TRAIN_SIZE = 130 # simples slit do dataset\n",
        "\n",
        "train_data = labels_group[:TRAIN_SIZE]\n",
        "labels_train = {k:v for k,v in zip(train_data.qid.to_list(), train_data.docid.to_list())}\n",
        "\n",
        "valid_data = labels_group[TRAIN_SIZE:] \n",
        "labels_valid = {k:v for k,v in zip(valid_data.qid.to_list(), valid_data.docid.to_list())}\n",
        "\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[18850]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[14255]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[308938]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[296717, 100764, 314352, 146317]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[196463]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>468</td>\n",
              "      <td>[498927, 536760]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>469</td>\n",
              "      <td>[250939, 549432]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>470</td>\n",
              "      <td>[45078]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>471</td>\n",
              "      <td>[158122, 494625]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>472</td>\n",
              "      <td>[337071]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     qid                             docid\n",
              "0      0                           [18850]\n",
              "1      1                           [14255]\n",
              "2      2                          [308938]\n",
              "3      3  [296717, 100764, 314352, 146317]\n",
              "4      4                          [196463]\n",
              "..   ...                               ...\n",
              "125  468                  [498927, 536760]\n",
              "126  469                  [250939, 549432]\n",
              "127  470                           [45078]\n",
              "128  471                  [158122, 494625]\n",
              "129  472                          [337071]\n",
              "\n",
              "[130 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WfovQic_PYS",
        "colab_type": "text"
      },
      "source": [
        "#### Se o docid para uma query possui mais de um elemento na lista, vamos sortear as respostas candidadas com relação ao tamanho da lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HImUUdmkMO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14c191b3-0e81-414b-e524-a4b5b40f9be5"
      },
      "source": [
        "def make_dataset(df, number_of_cands=30):\n",
        "    # num. de candidatos por amostra\n",
        "    K = number_of_cands\n",
        "\n",
        "    # dataset \n",
        "    df_ = df.copy() # cols: df[['qid'], ['docid']]\n",
        "\n",
        "    # lista que armazenará o shape final do dataset\n",
        "    data = []\n",
        "\n",
        "    # candidatos a resposta\n",
        "    cands_dataset = []\n",
        "\n",
        "    # para cada linha do df...\n",
        "    for i, row_data in enumerate(df_.iterrows()):\n",
        "\n",
        "        cands_dataset = []\n",
        "        \n",
        "        # sorteia cands aleatórias  \n",
        "        docs_choice = list(np.random.choice(df_docs.docid, 2 * K, replace=False))\n",
        "        \n",
        "        # adiciona as cands na lista \n",
        "        cands_dataset.extend(docs_choice)\n",
        "        \n",
        "        # anexa os labels na lista faz o set, emaralha e trunca em K\n",
        "        set_list_cands = list(set(row_data[1].docid + cands_dataset))\n",
        "        \n",
        "        cands = random.sample(set_list_cands, len(set_list_cands))[:K]\n",
        "\n",
        "        # descarta as amostras que não possuem o número de cands = K  \n",
        "        if len(cands) == K:    \n",
        "            data.append([row_data[1].qid, row_data[1].docid, cands])\n",
        "\n",
        "    return data # list [[qid], [labels], [cands]]    \n",
        "\n",
        "#---------------------------------------------\n",
        "data_train = make_dataset(train_data, 40)\n",
        "data_valid = make_dataset(valid_data, 40)\n",
        "data_train.pop(116)\n",
        "print(f'Amostras de treino: {len(data_train)} -- Amostras de valid: {len(data_valid)}')        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amostras de treino: 129 -- Amostras de valid: 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvO084z38ClS",
        "colab_type": "text"
      },
      "source": [
        "# Estudo do tam. das amostras do dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yw7pIP972pL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c95f9920-70e3-4e74-cb9c-17744768c846"
      },
      "source": [
        "def get_input_tokenized_lenghts(dataset):\n",
        "\n",
        "    # remove o warning do log\n",
        "    logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
        "\n",
        "    lengths = []\n",
        "\n",
        "    for i, seq in enumerate(dataset):\n",
        "        qid, ans_labels, cands = seq[0], seq[1], seq[2]\n",
        "\n",
        "        # Mapeia o id da pergunta para o texto\n",
        "        q_text = qid_to_text[qid]\n",
        "\n",
        "        # Para cada id de resposta em respostas candidatas\n",
        "        for docid in cands:\n",
        "            # Mapeia o docid para o texto\n",
        "            ans_text = docid_to_text[docid]\n",
        "            input_ids = tokenizer.encode(\n",
        "                q_text, \n",
        "                ans_text,\n",
        "                add_special_tokens = True)\n",
        "\n",
        "            lengths.append(len(input_ids))\n",
        "    return lengths\n",
        "\n",
        "#-----------------------------------------------------\n",
        "lengths = get_input_tokenized_lenghts(data_train)\n",
        "\n",
        "print(f' comp. Min: {min(lengths):>8} tokens')\n",
        "print(f' comp. Max: {max(lengths):>8} tokens')\n",
        "print(f' comp. Mediano: {np.median(lengths):,} tokens')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   comp. Min:     18 tokens\n",
            "   comp. Max:    2675 tokens\n",
            "   comp. Mediano: 132.0 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d00F_Hfh9O7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "a7999558-449f-48d5-8d1b-a41c6acab2d7"
      },
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "trunc_lengths = [min(l, 512) for l in lengths]\n",
        "\n",
        "sns.distplot(trunc_lengths, kde=False, rug=False)\n",
        "\n",
        "plt.title('Comprimento da Sequencia, truncado em 512')\n",
        "plt.xlabel('Comprimento da Sequencia')\n",
        "plt.ylabel('# de Exemplos')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUM7CjV69cSg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4aedcc7b-b029-493c-c36b-f98f634da505"
      },
      "source": [
        "lengths = np.asarray(lengths)\n",
        "\n",
        "num_comments = len(lengths)\n",
        "max_lens = [128, 256, 300, 384, 512]\n",
        "\n",
        "print('Quantas entradas serão truncadas?\\n')\n",
        "\n",
        "for max_len in max_lens:\n",
        "    num_over = np.sum(lengths > max_len)\n",
        "    prcnt_over = float(num_over) / float(num_comments)\n",
        "    print(f'max_len = {max_len:} --> {num_over:>5,} de ' \\\n",
        "    f'{num_comments:>5,}  ({prcnt_over:>5.1%}) serão truncadas')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantas entradas serão truncadas?\n",
            "\n",
            "max_len = 128 --> 2,661 de 5,160  (51.6%) serão truncadas\n",
            "max_len = 256 --> 1,086 de 5,160  (21.0%) serão truncadas\n",
            "max_len = 300 -->   809 de 5,160  (15.7%) serão truncadas\n",
            "max_len = 384 -->   510 de 5,160  ( 9.9%) serão truncadas\n",
            "max_len = 512 -->   227 de 5,160  ( 4.4%) serão truncadas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-d-fYDVjTtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6050decd-8708-4c33-e967-9a5e8dca399a"
      },
      "source": [
        "def get_input_data(dataset, max_seq_len=384):\n",
        "    all_input_ids, attention_masks, segment_ids, labels = [], [], [], []\n",
        "    \n",
        "    # remove o warning do log\n",
        "    logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
        "\n",
        "    for i, seq in enumerate(dataset):\n",
        "\n",
        "        qid, ans_labels, cands = seq[0], seq[1], seq[2]\n",
        "\n",
        "        # Mapeia a questão para o texto\n",
        "        q_text = qid_to_text[qid]\n",
        "\n",
        "        # Para cada resposta naas candidatas...\n",
        "        for docid in cands:\n",
        "            # Mapeia o docid para o texto\n",
        "            ans_text = docid_to_text[docid]\n",
        "            \n",
        "            # Codifica a sequencia usanso o tokenizador\n",
        "            encoded_seq = tokenizer.encode_plus(\n",
        "                q_text, \n",
        "                ans_text,\n",
        "                max_length=max_seq_len,\n",
        "                pad_to_max_length=True,\n",
        "                return_token_type_ids=True,\n",
        "                return_attention_mask=True,\n",
        "                return_tensors = 'pt'\n",
        "                )\n",
        "\n",
        "            # Se uma resposta na lista é relevante é um label positivo\n",
        "            if docid in ans_labels:\n",
        "                label = 1\n",
        "            # caso contrário é um label negativo\n",
        "            else:\n",
        "                label = 0\n",
        "            \n",
        "                \n",
        "            # Verifica se os tamanhos estão corretos\n",
        "            assert encoded_seq['input_ids'].shape[1] == max_seq_len, \"dim. do Input esta errada!\"\n",
        "            assert encoded_seq['token_type_ids'].shape[1] == max_seq_len, \"dim. do token_type_id esta errada!\"\n",
        "            assert encoded_seq['attention_mask'].shape[1] == max_seq_len, \"dim. da attention_mask esta errada!\"\n",
        "\n",
        "            all_input_ids.append(encoded_seq['input_ids'])\n",
        "            segment_ids.append(encoded_seq['token_type_ids'])\n",
        "            attention_masks.append(encoded_seq['attention_mask'])\n",
        "            labels.append(label)\n",
        "\n",
        "    all_input_ids = torch.cat(all_input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    segment_ids = torch.cat(segment_ids, dim=0)\n",
        "    \n",
        "    return all_input_ids, attention_masks, segment_ids, labels\n",
        "\n",
        "# teste de sanidade\n",
        "all_input_ids, attention_masks, segment_ids, labels = get_input_data(data_valid, 384)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhP4rbjBn5Hc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "186c9787-2096-4019-e932-78626d8de447"
      },
      "source": [
        "MAX_LEN = 384\n",
        "BATCH_SZ = 16\n",
        "\n",
        "#-----------------------------------__DATASETS__-----------------------------------\n",
        "# cria o dataset de treino\n",
        "all_input_ids_T, attention_masks_T, segment_ids_T, labels_T = get_input_data(\n",
        "    data_train, \n",
        "    MAX_LEN\n",
        "    )\n",
        "\n",
        "ds_train = TensorDataset(\n",
        "    all_input_ids_T, \n",
        "    attention_masks_T, \n",
        "    segment_ids_T, \n",
        "    torch.tensor(labels_T)\n",
        "    )\n",
        "\n",
        "# cria o dataset de validação\n",
        "all_input_ids_V, attention_masks_V, segment_ids_V, labels_V = get_input_data(\n",
        "    data_valid, \n",
        "    MAX_LEN\n",
        "    )\n",
        "ds_val = TensorDataset(\n",
        "    all_input_ids_V, \n",
        "    attention_masks_V, \n",
        "    segment_ids_V, \n",
        "    torch.tensor(labels_V)\n",
        "    )\n",
        "\n",
        "#---------------------------------__DATALOADERS__----------------------------------\n",
        "\n",
        "# dataloader é um dict com chave train e val\n",
        "dataloaders = {\n",
        "     'train': DataLoader(\n",
        "         ds_train,\n",
        "         batch_size=BATCH_SZ,\n",
        "         sampler = RandomSampler(ds_train), # Seleciona batches randomicamente\n",
        "         num_workers=4,\n",
        "         pin_memory=True\n",
        "         ),\n",
        "               \n",
        "     'val': DataLoader(\n",
        "         ds_val,\n",
        "         batch_size=BATCH_SZ,\n",
        "         sampler = SequentialSampler(ds_val), # toma batches sequencialmente\n",
        "         num_workers=4,\n",
        "         pin_memory=True\n",
        "         ),\n",
        "     }\n",
        "\n",
        "# teste de sanidade\n",
        "dl_sizes = {x: len(dataloaders[x]) for x in dataloaders.keys()}\n",
        "dl_sizes "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 323, 'val': 75}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRlP5_KcwZpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(preds, labels):\n",
        "\n",
        "    # Toma o label (coluna) com a maior probabilidade\n",
        "    predictions = np.argmax(preds, axis=1).flatten()\n",
        "    labels = labels.flatten()\n",
        "    \n",
        "    # Computa  a acc\n",
        "    accuracy = np.sum(predictions == labels) / len(labels)\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhZRnEfPjTYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, device, train_dataloader, optimizer, scheduler):\n",
        "\n",
        "    # Acumula o a loss do treino e a acuracia\n",
        "    total_loss, train_accuracy = 0, 0\n",
        "    \n",
        "    # conta o num. de batches\n",
        "    num_steps = 0\n",
        "    \n",
        "    # coloca o modelo em modo treino\n",
        "    model.train()\n",
        "    \n",
        "    # Para cada batch no dadaset de treino...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Coloca os tensores na GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Desempacota os inputs do dataloader\n",
        "        b_input_ids, b_input_masks, b_token_type_ids, b_labels = batch\n",
        "        \n",
        "        # Zera os gradientes\n",
        "        model.zero_grad()\n",
        "        \n",
        "        # Forward pass: o modelo irá retornar a loss e os logits\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids = b_token_type_ids,\n",
        "                        attention_mask = b_input_masks,\n",
        "                        labels = b_labels)\n",
        "\n",
        "        # loss e predições\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        \n",
        "        # Move os logits e labels para CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calcula a acuracia do batch\n",
        "        tmp_accuracy = get_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumula a acuracia total\n",
        "        train_accuracy += tmp_accuracy\n",
        "\n",
        "        # Conta os numeros de batches\n",
        "        num_steps += 1\n",
        "\n",
        "        # Accumula a loss de treinamento sobre todos os batches\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Executa o backward pass para calcular os gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Clipa o norma dos gradientes em 1.0, isso previne o problema \"exploding gradients\"\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Atualiza os parametros e toma um step no gradiente calculado\n",
        "        optimizer.step()\n",
        "\n",
        "        # Atualiza o scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calcula a média da loss no conj. de treino\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    avg_acc = train_accuracy/num_steps\n",
        "\n",
        "    return avg_loss, avg_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za93hOsJjTPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_model(model, device, validation_dataloader):\n",
        "\n",
        "    # Coloca o modelo em modo de avaliação\n",
        "    model.eval()\n",
        "\n",
        "    # Acumula a loss do conj. de valid e acuracia\n",
        "    total_loss, eval_accuracy = 0, 0\n",
        "\n",
        "    # conta o num. de batches\n",
        "    num_steps = 0\n",
        "\n",
        "    # Para cada batch no dadaset de treino...\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Coloca os tensores na GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Desempacota os inputs do dataloader\n",
        "        b_input_ids, b_input_masks, b_token_type_ids, b_labels = batch\n",
        "\n",
        "        # Não calcula os gradientes armazenados\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids = b_token_type_ids,\n",
        "                            attention_mask = b_input_masks,\n",
        "                            labels= b_labels)\n",
        "        \n",
        "        # loss e logits\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        \n",
        "        # Move os logits e labels para CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calcula a acuracia para o batch \n",
        "        tmp_eval_accuracy = get_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumula a acuracia total\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Conta o numeto de batches\n",
        "        num_steps += 1\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Calcula a loss e acuracia\n",
        "    avg_loss = total_loss / len(validation_dataloader)\n",
        "    avg_acc = eval_accuracy/num_steps\n",
        "\n",
        "    return avg_loss, avg_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oop4oVSB2kON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'bert-qa': é o BERT do Rodrigo fine-tuned no MS Macro\n",
        "# 'finbert-domain': é o BERT pre-trainado no Araci (grande corpus financeiro)\n",
        "# 'finbert-task': é o BERT re-(pre-treinado) no FIQA\n",
        "\n",
        "bert_qa = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/BERT/FinBERT/models/bert-qa'\n",
        "finbert_domain = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/BERT/FinBERT/models/finbert-domain'\n",
        "finbert_task = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/BERT/FinBERT/models/finbert-task'\n",
        "\n",
        "# Carrega o BertForSequenceClassification - pre-trainado com uma camada linear no final\n",
        "model = BertForSequenceClassification.from_pretrained(finbert_task, cache_dir=None, num_labels=2)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5u6nRQJxqCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5b6320f0-3340-49c4-ec52-944421d449bf"
      },
      "source": [
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "#----------------------------------------------------------------\n",
        "deterministic()\n",
        "N_EPOCHS = 2\n",
        "optimizer = AdamW(model.parameters(), lr = 3e-6, eps = 1e-8)\n",
        "\n",
        "total_steps = len(dataloaders['train']) * N_EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, \n",
        "    num_warmup_steps = 1_000,\n",
        "    num_training_steps = total_steps\n",
        "    )\n",
        "#----------------------------------------------------------------\n",
        "start.record()\n",
        "\n",
        "training_stats = []\n",
        "for epoch_i in range(1, N_EPOCHS+1):\n",
        "    loss_train, acc_train = train_model(\n",
        "        model, \n",
        "        device, \n",
        "        dataloaders['train'], \n",
        "        optimizer, \n",
        "        scheduler\n",
        "        )\n",
        "    loss_val, acc_val = validate_model(\n",
        "        model, \n",
        "        device, \n",
        "        dataloaders['val']\n",
        "        )\n",
        "    \n",
        "    print(f'\\nEpoca [{epoch_i}/{N_EPOCHS}] |', end=' ')\n",
        "    print(f'Loss Treino: {loss_train:.3f} -- Acc Treino: {acc_train:.3f} ---- \\\n",
        "Loss Valid: {loss_val:.3f} -- Acc Valid: {acc_val:.3}')\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i,\n",
        "            'Training Loss': loss_train,\n",
        "            'Training Acc': acc_train,\n",
        "            'Valid Loss': loss_val,\n",
        "            'Valid Acc': acc_val,\n",
        "        }\n",
        "    )\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()    \n",
        "#------------------------------------------------------------------\n",
        "print(f'\\nFEITO!')\n",
        "print(f'Tempo gasto: {start.elapsed_time(end)/1000/60 :.3f} min.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla T4 disponível.\n",
            "\n",
            "Epoca [1/2] | Loss Treino: 0.392 -- Acc Treino: 0.911 ---- Loss Valid: 0.201 -- Acc Valid: 0.963\n",
            "\n",
            "Epoca [2/2] | Loss Treino: 0.111 -- Acc Treino: 0.978 ---- Loss Valid: 0.115 -- Acc Valid: 0.965\n",
            "\n",
            "FEITO!\n",
            "Tempo gasto: 12.945 min.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmWzkAfaXKQp",
        "colab_type": "text"
      },
      "source": [
        "## Log do treino em dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhvKvyeBXNvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "ececb5ab-43c1-47ea-c728-d204a3a56f0d"
      },
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "pd.set_option('precision', 3)\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Training Acc</th>\n",
              "      <th>Valid Loss</th>\n",
              "      <th>Valid Acc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.392</td>\n",
              "      <td>0.911</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.111</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.965</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Training Acc  Valid Loss  Valid Acc\n",
              "epoch                                                    \n",
              "1              0.392         0.911       0.201      0.963\n",
              "2              0.111         0.978       0.115      0.965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Qppb1-nvRg",
        "colab_type": "text"
      },
      "source": [
        "# Avaliação dos resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6npVgMDNewIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, q_text, cands, max_seq_len=MAX_LEN):\n",
        "    \"\"\"\n",
        "    Re-ranqueia as respostas dos candidatos para cada pergunta.\n",
        "\n",
        "     Retorna:\n",
        "         ranked_ans: lista de docids candidatos re-classificados\n",
        "         sorted_scores: lista de pontuações de relevância das respostas\n",
        "     -------------------\n",
        "     Argumentos:\n",
        "         model - modelo PyTorch\n",
        "         q_text - str - query\n",
        "         cands - Lista de docids candidatos\n",
        "         max_seq_len - int\n",
        "     \"\"\"\n",
        "    # Converte a lista para numpy\n",
        "    cands_id = np.array(cands)\n",
        "    \n",
        "    scores = []\n",
        "    # Para cada respostas em cands...\n",
        "    for docid in cands:\n",
        "        # Mapeia o docid para o texto\n",
        "        ans_text = docid_to_text[docid]\n",
        "        # Cria os inputs para o modelo\n",
        "        encoded_seq = tokenizer.encode_plus(\n",
        "            q_text, \n",
        "            ans_text,\n",
        "            max_length=max_seq_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_attention_mask = True\n",
        "            )\n",
        "\n",
        "        input_ids = torch.tensor([encoded_seq['input_ids']]).to(device)\n",
        "        token_type_ids = torch.tensor([encoded_seq['token_type_ids']]).to(device)\n",
        "        att_mask = torch.tensor([encoded_seq['attention_mask']]).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calcula as predições/logit para cada par QA\n",
        "            outputs = model(\n",
        "                input_ids, \n",
        "                attention_mask=att_mask,\n",
        "                token_type_ids=token_type_ids, \n",
        "                )\n",
        "        \n",
        "        # predições\n",
        "        logits = outputs[0]\n",
        "        \n",
        "        # Aplica a softmax\n",
        "        pred = softmax(logits, dim=1)\n",
        "        \n",
        "        # Move os logits e labels para CPU\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        \n",
        "        # Anexa os scores relevantes para lista (onde label = 1)\n",
        "        scores.append(pred[:,1][0])\n",
        "        \n",
        "        # Obtenha os índices dos scores de similaridade ordenados\n",
        "        sorted_index = np.argsort(scores)[::-1]\n",
        "        \n",
        "        # Obtenha uma lista de docid vindo dos indices ordenados\n",
        "        ranked_ans = list(cands_id[sorted_index])\n",
        "        sorted_scores = list(np.around(sorted(scores, reverse=True),decimals=3))\n",
        "\n",
        "    return ranked_ans, sorted_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRSvaM8BEvH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rank(model, test_set, max_seq_len=MAX_LEN):\n",
        "    \"\"\"\n",
        "    Re-ranqueia as respostas candidatas para cada pergunta.\n",
        "\n",
        "     Retorna:\n",
        "         qid_pred_rank: Dicionário\n",
        "             key - qid\n",
        "             value - lista de candidatos re-ranqueados\n",
        "     -------------------\n",
        "     Argumentos:\n",
        "         model - modelo PyTorch\n",
        "         test_set Lista de listas\n",
        "         max_seq_len - int\n",
        "     \"\"\"\n",
        "    \n",
        "    qid_pred_rank = {}\n",
        "    \n",
        "    # Configura o modelo para o modo evaluation\n",
        "    model.eval()\n",
        "    \n",
        "    # Para cada elmento no conj. de test\n",
        "    for i, seq in enumerate(test_set):\n",
        "        qid, label, cands = seq[0], seq[1], seq[2]\n",
        "        # Mapeia o id da questão para o texto\n",
        "        q_text = qid_to_text[qid]\n",
        "\n",
        "        # Lista de docids re-ranqueados com suas correspondentes probabilidades\n",
        "        ranked_ans, sorted_scores = predict(model, q_text, cands, max_seq_len)\n",
        "\n",
        "        # Dicionaro com key=qid e value=lista ranqueada de docids\n",
        "        qid_pred_rank[qid] = ranked_ans\n",
        "\n",
        "    return qid_pred_rank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87o1pY7xUZUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rel(labels, cands):\n",
        "    \"\"\"\n",
        "    Obtem posições relevantes dos acertos.\n",
        "\n",
        "     Retorna: Lista de 0s e 1s que incidem em uma resposta relevante\n",
        "     -------------------\n",
        "     Argumentos:\n",
        "         labels: lista de docids relevantes\n",
        "         cands: Lista de candidatos a docids\n",
        "     \"\"\"\n",
        "    rel = []\n",
        "    for cand in cands:\n",
        "        if cand in labels:\n",
        "            rel.append(1)\n",
        "        else:\n",
        "            rel.append(0)\n",
        "\n",
        "    return rel\n",
        "\n",
        "def dcg(rels, k):\n",
        "    \"\"\"\n",
        "     Ganho cumulativo com desconto. Calcula o DCG acumulado do top-k\n",
        "     documentos relevantes em todas as queries.\n",
        "\n",
        "     Retorna:\n",
        "         cumulated_sum: float - DCG acumulado\n",
        "     ----------\n",
        "     Argumentos:\n",
        "         rels: lista\n",
        "             Lista de pontuações relevantes de 0 ou 1, por exemplo [0, 1, 0, 1]\n",
        "         k: int\n",
        "             Top-k documentos relevantes\n",
        "     \"\"\"\n",
        "    cumulated_sum = rels[0]\n",
        "    for i in range(1, k):\n",
        "        cumulated_sum += rels[i]/math.log(i+1,2)\n",
        "    return cumulated_sum\n",
        "\n",
        "def avg_ndcg(rel_score, k):\n",
        "    \"\"\"\n",
        "     Ganho Cumulativo Descontado Normalizado Médio. Calcula o DCG, iDCG e\n",
        "     nDCG para cada consulta e retorna o nDCG médio em todas as queries.\n",
        "\n",
        "     Retorna:\n",
        "         avg: float - nDCG médio\n",
        "     ----------\n",
        "     Argumentos:\n",
        "         rel_score: dicionário\n",
        "             chave - id da pergunta\n",
        "             valor - lista de pontuações de relevância com 1 (relevante) e 0 (irrelevante)\n",
        "             por exemplo. {0: [0, 1, 0], 1: [1, 1, 0]}\n",
        "         k: int\n",
        "             Top-k documentos relevantes\n",
        "     \"\"\"\n",
        "    ndcg_list = []\n",
        "    for qid, rels in rel_score.items():\n",
        "        # Computa DCG para cada pergunta\n",
        "        dcg_val = dcg(rels, k)\n",
        "        sorted_rel = sorted(rels, reverse=True)\n",
        "        # Computa iDCG para cada pergunta\n",
        "        idcg_val = dcg(sorted_rel, k)\n",
        "\n",
        "        try:\n",
        "            ndcg_val = dcg_val/idcg_val\n",
        "            ndcg_list.append(ndcg_val)\n",
        "        except ZeroDivisionError:\n",
        "            ndcg_list.append(0)\n",
        "\n",
        "    assert len(ndcg_list) == len(rel_score), \"Pontuação relevante não casa/combina\"\n",
        "\n",
        "    # Obtem a média nDCG para todas queries\n",
        "    avg = mean(ndcg_list)\n",
        "\n",
        "    return avg\n",
        "\n",
        "def compute_RR(cand_docs, rel_docs, cumulated_reciprocal_rank, rank_pos, k):\n",
        "   \"\"\"\n",
        "     Calcula a classificação recíproca - probabilidade de correção da classificação. \n",
        "     Retorna a classificação recíproca acumulada em todas as queries e as posições do\n",
        "     documentos relevantes nos candidatos.\n",
        "\n",
        "     Retorna:\n",
        "         cumulated_reciprocal_rank: float - classificação recíproca acumulada em \n",
        "         todas as queries\n",
        "         rank_pos: list - índice dos documentos relevantes nos candidatos\n",
        "     ----------\n",
        "     Argumentos:\n",
        "         cand_docs: list\n",
        "             Lista de docids classificados para uma pergunta\n",
        "         rel_docs: list\n",
        "             Lista da relevância dos docids para uma pergunta\n",
        "         cumulated_reciprocal_rank: int\n",
        "             Valor inicial = 0\n",
        "         rank_pos: list\n",
        "             Lista inicial = []\n",
        "         k: int\n",
        "             Top-k documentos relevantes\n",
        "     \"\"\"\n",
        "\n",
        "    for i in range(0, k):\n",
        "        # Se o doc_id do top-k passagens candidatas com melhor classificação estiver \n",
        "        # na lista de passagens relevantes\n",
        "        if cand_docs[i] in rel_docs:\n",
        "            # Computa a classificação recíproca (i é a classificação)\n",
        "            rank_pos.append(i+1)\n",
        "            cumulated_reciprocal_rank += 1/(i+1)\n",
        "            break\n",
        "\n",
        "    return cumulated_reciprocal_rank, rank_pos\n",
        "\n",
        "def create_qid_pred_rank(test_set):\n",
        "    \"\"\"\n",
        "     Cria dicionário de qid e lista de candidatos do conjunto de teste.\n",
        "\n",
        "     Retorna:\n",
        "         qid_pred_rank: dicionário\n",
        "             chave - qid\n",
        "             valor - lista de candidatos\n",
        "     ----------\n",
        "     Argumentos:\n",
        "         test_set: list\n",
        "             [[qid, [docids positivos], [lista de candidatos]]]\n",
        "     \"\"\"\n",
        "    qid_pred_rank = {}\n",
        "\n",
        "    for row in test_set:\n",
        "        qid_pred_rank[row[0]] = row[2]\n",
        "\n",
        "    return qid_pred_rank\n",
        "\n",
        "def evaluate(qid_ranked_docs, qid_rel, k):\n",
        "    \"\"\"\n",
        "     Calcula o MRR@k, nDCG@k médio e precision@k1\n",
        "\n",
        "     Retorna:\n",
        "         MRR: float\n",
        "         average_ndcg: float\n",
        "         avg_precision: float\n",
        "         r_pos: int\n",
        "     ----------\n",
        "     Argumentos:\n",
        "         qid_ranked_docs: dicionário\n",
        "             chave - qid\n",
        "             valor - lista de cand ans\n",
        "         qid_rel: dicionario\n",
        "             key- qid\n",
        "             valor - lista de documentos relevantes\n",
        "     \"\"\"\n",
        "    \n",
        "    cumulated_reciprocal_rank, num_rel_docs = 0,0\n",
        "    rel_scores, precision_list = {}, {}\n",
        "    rank_pos = []\n",
        "\n",
        "    # Para cada query...\n",
        "        for qid in qid_ranked_docs:\n",
        "        # Se a query é relevante\n",
        "        if qid in qid_rel:\n",
        "            # Obtem a  lista de docs relevantes para uma query\n",
        "            rel_docs = qid_rel[qid]\n",
        "            # Obtem a lista de documentos classificados para uma query\n",
        "            cand_docs = qid_ranked_docs[qid]\n",
        "            # Computa o score dos candidatos\n",
        "            if qid not in rel_scores:\n",
        "                rel_scores[qid] = []\n",
        "                for i in range(0, k):\n",
        "                    if cand_docs[i] in rel_docs:\n",
        "                        rel_scores[qid].append(1)\n",
        "                    else:\n",
        "                        rel_scores[qid].append(0)\n",
        "            # Computa a i-ésima classificação reciproca e posição de classificação\n",
        "            cumulated_reciprocal_rank, r_pos = compute_RR(\n",
        "                cand_docs, \n",
        "                rel_docs, \n",
        "                cumulated_reciprocal_rank, \n",
        "                rank_pos, k\n",
        "                )\n",
        "    \n",
        "    # Computa o MRR@k\n",
        "    MRR = cumulated_reciprocal_rank/len(qid_ranked_docs)\n",
        "    # Computa o nDCG@k\n",
        "    average_ndcg = avg_ndcg(rel_scores, k)\n",
        "\n",
        "    # Computa precision@1\n",
        "    precision_at_k = []\n",
        "    for qid, score in rel_scores.items():\n",
        "        num_rel = 0\n",
        "        for i in range(0, 1):\n",
        "            if score[i] == 1:\n",
        "                num_rel += 1\n",
        "        precision_at_k.append(num_rel/1)\n",
        "    \n",
        "    avg_precision = mean(precision_at_k)\n",
        "\n",
        "    return MRR, average_ndcg, avg_precision, r_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQb8GDWk-otV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "da4fb7bd-18c9-42d3-e7cc-b316e7d4775e"
      },
      "source": [
        "qid_pred_rank = get_rank(model, data_valid, 384)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z66Ro7SsAEYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ef29e9cc-a3e7-4315-dd7d-b7976459f2ac"
      },
      "source": [
        "k = 10\n",
        "num_q = len(data_valid)\n",
        "\n",
        "MRR, average_ndcg, precision, rank_pos = evaluate(qid_pred_rank, labels_valid, k)\n",
        "\n",
        "print(f'\\nAverage nDCG@{k} for {num_q} queries: {average_ndcg:.3f}')\n",
        "print(f'MRR@{k} for {num_q} queries: {MRR:.3f}')\n",
        "print(f'Average Precision@1 for {num_q} queries: {precision:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average nDCG@10 for 30 queries: 0.718\n",
            "MRR@10 for 30 queries: 0.679\n",
            "Average Precision@1 for 30 queries: 0.600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ0vrEj5z0QM",
        "colab_type": "text"
      },
      "source": [
        "# Analise do predict\n",
        "\n",
        "#### `df_docs_cos` é um dataframe obtido por similaridade de cossenos entre todos os documentos, logo os cands serão os `docs` que possuirém maior similaridade com o `qid`. A similaridade foi obtida com o distilUSE do UKPLab-[SBERT](https://www.sbert.net/docs/pretrained_models.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JVnd3Ct4mxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pickle_file(path, data=None):\n",
        "    if data is None:\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    if data is not None:\n",
        "        with open(path, 'wb') as handle:\n",
        "            pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# carregando o dataframe\n",
        "path_df_cos = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/BERT/FinBERT/df_docs_cos'\n",
        "df_docs_cos = pickle_file(path_df_cos)\n",
        "\n",
        "# ordenando pelo score decrescente da similaridade de cosseno\n",
        "df_docs_cos = df_docs_cos.sort_values(by='COS_SIM', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# criando uma lista com esses documentos pela col. ID2\n",
        "remove_equals_docs = df_docs_cos[0:6].ID2.to_list()\n",
        "\n",
        "# esses documentos não podem ser labels para nenhuma qid, logo len = 0\n",
        "assert len(df_labels_sub[df_labels_sub.docid.isin(remove_equals_docs)]) == 0\n",
        "\n",
        "# removendo\n",
        "df_docs_cos = df_docs_cos[~df_docs_cos.ID2.isin(remove_equals_docs)]\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "def make_cands_with_cos_sim(df, number_of_cands=30):\n",
        "    # num. de candidatos por amostra\n",
        "    K = number_of_cands\n",
        "\n",
        "    # dataset \n",
        "    df_ = df.copy() # cols: df[['qid'], ['docid']]\n",
        "\n",
        "    # lista que armazenará o shape final do dataset\n",
        "    data = []\n",
        "\n",
        "    # candidatos a resposta\n",
        "    cands_dataset = []\n",
        "\n",
        "    # para cada linha do df...\n",
        "    for i, row_data in enumerate(df_.iterrows()):\n",
        "\n",
        "        # se existe mais de um rel. doc por qid...\n",
        "        if len(row_data[1].docid) > 1:\n",
        "\n",
        "            # conta quantos exemplos de cada id está sendo anexado\n",
        "            sum = 0\n",
        "            # num. de exemplos por amostra - forma de balancear os candidatos\n",
        "            samples_per_doc = int(K/len(row_data[1].docid)-1)\n",
        "            \n",
        "            # lista que armazena os docs candidatos\n",
        "            cands_dataset = []\n",
        "\n",
        "            # para cada elem. na lista de docs candidatos\n",
        "            for j, elem in enumerate(row_data[1].docid, 1): \n",
        "\n",
        "                if j != len(row_data[1].docid):\n",
        "                    # soma a quantidade de docs cands. anexado\n",
        "                    sum += samples_per_doc\n",
        "                    # checamos se existe docs cands. suficiente\n",
        "                    len_sample = len(df_docs_cos[df_docs_cos.ID1 == elem]\\\n",
        "                                     [:samples_per_doc].ID2.to_list())\n",
        "\n",
        "                    # se não existir amostras suficientes, faz um sorteio de \n",
        "                    # samples_per_doc docs cands\n",
        "                    if len_sample < samples_per_doc:\n",
        "                        docs_choice = list(np.random.choice(\n",
        "                            df_docs_cos.ID2, 2 * samples_per_doc, replace=False))\n",
        "                        cands_dataset.extend(docs_choice)\n",
        "\n",
        "                    else: # caso exista o num. suficiente anexamos os que possuem \n",
        "                          # maior pontuação de cosseno\n",
        "\n",
        "                        # anexa os docs candidatos para j < len(row_data[1].docid)\n",
        "                        cands_dataset.extend(df_docs_cos[df_docs_cos.ID1 == elem]\\\n",
        "                                             [:samples_per_doc].ID2.to_list())\n",
        "                        # conta quntos docs foram anexados\n",
        "                \n",
        "                # para o último elem da lista de respostas\n",
        "                if j == len(row_data[1].docid):\n",
        "                    len_sample = len(df_docs_cos[df_docs_cos.ID1 == elem]\\\n",
        "                                     [:samples_per_doc].ID2.to_list())\n",
        "                    \n",
        "                    # se j é o último elem. da lista, completa os cands com o rest\n",
        "                    rest = K - sum\n",
        "                    \n",
        "                    # se não existir amostras suficientes, faz um sorteio de \n",
        "                    # restr docs cands\n",
        "                    if len_sample < rest:\n",
        "                        docs_choice = list(np.random.choice(\n",
        "                            df_docs_cos.ID2, 2 * rest, replace=False))\n",
        "                        cands_dataset.extend(docs_choice)\n",
        "\n",
        "                    else: # caso exista o num. suficiente anexamos os que possuem \n",
        "                          # maior pontuação de cosseno\n",
        "                        cands_dataset.extend(df_docs_cos[df_docs_cos.ID1 == elem]\\\n",
        "                                             [:rest].ID2.to_list())\n",
        "\n",
        "        if len(row_data[1].docid) == 1:\n",
        "            len_sample = df_docs_cos[\n",
        "                df_docs_cos.ID1.isin(row_data[1].docid)].ID2.to_list()[:K]\n",
        "\n",
        "            if len(len_sample) < K:\n",
        "                docs_choice = list(np.random.choice(\n",
        "                    df_docs_cos.ID2, 2 * K, replace=False))\n",
        "                cands_dataset.extend(docs_choice)\n",
        "\n",
        "            else:\n",
        "                cands_dataset.extend(df_docs_cos[df_docs_cos.ID1 == row_data[1].qid]\\\n",
        "                                     [:K].ID2.to_list())\n",
        "\n",
        "        # anexa os labels no inicio do conj. dos docs candidatos e trunca em K\n",
        "        cands = list(set(row_data[1].docid + cands_dataset))\n",
        "\n",
        "        # embaralha a lista\n",
        "        cands = random.sample(cands, len(cands))[:K]\n",
        "        data.append([row_data[1].qid, row_data[1].docid, cands])\n",
        "        \n",
        "    return data # list [[qid], [labels], [cands]]    \n",
        "\n",
        "#-----------------------------------------------------------\n",
        "valid_cands_cos = make_cands_with_cos_sim(valid_data, 40)\n",
        "print(f'Valid. candidatas: {len(valid_cands_cos)}')        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYyELZH2FNGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "5ea45d2d-f87d-4de4-c96d-fc782ec8730d"
      },
      "source": [
        "N = np.random.randint(0, len(valid_cands_cos))\n",
        "\n",
        "# Exemplo escolhido aletóriamente com cadas escolhidos por similaridade de cosseno\n",
        "seq = valid_cands_cos[N]\n",
        "qid, label, cands = seq[0], seq[1], seq[2]\n",
        "q_text = qid_to_text[qid]\n",
        "query = q_text\n",
        "\n",
        "#---------------------------------------------------------\n",
        "model.eval()\n",
        "# Re-classifica os candidatos\n",
        "rank, scores = predict(model, query, cands, MAX_LEN)\n",
        "\n",
        "# Top-k respostas\n",
        "k = 5\n",
        "\n",
        "print(f'\\nQuery:\\n\\t{query}\\n')\n",
        "print(f'Top-{k} Answers: \\n')\n",
        "for i in range(0, k):\n",
        "    print(f'{i+1} docid: {rank[i]:>6} -- text: {docid_to_text[rank[i]]}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Query:\n",
            "\tWhy are U.S. credit unions not open to everyone?\n",
            "\n",
            "Top-5 Answers: \n",
            "\n",
            "1 docid: 155634 -- text: It's required by law.  12 USC 1759 (b) requires that membership in a credit union be limited to one or more groups with a \"common bond\", or to people within a particular geographic area. For lots more gory details on how this is interpreted and enforced, you can read the manual given to credit unions by the National Credit Union Administration, which is their regulatory agency.\n",
            "\n",
            "2 docid: 269447 -- text: Credit unions are mutually-owned (i.e. customer owned) financial institutions that provide banking services.  They take deposits from their members (customers) and loan them to other members.  Members vote on a board of directors who manage operations.   They are considered not-for-profit, but they pay interest on deposits.  They get some preferential tax treatment and regulation and their deposits are insured by a separate organization if federally accredited.  State-chartered credit unions don't have to maintain deposit insurance at all.   Their charters specify who can join.  They can be regionally based, employer based, or based on some other group with common interests.  Regulators restrict them so that they don't interfere too much with banks.  Otherwise their preferential tax and regulatory treatment would leave banks uncompetitive.   Other organizations with similar limits have gone on to be competitive when the limits were released.  For example, there used to be an insurance company just for government employees, the Government Employees Insurance Company.  You may know it better as GEICO (yes, the one with the gecko advertisements).  Now they offer life and auto insurance all over.   Credit unions would like looser limitations (or no limitations at all), but not enough to give up their preferential tax treatment.  Banks oppose looser limitations and have as much political clout as credit unions.\n",
            "\n",
            "3 docid:   5644 -- text: Your instructor's numbers do not seem to have any basis in current reality. At this page you can see a comparison of interest rates offered by banks and credit unions.  In the most recent table for June 2014, banks paid an average interest rate of 0.12 percent on savings accounts, while credit unions paid an average of 0.13 percent.   If you look back further, you will see that interest rates paid by banks and credit unions are generally comparable.  Credit union rates tend to be a little bit higher, but certainly not 7 times higher. The last time any financial institution paid as much as 15% on a savings account would probably be the early 1980s.  You can see here a historical chart of the \"prime rate\" for lending.  Savings account rates (at either banks or credit unions) would typically be lower. (This is based on the US, in accordance with your tag.  Interest rates in other places, especially developing countries with less stable currencies, can be dramatically different.)\n",
            "\n",
            "4 docid:  16586 -- text: this post offers valuable information we can all use when scouting for frequent flyer credit cards. let's all support this post of my friend, sean travis, by reading and sharing it to all our friends and followers in different social networking sites.\n",
            "\n",
            "5 docid:  20797 -- text: KIRO Studios provides photography services to suit your every need. Enjoy and preserve your next event with stunning Photography Ottawa that will last a lifetime. With KIRO Studios, you can be assured that you are getting the quality photography you seek and peace of mind you deserve.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaJ2pIvnuTYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "dbe961e3-37b6-4abe-8a02-c02e14d2b649"
      },
      "source": [
        "df_labels[df_labels.qid==qid]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>493</td>\n",
              "      <td>269447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>493</td>\n",
              "      <td>155634</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     qid   docid\n",
              "277  493  269447\n",
              "278  493  155634"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_0nDkgywV7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "c1b52e4d-2a74-42f1-decf-c235781027fa"
      },
      "source": [
        "df_questions[df_questions.qid==qid]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>493</td>\n",
              "      <td>Why are U.S. credit unions not open to everyone?</td>\n",
              "      <td>Feb 19 at 21:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     qid                                          question        timestamp\n",
              "148  493  Why are U.S. credit unions not open to everyone?  Feb 19 at 21:04"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OazQ-1o929se",
        "colab_type": "text"
      },
      "source": [
        "# FIM"
      ]
    }
  ]
}