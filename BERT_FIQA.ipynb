{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT FIQA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cccbd88d0a514f3c80727df398f242cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7cc184ea343c44d2adf1dedf36a386bf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e52c0d8b891a4904bd1f8416168b4eb6",
              "IPY_MODEL_1b627b5979ba4fc9a779b28d7b110898"
            ]
          }
        },
        "7cc184ea343c44d2adf1dedf36a386bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e52c0d8b891a4904bd1f8416168b4eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_12a2eb4de495477987cccaa491e2a24a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb1c06e048df47cd8867b88871be08dc"
          }
        },
        "1b627b5979ba4fc9a779b28d7b110898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ede1fe7ba4474a05a052c26c15d842bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 968kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8627393393ce4bafbf91bf5b15ce2f65"
          }
        },
        "12a2eb4de495477987cccaa491e2a24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb1c06e048df47cd8867b88871be08dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ede1fe7ba4474a05a052c26c15d842bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8627393393ce4bafbf91bf5b15ce2f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/tutos/blob/master/BERT_FIQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0aSsmftY7wz",
        "colab_type": "text"
      },
      "source": [
        "# Dataset FiQA\n",
        "> [Link do dataset](https://sites.google.com/view/fiqa/home?authuser=0)\n",
        "\n",
        "Inspirado no github:\n",
        "> [Yuanbit](https://github.com/yuanbit/FinBERT-QA/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYZP7bc84ar3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3456d9b7-d41a-47f1-824a-0e40757469b9"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 5.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 17.4MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 60.9MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 50.8MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYk-8I2xZCDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b9b9f67b-eced-469b-f4dd-23b1f97eb45c"
      },
      "source": [
        "# basic\n",
        "import os\n",
        "import math \n",
        "import pickle\n",
        "import random\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statistics import mean\n",
        "from itertools import combinations\n",
        "\n",
        "# plot\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "from torch.utils.data import random_split, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "# transformers\n",
        "from transformers import (BertTokenizer, BertForSequenceClassification, \n",
        "                          AdamW, get_linear_schedule_with_warmup, BertConfig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsAqDQ3wt7Gy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7550aad-5dcf-4413-a62f-837d1ae8c240"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "manual_seed = 2357\n",
        "\n",
        "def deterministic(rep=True):\n",
        "    if rep:\n",
        "        np.random.seed(manual_seed)\n",
        "        torch.manual_seed(manual_seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(manual_seed)\n",
        "            torch.cuda.manual_seed_all(manual_seed)\n",
        "        torch.backends.cudnn.enabled = False \n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(f'Experimento deterministico, seed: {manual_seed} -- ', end = '')\n",
        "        print(f'Existe {torch.cuda.device_count()} GPU {torch.cuda.get_device_name(0)} disponÃ­vel.')\n",
        "    else:\n",
        "        print('Experimento randomico')\n",
        "\n",
        "deterministic()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla T4 disponÃ­vel.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2ltuOvUisG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "cccbd88d0a514f3c80727df398f242cf",
            "7cc184ea343c44d2adf1dedf36a386bf",
            "e52c0d8b891a4904bd1f8416168b4eb6",
            "1b627b5979ba4fc9a779b28d7b110898",
            "12a2eb4de495477987cccaa491e2a24a",
            "fb1c06e048df47cd8867b88871be08dc",
            "ede1fe7ba4474a05a052c26c15d842bc",
            "8627393393ce4bafbf91bf5b15ce2f65"
          ]
        },
        "outputId": "81be8f2d-a585-4996-eef2-1ee8ddfee0d2"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cccbd88d0a514f3c80727df398f242cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMh9iElXjvLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c1cb97e-6099-4a2d-bdc6-5fad5a81cead"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71tLRWFtZDEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "be29c771-2c35-45c2-b457-27ac38fe26a0"
      },
      "source": [
        "path_dataset = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/BERT/FinBERT/data/raw/'\n",
        "\n",
        "df_questions = pd.read_csv(path_dataset+'FiQA_train_question_final.tsv', sep='\\t', index_col=0)\n",
        "df_docs = pd.read_csv(path_dataset+'FiQA_train_doc_final.tsv', sep='\\t', index_col=0)\n",
        "df_labels = pd.read_csv(path_dataset+'FiQA_train_question_doc_final.tsv', sep='\\t', index_col=0)\n",
        "\n",
        "print(f'Shape do dataset das questions: {df_questions.shape:}')\n",
        "print(f'Shape do dataset dos docs:      {df_docs.shape}')\n",
        "print(f'Shape do dataset das labels:    {df_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape do dataset das questions: (6648, 3)\n",
            "Shape do dataset dos docs:      (57638, 3)\n",
            "Shape do dataset das labels:    (17110, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zQx21__amQ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "83d9dc10-a9a0-4b4d-e3b5-ede68776e66b"
      },
      "source": [
        "df_questions.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What is considered a business expense on a bus...</td>\n",
              "      <td>Nov 8 '11 at 15:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Claiming business expenses for a business with...</td>\n",
              "      <td>May 13 '14 at 13:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Transferring money from One business checking ...</td>\n",
              "      <td>Jan 20 '16 at 20:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qid                                           question            timestamp\n",
              "0    0  What is considered a business expense on a bus...   Nov 8 '11 at 15:14\n",
              "1    1  Claiming business expenses for a business with...  May 13 '14 at 13:17\n",
              "2    2  Transferring money from One business checking ...  Jan 20 '16 at 20:31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5NZi9i-ZJQN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "6a6382c3-ef6f-45ae-9f69-c256d0fe41e3"
      },
      "source": [
        "df_docs.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>doc</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>I'm not saying I don't like the idea of on-the...</td>\n",
              "      <td>Oct 03 '12 at 14:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31</td>\n",
              "      <td>So nothing preventing false ratings besides ad...</td>\n",
              "      <td>Sep 01 '17 at 13:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56</td>\n",
              "      <td>You can never use a health FSA for individual ...</td>\n",
              "      <td>Jun 9 '14 at 17:37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   docid  ...            timestamp\n",
              "0      3  ...  Oct 03 '12 at 14:56\n",
              "1     31  ...  Sep 01 '17 at 13:36\n",
              "2     56  ...   Jun 9 '14 at 17:37\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxcBZYF5aeGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "1b87e984-e925-47ab-932f-102c044300fb"
      },
      "source": [
        "df_labels.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>14255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>308938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qid   docid\n",
              "0    0   18850\n",
              "1    1   14255\n",
              "2    2  308938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at_GmgPpmpdt",
        "colab_type": "text"
      },
      "source": [
        "# Subamostragem\n",
        "> um pedaÃ§o do dataset, motivo: conseguir treinar mais rÃ¡pido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqYIDCfYpDvU",
        "colab_type": "text"
      },
      "source": [
        "### Subsamostragem das labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-JPB26smsmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "1f3af54a-8bb3-441d-c92d-a88798bb0616"
      },
      "source": [
        "df_labels_sub = df_labels[:300] \n",
        "\n",
        "questions_sub = list(set(df_labels_sub.qid.to_list()))\n",
        "docs_rel = list(set(df_labels_sub.docid.to_list()))\n",
        "print(f'Qtde de questions subsampling: {len(questions_sub)}')\n",
        "print(f'Qtde de docs rel. subsampling: {len(docs_rel)}')\n",
        "\n",
        "print(f'df_labels_sub shape: {df_labels_sub.shape}\\n')\n",
        "df_labels_sub.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Qtde de questions subsampling: 160\n",
            "Qtde de docs rel. subsampling: 300\n",
            "df_labels_sub shape: (300, 2)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>18850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>14255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>308938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qid   docid\n",
              "0    0   18850\n",
              "1    1   14255\n",
              "2    2  308938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifGodLsao9z5",
        "colab_type": "text"
      },
      "source": [
        "### Subsamostragem dos documentos/respostas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90vSst_emseW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "8f787f56-791b-4ca8-9c41-d9db042bb229"
      },
      "source": [
        "# docs irrelevantes (nÃ£o Ã© reposta de nenhum qid)\n",
        "noise_docs = df_docs[~df_docs.docid.isin(docs_rel)][:2000]\n",
        "\n",
        "# docs relevantes Ã© reposta de alguma qid\n",
        "docs_with_answer = df_docs[df_docs.docid.isin(docs_rel)]\n",
        "\n",
        "# subsampling docs: (docs rel. + docs irrel.)\n",
        "df_docs_sub = pd.concat((docs_with_answer, noise_docs), axis=0)\n",
        "\n",
        "# dict com codid -> doc\n",
        "docid_to_text = {k:v for k,v in zip(df_docs.docid.to_list(), df_docs.doc.to_list())}\n",
        "print(f'df_docs_sub shape: {df_docs_sub.shape}')\n",
        "df_docs_sub.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_docs_sub shape: (2300, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>doc</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>13013</td>\n",
              "      <td>There are a number of mutual funds which claim...</td>\n",
              "      <td>Aug 25 '15 at 20:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1338</th>\n",
              "      <td>14255</td>\n",
              "      <td>Yes you can claim your business deductions if ...</td>\n",
              "      <td>May 14 '14 at 8:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>18792</td>\n",
              "      <td>You are confining the way you and the other co...</td>\n",
              "      <td>Feb 20 at 22:47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      docid  ...            timestamp\n",
              "1230  13013  ...  Aug 25 '15 at 20:04\n",
              "1338  14255  ...   May 14 '14 at 8:07\n",
              "1795  18792  ...      Feb 20 at 22:47\n",
              "\n",
              "[3 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G5hWPtiBqBpg"
      },
      "source": [
        "### Subsamostragem das questÃµes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D9eoOM9JqBpm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "044a46b3-f8a6-4d12-ab31-d6909fa93980"
      },
      "source": [
        "df_questions_sub = df_questions[df_questions.qid.isin(questions_sub)]\n",
        "\n",
        "# dict com qid -> question\n",
        "qid_to_text = {k:v for k,v in zip(df_questions.qid.to_list(), df_questions.question.to_list())}\n",
        "print(f'df_questions_sub shape: {df_questions_sub.shape}')\n",
        "df_questions_sub.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_questions_sub shape: (160, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What is considered a business expense on a bus...</td>\n",
              "      <td>Nov 8 '11 at 15:14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Claiming business expenses for a business with...</td>\n",
              "      <td>May 13 '14 at 13:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Transferring money from One business checking ...</td>\n",
              "      <td>Jan 20 '16 at 20:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   qid                                           question            timestamp\n",
              "0    0  What is considered a business expense on a bus...   Nov 8 '11 at 15:14\n",
              "1    1  Claiming business expenses for a business with...  May 13 '14 at 13:17\n",
              "2    2  Transferring money from One business checking ...  Jan 20 '16 at 20:31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPvKVKysmr_D",
        "colab_type": "text"
      },
      "source": [
        "# Prep data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d97wg7X-2iuu",
        "colab_type": "text"
      },
      "source": [
        "## Agrupando os labels por qid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IspWgUXY2imL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "779fecd3-f222-463c-ee81-493dce638a8d"
      },
      "source": [
        "df_labels_sub = df_labels_sub.assign(qid = df_labels_sub.qid.apply(lambda x: int(x)))\n",
        "df_labels_sub = df_labels_sub.assign(docid = df_labels_sub.docid.apply(lambda x: int(x)))\n",
        "\n",
        "labels_group = df_labels_sub.groupby(['qid']).agg(lambda x: tuple(x)).applymap(list).reset_index()\n",
        "\n",
        "TRAIN_SIZE = 130 # simples slit do dataset\n",
        "\n",
        "train_data = labels_group[:TRAIN_SIZE]\n",
        "labels_train = {k:v for k,v in zip(train_data.qid.to_list(), train_data.docid.to_list())}\n",
        "\n",
        "valid_data = labels_group[TRAIN_SIZE:] \n",
        "labels_valid = {k:v for k,v in zip(valid_data.qid.to_list(), valid_data.docid.to_list())}\n",
        "\n",
        "train_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[18850]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[14255]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[308938]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[296717, 100764, 314352, 146317]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[196463]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>468</td>\n",
              "      <td>[498927, 536760]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>469</td>\n",
              "      <td>[250939, 549432]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>470</td>\n",
              "      <td>[45078]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>471</td>\n",
              "      <td>[158122, 494625]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>472</td>\n",
              "      <td>[337071]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     qid                             docid\n",
              "0      0                           [18850]\n",
              "1      1                           [14255]\n",
              "2      2                          [308938]\n",
              "3      3  [296717, 100764, 314352, 146317]\n",
              "4      4                          [196463]\n",
              "..   ...                               ...\n",
              "125  468                  [498927, 536760]\n",
              "126  469                  [250939, 549432]\n",
              "127  470                           [45078]\n",
              "128  471                  [158122, 494625]\n",
              "129  472                          [337071]\n",
              "\n",
              "[130 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WfovQic_PYS",
        "colab_type": "text"
      },
      "source": [
        "#### Se o docid para uma query possui mais de um elemento na lista, vamos sortear as respostas candidadas com relaÃ§Ã£o ao tamanho da lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HImUUdmkMO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14c191b3-0e81-414b-e524-a4b5b40f9be5"
      },
      "source": [
        "def make_dataset(df, number_of_cands=30):\n",
        "    # num. de candidatos por amostra\n",
        "    K = number_of_cands\n",
        "\n",
        "    # dataset \n",
        "    df_ = df.copy() # cols: df[['qid'], ['docid']]\n",
        "\n",
        "    # lista que armazenarÃ¡ o shape final do dataset\n",
        "    data = []\n",
        "\n",
        "    # candidatos a resposta\n",
        "    cands_dataset = []\n",
        "\n",
        "    # para cada linha do df...\n",
        "    for i, row_data in enumerate(df_.iterrows()):\n",
        "\n",
        "        cands_dataset = []\n",
        "        \n",
        "        # sorteia cands aleatÃ³rias  \n",
        "        docs_choice = list(np.random.choice(df_docs.docid, 2 * K, replace=False))\n",
        "        \n",
        "        # adiciona as cands na lista \n",
        "        cands_dataset.extend(docs_choice)\n",
        "        \n",
        "        # anexa os labels na lista faz o set, emaralha e trunca em K\n",
        "        set_list_cands = list(set(row_data[1].docid + cands_dataset))\n",
        "        \n",
        "        cands = random.sample(set_list_cands, len(set_list_cands))[:K]\n",
        "\n",
        "        # descarta as amostras que nÃ£o possuem o nÃºmero de cands = K  \n",
        "        if len(cands) == K:    \n",
        "            data.append([row_data[1].qid, row_data[1].docid, cands])\n",
        "\n",
        "    return data # list [[qid], [labels], [cands]]    \n",
        "\n",
        "#---------------------------------------------\n",
        "data_train = make_dataset(train_data, 40)\n",
        "data_valid = make_dataset(valid_data, 40)\n",
        "data_train.pop(116)\n",
        "print(f'Amostras de treino: {len(data_train)} -- Amostras de valid: {len(data_valid)}')        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amostras de treino: 129 -- Amostras de valid: 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvO084z38ClS",
        "colab_type": "text"
      },
      "source": [
        "# Estudo do tam. das amostras do dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yw7pIP972pL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c95f9920-70e3-4e74-cb9c-17744768c846"
      },
      "source": [
        "def get_input_tokenized_lenghts(dataset):\n",
        "\n",
        "    # remove o warning do log\n",
        "    logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
        "\n",
        "    lengths = []\n",
        "\n",
        "    for i, seq in enumerate(dataset):\n",
        "        qid, ans_labels, cands = seq[0], seq[1], seq[2]\n",
        "\n",
        "        # Mapeia o id da pergunta para o texto\n",
        "        q_text = qid_to_text[qid]\n",
        "\n",
        "        # Para cada id de resposta em respostas candidatas\n",
        "        for docid in cands:\n",
        "            # Mapeia o docid para o texto\n",
        "            ans_text = docid_to_text[docid]\n",
        "            input_ids = tokenizer.encode(\n",
        "                q_text, \n",
        "                ans_text,\n",
        "                add_special_tokens = True)\n",
        "\n",
        "            lengths.append(len(input_ids))\n",
        "    return lengths\n",
        "\n",
        "#-----------------------------------------------------\n",
        "lengths = get_input_tokenized_lenghts(data_train)\n",
        "\n",
        "print(f' comp. Min: {min(lengths):>8} tokens')\n",
        "print(f' comp. Max: {max(lengths):>8} tokens')\n",
        "print(f' comp. Mediano: {np.median(lengths):,} tokens')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   comp. Min:     18 tokens\n",
            "   comp. Max:    2675 tokens\n",
            "   comp. Mediano: 132.0 tokens\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d00F_Hfh9O7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "a7999558-449f-48d5-8d1b-a41c6acab2d7"
      },
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "\n",
        "trunc_lengths = [min(l, 512) for l in lengths]\n",
        "\n",
        "sns.distplot(trunc_lengths, kde=False, rug=False)\n",
        "\n",
        "plt.title('Comprimento da Sequencia, truncado em 512')\n",
        "plt.xlabel('Comprimento da Sequencia')\n",
        "plt.ylabel('# de Exemplos')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUM7CjV69cSg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4aedcc7b-b029-493c-c36b-f98f634da505"
      },
      "source": [
        "lengths = np.asarray(lengths)\n",
        "\n",
        "num_comments = len(lengths)\n",
        "max_lens = [128, 256, 300, 384, 512]\n",
        "\n",
        "print('Quantas entradas serÃ£o truncadas?\\n')\n",
        "\n",
        "for max_len in max_lens:\n",
        "    num_over = np.sum(lengths > max_len)\n",
        "    prcnt_over = float(num_over) / float(num_comments)\n",
        "    print(f'max_len = {max_len:} --> {num_over:>5,} de ' \\\n",
        "    f'{num_comments:>5,}  ({prcnt_over:>5.1%}) serÃ£o truncadas')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantas entradas serÃ£o truncadas?\n",
            "\n",
            "max_len = 128 --> 2,661 de 5,160  (51.6%) serÃ£o truncadas\n",
            "max_len = 256 --> 1,086 de 5,160  (21.0%) serÃ£o truncadas\n",
            "max_len = 300 -->   809 de 5,160  (15.7%) serÃ£o truncadas\n",
            "max_len = 384 -->   510 de 5,160  ( 9.9%) serÃ£o truncadas\n",
            "max_len = 512 -->   227 de 5,160  ( 4.4%) serÃ£o truncadas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-d-fYDVjTtA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6050decd-8708-4c33-e967-9a5e8dca399a"
      },
      "source": [
        "def get_input_data(dataset, max_seq_len=384):\n",
        "    all_input_ids, attention_masks, segment_ids, labels = [], [], [], []\n",
        "    \n",
        "    # remove o warning do log\n",
        "    logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
        "\n",
        "    for i, seq in enumerate(dataset):\n",
        "\n",
        "        qid, ans_labels, cands = seq[0], seq[1], seq[2]\n",
        "\n",
        "        # Mapeia a questÃ£o para o texto\n",
        "        q_text = qid_to_text[qid]\n",
        "\n",
        "        # Para cada resposta naas candidatas...\n",
        "        for docid in cands:\n",
        "            # Mapeia o docid para o texto\n",
        "            ans_text = docid_to_text[docid]\n",
        "            \n",
        "            # Codifica a sequencia usanso o tokenizador\n",
        "            encoded_seq = tokenizer.encode_plus(\n",
        "                q_text, \n",
        "                ans_text,\n",
        "                max_length=max_seq_len,\n",
        "                pad_to_max_length=True,\n",
        "                return_token_type_ids=True,\n",
        "                return_attention_mask=True,\n",
        "                return_tensors = 'pt'\n",
        "                )\n",
        "\n",
        "            # Se uma resposta na lista Ã© relevante Ã© um label positivo\n",
        "            if docid in ans_labels:\n",
        "                label = 1\n",
        "            # caso contrÃ¡rio Ã© um label negativo\n",
        "            else:\n",
        "                label = 0\n",
        "            \n",
        "                \n",
        "            # Verifica se os tamanhos estÃ£o corretos\n",
        "            assert encoded_seq['input_ids'].shape[1] == max_seq_len, \"dim. do Input esta errada!\"\n",
        "            assert encoded_seq['token_type_ids'].shape[1] == max_seq_len, \"dim. do token_type_id esta errada!\"\n",
        "            assert encoded_seq['attention_mask'].shape[1] == max_seq_len, \"dim. da attention_mask esta errada!\"\n",
        "\n",
        "            all_input_ids.append(encoded_seq['input_ids'])\n",
        "            segment_ids.append(encoded_seq['token_type_ids'])\n",
        "            attention_masks.append(encoded_seq['attention_mask'])\n",
        "            labels.append(label)\n",
        "\n",
        "    all_input_ids = torch.cat(all_input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    segment_ids = torch.cat(segment_ids, dim=0)\n",
        "    \n",
        "    return all_input_ids, attention_masks, segment_ids, labels\n",
        "\n",
        "# teste de sanidade\n",
        "all_input_ids, attention_masks, segment_ids, labels = get_input_data(data_valid, 384)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhP4rbjBn5Hc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "186c9787-2096-4019-e932-78626d8de447"
      },
      "source": [
        "MAX_LEN = 384\n",
        "BATCH_SZ = 16\n",
        "\n",
        "#-----------------------------------__DATASETS__-----------------------------------\n",
        "# cria o dataset de treino\n",
        "all_input_ids_T, attention_masks_T, segment_ids_T, labels_T = get_input_data(\n",
        "    data_train, \n",
        "    MAX_LEN\n",
        "    )\n",
        "\n",
        "ds_train = TensorDataset(\n",
        "    all_input_ids_T, \n",
        "    attention_masks_T, \n",
        "    segment_ids_T, \n",
        "    torch.tensor(labels_T)\n",
        "    )\n",
        "\n",
        "# cria o dataset de validaÃ§Ã£o\n",
        "all_input_ids_V, attention_masks_V, segment_ids_V, labels_V = get_input_data(\n",
        "    data_valid, \n",
        "    MAX_LEN\n",
        "    )\n",
        "ds_val = TensorDataset(\n",
        "    all_input_ids_V, \n",
        "    attention_masks_V, \n",
        "    segment_ids_V, \n",
        "    torch.tensor(labels_V)\n",
        "    )\n",
        "\n",
        "#---------------------------------__DATALOADERS__----------------------------------\n",
        "\n",
        "# dataloader Ã© um dict com chave train e val\n",
        "dataloaders = {\n",
        "     'train': DataLoader(\n",
        "         ds_train,\n",
        "         batch_size=BATCH_SZ,\n",
        "         sampler = RandomSampler(ds_train), # Seleciona batches randomicamente\n",
        "         num_workers=4,\n",
        "         pin_memory=True\n",
        "         ),\n",
        "               \n",
        "     'val': DataLoader(\n",
        "         ds_val,\n",
        "         batch_size=BATCH_SZ,\n",
        "         sampler = SequentialSampler(ds_val), # toma batches sequencialmente\n",
        "         num_workers=4,\n",
        "         pin_memory=True\n",
        "         ),\n",
        "     }\n",
        "\n",
        "# teste de sanidade\n",
        "dl_sizes = {x: len(dataloaders[x]) for x in dataloaders.keys()}\n",
        "dl_sizes "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 323, 'val': 75}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRlP5_KcwZpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(preds, labels):\n",
        "\n",
        "    # Toma o label (coluna) com a maior probabilidade\n",
        "    predictions = np.argmax(preds, axis=1).flatten()\n",
        "    labels = labels.flatten()\n",
        "    \n",
        "    # Computa  a acc\n",
        "    accuracy = np.sum(predictions == labels) / len(labels)\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhZRnEfPjTYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, device, train_dataloader, optimizer, scheduler):\n",
        "\n",
        "    # Acumula o a loss do treino e a acuracia\n",
        "    total_loss, train_accuracy = 0, 0\n",
        "    \n",
        "    # conta o num. de batches\n",
        "    num_steps = 0\n",
        "    \n",
        "    # coloca o modelo em modo treino\n",
        "    model.train()\n",
        "    \n",
        "    # Para cada batch no dadaset de treino...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Coloca os tensores na GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Desempacota os inputs do dataloader\n",
        "        b_input_ids, b_input_masks, b_token_type_ids, b_labels = batch\n",
        "        \n",
        "        # Zera os gradientes\n",
        "        model.zero_grad()\n",
        "        \n",
        "        # Forward pass: o modelo irÃ¡ retornar a loss e os logits\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids = b_token_type_ids,\n",
        "                        attention_mask = b_input_masks,\n",
        "                        labels = b_labels)\n",
        "\n",
        "        # loss e prediÃ§Ãµes\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        \n",
        "        # Move os logits e labels para CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calcula a acuracia do batch\n",
        "        tmp_accuracy = get_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumula a acuracia total\n",
        "        train_accuracy += tmp_accuracy\n",
        "\n",
        "        # Conta os numeros de batches\n",
        "        num_steps += 1\n",
        "\n",
        "        # Accumula a loss de treinamento sobre todos os batches\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Executa o backward pass para calcular os gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Clipa o norma dos gradientes em 1.0, isso previne o problema \"exploding gradients\"\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Atualiza os parametros e toma um step no gradiente calculado\n",
        "        optimizer.step()\n",
        "\n",
        "        # Atualiza o scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calcula a mÃ©dia da loss no conj. de treino\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    avg_acc = train_accuracy/num_steps\n",
        "\n",
        "    return avg_loss, avg_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za93hOsJjTPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_model(model, device, validation_dataloader):\n",
        "\n",
        "    # Coloca o modelo em modo de avaliaÃ§Ã£o\n",
        "    model.eval()\n",
        "\n",
        "    # Acumula a loss do conj. de valid e acuracia\n",
        "    total_loss, eval_accuracy = 0, 0\n",
        "\n",
        "    # conta o num. de batches\n",
        "    num_steps = 0\n",
        "\n",
        "    # Para cada batch no dadaset de treino...\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Coloca os tensores na GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Desempacota os inputs do dataloader\n",
        "        b_input_ids, b_input_masks, b_token_type_ids, b_labels = batch\n",
        "\n",
        "        # NÃ£o calcula os gradientes armazenados\n",
        "        with torch.no_grad():\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids = b_token_type_ids,\n",
        "                            attention_mask = b_input_masks,\n",
        "                            labels= b_labels)\n",
        "        \n",
        "        # loss e logits\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        \n",
        "        # Move os logits e labels para CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calcula a acuracia para o batch \n",
        "        tmp_eval_accuracy = get_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumula a acuracia total\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Conta o numeto de batches\n",
        "        num_steps += 1\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Calcula a loss e acuracia\n",
        "    avg_loss = total_loss / len(validation_dataloader)\n",
        "    avg_acc = eval_accuracy/num_steps\n",
        "\n",
        "    return avg_loss, avg_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oop4oVSB2kON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'bert-qa': Ã© o BERT do Rodrigo fine-tuned no MS Macro\n",
        "# 'finbert-domain': Ã© o BERT pre-trainado no Araci (grande corpus financeiro)\n",
        "# 'finbert-task': Ã© o BERT re-(pre-treinado) no FIQA\n",
        "\n",
        "bert_qa = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/BERT/FinBERT/models/bert-qa'\n",
        "finbert_domain = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/BERT/FinBERT/models/finbert-domain'\n",
        "finbert_task = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/BERT/FinBERT/models/finbert-task'\n",
        "\n",
        "# Carrega o BertForSequenceClassification - pre-trainado com uma camada linear no final\n",
        "model = BertForSequenceClassification.from_pretrained(finbert_task, cache_dir=None, num_labels=2)\n",
        "\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5u6nRQJxqCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5b6320f0-3340-49c4-ec52-944421d449bf"
      },
      "source": [
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "#----------------------------------------------------------------\n",
        "deterministic()\n",
        "N_EPOCHS = 2\n",
        "optimizer = AdamW(model.parameters(), lr = 3e-6, eps = 1e-8)\n",
        "\n",
        "total_steps = len(dataloaders['train']) * N_EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, \n",
        "    num_warmup_steps = 1_000,\n",
        "    num_training_steps = total_steps\n",
        "    )\n",
        "#----------------------------------------------------------------\n",
        "start.record()\n",
        "\n",
        "training_stats = []\n",
        "for epoch_i in range(1, N_EPOCHS+1):\n",
        "    loss_train, acc_train = train_model(\n",
        "        model, \n",
        "        device, \n",
        "        dataloaders['train'], \n",
        "        optimizer, \n",
        "        scheduler\n",
        "        )\n",
        "    loss_val, acc_val = validate_model(\n",
        "        model, \n",
        "        device, \n",
        "        dataloaders['val']\n",
        "        )\n",
        "    \n",
        "    print(f'\\nEpoca [{epoch_i}/{N_EPOCHS}] |', end=' ')\n",
        "    print(f'Loss Treino: {loss_train:.3f} -- Acc Treino: {acc_train:.3f} ---- \\\n",
        "Loss Valid: {loss_val:.3f} -- Acc Valid: {acc_val:.3}')\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i,\n",
        "            'Training Loss': loss_train,\n",
        "            'Training Acc': acc_train,\n",
        "            'Valid Loss': loss_val,\n",
        "            'Valid Acc': acc_val,\n",
        "        }\n",
        "    )\n",
        "\n",
        "end.record()\n",
        "torch.cuda.synchronize()    \n",
        "#------------------------------------------------------------------\n",
        "print(f'\\nFEITO!')\n",
        "print(f'Tempo gasto: {start.elapsed_time(end)/1000/60 :.3f} min.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla T4 disponÃ­vel.\n",
            "\n",
            "Epoca [1/2] | Loss Treino: 0.392 -- Acc Treino: 0.911 ---- Loss Valid: 0.201 -- Acc Valid: 0.963\n",
            "\n",
            "Epoca [2/2] | Loss Treino: 0.111 -- Acc Treino: 0.978 ---- Loss Valid: 0.115 -- Acc Valid: 0.965\n",
            "\n",
            "FEITO!\n",
            "Tempo gasto: 12.945 min.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmWzkAfaXKQp",
        "colab_type": "text"
      },
      "source": [
        "## Log do treino em dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhvKvyeBXNvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "ececb5ab-43c1-47ea-c728-d204a3a56f0d"
      },
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "pd.set_option('precision', 3)\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Training Acc</th>\n",
              "      <th>Valid Loss</th>\n",
              "      <th>Valid Acc</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.392</td>\n",
              "      <td>0.911</td>\n",
              "      <td>0.201</td>\n",
              "      <td>0.963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.111</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.965</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Training Acc  Valid Loss  Valid Acc\n",
              "epoch                                                    \n",
              "1              0.392         0.911       0.201      0.963\n",
              "2              0.111         0.978       0.115      0.965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3Qppb1-nvRg",
        "colab_type": "text"
      },
      "source": [
        "# AvaliaÃ§Ã£o dos resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6npVgMDNewIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, q_text, cands, max_seq_len=MAX_LEN):\n",
        "    \"\"\"\n",
        "    Re-ranqueia as respostas dos candidatos para cada pergunta.\n",
        "\n",
        "     Retorna:\n",
        "         ranked_ans: lista de docids candidatos re-classificados\n",
        "         sorted_scores: lista de pontuaÃ§Ãµes de relevÃ¢ncia das respostas\n",
        "     -------------------\n",
        "     Argumentos:\n",
        "         model - modelo PyTorch\n",
        "         q_text - str - query\n",
        "         cands - Lista de docids candidatos\n",
        "         max_seq_len - int\n",
        "     \"\"\"\n",
        "    # Converte a lista para numpy\n",
        "    cands_id = np.array(cands)\n",
        "    \n",
        "    scores = []\n",
        "    # Para cada respostas em cands...\n",
        "    for docid in cands:\n",
        "        # Mapeia o docid para o texto\n",
        "        ans_text = docid_to_text[docid]\n",
        "        # Cria os inputs para o modelo\n",
        "        encoded_seq = tokenizer.encode_plus(\n",
        "            q_text, \n",
        "            ans_text,\n",
        "            max_length=max_seq_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_attention_mask = True\n",
        "            )\n",
        "\n",
        "        input_ids = torch.tensor([encoded_seq['input_ids']]).to(device)\n",
        "        token_type_ids = torch.tensor([encoded_seq['token_type_ids']]).to(device)\n",
        "        att_mask = torch.tensor([encoded_seq['attention_mask']]).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calcula as prediÃ§Ãµes/logit para cada par QA\n",
        "            outputs = model(\n",
        "                input_ids, \n",
        "                attention_mask=att_mask,\n",
        "                token_type_ids=token_type_ids, \n",
        "                )\n",
        "        \n",
        "        # prediÃ§Ãµes\n",
        "        logits = outputs[0]\n",
        "        \n",
        "        # Aplica a softmax\n",
        "        pred = softmax(logits, dim=1)\n",
        "        \n",
        "        # Move os logits e labels para CPU\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        \n",
        "        # Anexa os scores relevantes para lista (onde label = 1)\n",
        "        scores.append(pred[:,1][0])\n",
        "        \n",
        "        # Obtenha os Ã­ndices dos scores de similaridade ordenados\n",
        "        sorted_index = np.argsort(scores)[::-1]\n",
        "        \n",
        "        # Obtenha uma lista de docid vindo dos indices ordenados\n",
        "        ranked_ans = list(cands_id[sorted_index])\n",
        "        sorted_scores = list(np.around(sorted(scores, reverse=True),decimals=3))\n",
        "\n",
        "    return ranked_ans, sorted_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRSvaM8BEvH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rank(model, test_set, max_seq_len=MAX_LEN):\n",
        "    \"\"\"\n",
        "    Re-ranqueia as respostas candidatas para cada pergunta.\n",
        "\n",
        "     Retorna:\n",
        "         qid_pred_rank: DicionÃ¡rio\n",
        "             key - qid\n",
        "             value - lista de candidatos re-ranqueados\n",
        "     -------------------\n",
        "     Argumentos:\n",
        "         model - modelo PyTorch\n",
        "         test_set Lista de listas\n",
        "         max_seq_len - int\n",
        "     \"\"\"\n",
        "    \n",
        "    qid_pred_rank = {}\n",
        "    \n",
        "    # Configura o modelo para o modo evaluation\n",
        "    model.eval()\n",
        "    \n",
        "    # Para cada elmento no conj. de test\n",
        "    for i, seq in enumerate(test_set):\n",
        "        qid, label, cands = seq[0], seq[1], seq[2]\n",
        "        # Mapeia o id da questÃ£o para o texto\n",
        "        q_text = qid_to_text[qid]\n",
        "\n",
        "        # Lista de docids re-ranqueados com suas correspondentes probabilidades\n",
        "        ranked_ans, sorted_scores = predict(model, q_text, cands, max_seq_len)\n",
        "\n",
        "        # Dicionaro com key=qid e value=lista ranqueada de docids\n",
        "        qid_pred_rank[qid] = ranked_ans\n",
        "\n",
        "    return qid_pred_rank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87o1pY7xUZUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rel(labels, cands):\n",
        "    \"\"\"\n",
        "    Obtem posiÃ§Ãµes relevantes dos acertos.\n",
        "\n",
        "     Retorna: Lista de 0s e 1s que incidem em uma resposta relevante\n",
        "     -------------------\n",
        "     Argumentos:\n",
        "         labels: lista de docids relevantes\n",
        "         cands: Lista de candidatos a docids\n",
        "     \"\"\"\n",
        "    rel = []\n",
        "    for cand in cands:\n",
        "        if cand in labels:\n",
        "            rel.append(1)\n",
        "        else:\n",
        "            rel.append(0)\n",
        "\n",
        "    return rel\n",
        "\n",
        "def dcg(rels, k):\n",
        "    \"\"\"\n",
        "     Ganho cumulativo com desconto. Calcula o DCG acumulado do top-k\n",
        "     documentos relevantes em todas as queries.\n",
        "\n",
        "     Retorna:\n",
        "         cumulated_sum: float - DCG acumulado\n",
        "     ----------\n",
        "     Argumentos:\n",
        "         rels: lista\n",
        "             Lista de pontuaÃ§Ãµes relevantes de 0 ou 1, por exemplo [0, 1, 0, 1]\n",
        "         k: int\n",
        "             Top-k documentos relevantes\n",
        "     \"\"\"\n",
        "    cumulated_sum = rels[0]\n",
        "    for i in range(1, k):\n",
        "        cumulated_sum += rels[i]/math.log(i+1,2)\n",
        "    return cumulated_sum\n",
        "\n",
        "def avg_ndcg(rel_score, k):\n",
        "    \"\"\"\n",
        "     Ganho Cumulativo Descontado Normalizado MÃ©dio. Calcula o DCG, iDCG e\n",
        "     nDCG para cada consulta e retorna o nDCG mÃ©dio em todas as queries.\n",
        "\n",
        "     Retorna:\n",
        "         avg: float - nDCG mÃ©dio\n",
        "     ----------\n",
        "     Argumentos:\n",
        "         rel_score: dicionÃ¡rio\n",
        "             chave - id da pergunta\n",
        "             valor - lista de pontuaÃ§Ãµes de relevÃ¢ncia com 1 (relevante) e 0 (irrelevante)\n",
        "             por exemplo. {0: [0, 1, 0], 1: [1, 1, 0]}\n",
        "         k: int\n",
        "             Top-k documentos relevantes\n",
        "     \"\"\"\n",
        "    ndcg_list = []\n",
        "    for qid, rels in rel_score.items():\n",
        "        # Computa DCG para cada pergunta\n",
        "        dcg_val = dcg(rels, k)\n",
        "        sorted_rel = sorted(rels, reverse=True)\n",
        "        # Computa iDCG para cada pergunta\n",
        "        idcg_val = dcg(sorted_rel, k)\n",
        "\n",
        "        try:\n",
        "            ndcg_val = dcg_val/idcg_val\n",
        "            ndcg_list.append(ndcg_val)\n",
        "        except ZeroDivisionError:\n",
        "            ndcg_list.append(0)\n",
        "\n",
        "    assert len(ndcg_list) == len(rel_score), \"PontuaÃ§Ã£o relevante nÃ£o casa/combina\"\n",
        "\n",
        "    # Obtem a mÃ©dia nDCG para todas queries\n",
        "    avg = mean(ndcg_list)\n",
        "\n",
        "    return avg\n",
        "\n",
        "def compute_RR(cand_docs, rel_docs, cumulated_reciprocal_rank, rank_pos, k):\n",
        "   \"\"\"\n",
        "     Calcula a classificaÃ§Ã£o recÃ­proca - probabilidade de correÃ§Ã£o da classificaÃ§Ã£o. \n",
        "     Retorna a classificaÃ§Ã£o recÃ­proca acumulada em todas as queries e as posiÃ§Ãµes do\n",
        "     documentos relevantes nos candidatos.\n",
        "\n",
        "     Retorna:\n",
        "         cumulated_reciprocal_rank: float - classificaÃ§Ã£o recÃ­proca acumulada em \n",
        "         todas as queries\n",
        "         rank_pos: list - Ã­ndice dos documentos relevantes nos candidatos\n",
        "     ----------\n",
        "     Argumentos:\n",
        "         cand_docs: list\n",
        "             Lista de docids classificados para uma pergunta\n",
        "         rel_docs: list\n",
        "             Lista da relevÃ¢ncia dos docids para uma pergunta\n",
        "         cumulated_reciprocal_rank: int\n",
        "             Valor inicial = 0\n",
        "         rank_pos: list\n",
        "             Lista inicial = []\n",
        "         k: int\n",
        "             Top-k documentos relevantes\n",
        "     \"\"\"\n",
        "\n",
        "    for i in range(0, k):\n",
        "        # Se o doc_id do top-k passagens candidatas com melhor classificaÃ§Ã£o estiver \n",
        "        # na lista de passagens relevantes\n",
        "        if cand_docs[i] in rel_docs:\n",
        "            # Computa a classificaÃ§Ã£o recÃ­proca (i Ã© a classificaÃ§Ã£o)\n",
        "            rank_pos.append(i+1)\n",
        "            cumulated_reciprocal_rank += 1/(i+1)\n",
        "            break\n",
        "\n",
        "    return cumulated_reciprocal_rank, rank_pos\n",
        "\n",
        "def create_qid_pred_rank(test_set):\n",
        "    \"\"\"\n",
        "     Cria dicionÃ¡rio de qid e lista de candidatos do conjunto de teste.\n",
        "\n",
        "     Retorna:\n",
        "         qid_pred_rank: dicionÃ¡rio\n",
        "             chave - qid\n",
        "             valor - lista de candidatos\n",
        "     ----------\n",
        "     Argumentos:\n",
        "         test_set: list\n",
        "             [[qid, [docids positivos], [lista de candidatos]]]\n",
        "     \"\"\"\n",
        "    qid_pred_rank = {}\n",
        "\n",
        "    for row in test_set:\n",
        "        qid_pred_rank[row[0]] = row[2]\n",
        "\n",
        "    return qid_pred_rank\n",
        "\n",
        "def evaluate(qid_ranked_docs, qid_rel, k):\n",
        "    \"\"\"\n",
        "     Calcula o MRR@k, nDCG@k mÃ©dio e precision@k1\n",
        "\n",
        "     Retorna:\n",
        "         MRR: float\n",
        "         average_ndcg: float\n",
        "         avg_precision: float\n",
        "         r_pos: int\n",
        "     ----------\n",
        "     Argumentos:\n",
        "         qid_ranked_docs: dicionÃ¡rio\n",
        "             chave - qid\n",
        "             valor - lista de cand ans\n",
        "         qid_rel: dicionario\n",
        "             key- qid\n",
        "             valor - lista de documentos relevantes\n",
        "     \"\"\"\n",
        "    \n",
        "    cumulated_reciprocal_rank, num_rel_docs = 0,0\n",
        "    rel_scores, precision_list = {}, {}\n",
        "    rank_pos = []\n",
        "\n",
        "    # Para cada query...\n",
        "        for qid in qid_ranked_docs:\n",
        "        # Se a query Ã© relevante\n",
        "        if qid in qid_rel:\n",
        "            # Obtem a  lista de docs relevantes para uma query\n",
        "            rel_docs = qid_rel[qid]\n",
        "            # Obtem a lista de documentos classificados para uma query\n",
        "            cand_docs = qid_ranked_docs[qid]\n",
        "            # Computa o score dos candidatos\n",
        "            if qid not in rel_scores:\n",
        "                rel_scores[qid] = []\n",
        "                for i in range(0, k):\n",
        "                    if cand_docs[i] in rel_docs:\n",
        "                        rel_scores[qid].append(1)\n",
        "                    else:\n",
        "                        rel_scores[qid].append(0)\n",
        "            # Computa a i-Ã©sima classificaÃ§Ã£o reciproca e posiÃ§Ã£o de classificaÃ§Ã£o\n",
        "            cumulated_reciprocal_rank, r_pos = compute_RR(\n",
        "                cand_docs, \n",
        "                rel_docs, \n",
        "                cumulated_reciprocal_rank, \n",
        "                rank_pos, k\n",
        "                )\n",
        "    \n",
        "    # Computa o MRR@k\n",
        "    MRR = cumulated_reciprocal_rank/len(qid_ranked_docs)\n",
        "    # Computa o nDCG@k\n",
        "    average_ndcg = avg_ndcg(rel_scores, k)\n",
        "\n",
        "    # Computa precision@1\n",
        "    precision_at_k = []\n",
        "    for qid, score in rel_scores.items():\n",
        "        num_rel = 0\n",
        "        for i in range(0, 1):\n",
        "            if score[i] == 1:\n",
        "                num_rel += 1\n",
        "        precision_at_k.append(num_rel/1)\n",
        "    \n",
        "    avg_precision = mean(precision_at_k)\n",
        "\n",
        "    return MRR, average_ndcg, avg_precision, r_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQb8GDWk-otV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "da4fb7bd-18c9-42d3-e7cc-b316e7d4775e"
      },
      "source": [
        "qid_pred_rank = get_rank(model, data_valid, 384)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z66Ro7SsAEYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ef29e9cc-a3e7-4315-dd7d-b7976459f2ac"
      },
      "source": [
        "k = 10\n",
        "num_q = len(data_valid)\n",
        "\n",
        "MRR, average_ndcg, precision, rank_pos = evaluate(qid_pred_rank, labels_valid, k)\n",
        "\n",
        "print(f'\\nAverage nDCG@{k} for {num_q} queries: {average_ndcg:.3f}')\n",
        "print(f'MRR@{k} for {num_q} queries: {MRR:.3f}')\n",
        "print(f'Average Precision@1 for {num_q} queries: {precision:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average nDCG@10 for 30 queries: 0.718\n",
            "MRR@10 for 30 queries: 0.679\n",
            "Average Precision@1 for 30 queries: 0.600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ0vrEj5z0QM",
        "colab_type": "text"
      },
      "source": [
        "# Analise do predict\n",
        "\n",
        "#### `df_docs_cos` Ã© um dataframe obtido por similaridade de cossenos entre todos os documentos, logo os cands serÃ£o os `docs` que possuirÃ©m maior similaridade com o `qid`. A similaridade foi obtida com o distilUSE do UKPLab-[SBERT](https://www.sbert.net/docs/pretrained_models.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JVnd3Ct4mxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pickle_file(path, data=None):\n",
        "    if data is None:\n",
        "        with open(path, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "    if data is not None:\n",
        "        with open(path, 'wb') as handle:\n",
        "            pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# carregando o dataframe\n",
        "path_df_cos = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/BERT/FinBERT/df_docs_cos'\n",
        "df_docs_cos = pickle_file(path_df_cos)\n",
        "\n",
        "# ordenando pelo score decrescente da similaridade de cosseno\n",
        "df_docs_cos = df_docs_cos.sort_values(by='COS_SIM', ascending=False).reset_index(drop=True)\n",
        "\n",
        "# criando uma lista com esses documentos pela col. ID2\n",
        "remove_equals_docs = df_docs_cos[0:6].ID2.to_list()\n",
        "\n",
        "# esses documentos nÃ£o podem ser labels para nenhuma qid, logo len = 0\n",
        "assert len(df_labels_sub[df_labels_sub.docid.isin(remove_equals_docs)]) == 0\n",
        "\n",
        "# removendo\n",
        "df_docs_cos = df_docs_cos[~df_docs_cos.ID2.isin(remove_equals_docs)]\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "def make_cands_with_cos_sim(df, number_of_cands=30):\n",
        "    # num. de candidatos por amostra\n",
        "    K = number_of_cands\n",
        "\n",
        "    # dataset \n",
        "    df_ = df.copy() # cols: df[['qid'], ['docid']]\n",
        "\n",
        "    # lista que armazenarÃ¡ o shape final do dataset\n",
        "    data = []\n",
        "\n",
        "    # candidatos a resposta\n",
        "    cands_dataset = []\n",
        "\n",
        "    # para cada linha do df...\n",
        "    for i, row_data in enumerate(df_.iterrows()):\n",
        "\n",
        "        # se existe mais de um rel. doc por qid...\n",
        "        if len(row_data[1].docid) > 1:\n",
        "\n",
        "            # conta quantos exemplos de cada id estÃ¡ sendo anexado\n",
        "            sum = 0\n",
        "            # num. de exemplos por amostra - forma de balancear os candidatos\n",
        "            samples_per_doc = int(K/len(row_data[1].docid)-1)\n",
        "            \n",
        "            # lista que armazena os docs candidatos\n",
        "            cands_dataset = []\n",
        "\n",
        "            # para cada elem. na lista de docs candidatos\n",
        "            for j, elem in enumerate(row_data[1].docid, 1): \n",
        "\n",
        "                if j != len(row_data[1].docid):\n",
        "                    # soma a quantidade de docs cands. anexado\n",
        "                    sum += samples_per_doc\n",
        "                    # checamos se existe docs cands. suficiente\n",
        "                    len_sample = len(df_docs_cos[df_docs_cos.ID1 == elem]\\\n",
        "                                     [:samples_per_doc].ID2.to_list())\n",
        "\n",
        "                    # se nÃ£o existir amostras suficientes, faz um sorteio de \n",
        "                    # samples_per_doc docs cands\n",
        "                    if len_sample < samples_per_doc:\n",
        "                        docs_choice = list(np.random.choice(\n",
        "                            df_docs_cos.ID2, 2 * samples_per_doc, replace=False))\n",
        "                        cands_dataset.extend(docs_choice)\n",
        "\n",
        "                    else: # caso exista o num. suficiente anexamos os que possuem \n",
        "                          # maior pontuaÃ§Ã£o de cosseno\n",
        "\n",
        "                        # anexa os docs candidatos para j < len(row_data[1].docid)\n",
        "                        cands_dataset.extend(df_docs_cos[df_docs_cos.ID1 == elem]\\\n",
        "                                             [:samples_per_doc].ID2.to_list())\n",
        "                        # conta quntos docs foram anexados\n",
        "                \n",
        "                # para o Ãºltimo elem da lista de respostas\n",
        "                if j == len(row_data[1].docid):\n",
        "                    len_sample = len(df_docs_cos[df_docs_cos.ID1 == elem]\\\n",
        "                                     [:samples_per_doc].ID2.to_list())\n",
        "                    \n",
        "                    # se j Ã© o Ãºltimo elem. da lista, completa os cands com o rest\n",
        "                    rest = K - sum\n",
        "                    \n",
        "                    # se nÃ£o existir amostras suficientes, faz um sorteio de \n",
        "                    # restr docs cands\n",
        "                    if len_sample < rest:\n",
        "                        docs_choice = list(np.random.choice(\n",
        "                            df_docs_cos.ID2, 2 * rest, replace=False))\n",
        "                        cands_dataset.extend(docs_choice)\n",
        "\n",
        "                    else: # caso exista o num. suficiente anexamos os que possuem \n",
        "                          # maior pontuaÃ§Ã£o de cosseno\n",
        "                        cands_dataset.extend(df_docs_cos[df_docs_cos.ID1 == elem]\\\n",
        "                                             [:rest].ID2.to_list())\n",
        "\n",
        "        if len(row_data[1].docid) == 1:\n",
        "            len_sample = df_docs_cos[\n",
        "                df_docs_cos.ID1.isin(row_data[1].docid)].ID2.to_list()[:K]\n",
        "\n",
        "            if len(len_sample) < K:\n",
        "                docs_choice = list(np.random.choice(\n",
        "                    df_docs_cos.ID2, 2 * K, replace=False))\n",
        "                cands_dataset.extend(docs_choice)\n",
        "\n",
        "            else:\n",
        "                cands_dataset.extend(df_docs_cos[df_docs_cos.ID1 == row_data[1].qid]\\\n",
        "                                     [:K].ID2.to_list())\n",
        "\n",
        "        # anexa os labels no inicio do conj. dos docs candidatos e trunca em K\n",
        "        cands = list(set(row_data[1].docid + cands_dataset))\n",
        "\n",
        "        # embaralha a lista\n",
        "        cands = random.sample(cands, len(cands))[:K]\n",
        "        data.append([row_data[1].qid, row_data[1].docid, cands])\n",
        "        \n",
        "    return data # list [[qid], [labels], [cands]]    \n",
        "\n",
        "#-----------------------------------------------------------\n",
        "valid_cands_cos = make_cands_with_cos_sim(valid_data, 40)\n",
        "print(f'Valid. candidatas: {len(valid_cands_cos)}')        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYyELZH2FNGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "5ea45d2d-f87d-4de4-c96d-fc782ec8730d"
      },
      "source": [
        "N = np.random.randint(0, len(valid_cands_cos))\n",
        "\n",
        "# Exemplo escolhido aletÃ³riamente com cadas escolhidos por similaridade de cosseno\n",
        "seq = valid_cands_cos[N]\n",
        "qid, label, cands = seq[0], seq[1], seq[2]\n",
        "q_text = qid_to_text[qid]\n",
        "query = q_text\n",
        "\n",
        "#---------------------------------------------------------\n",
        "model.eval()\n",
        "# Re-classifica os candidatos\n",
        "rank, scores = predict(model, query, cands, MAX_LEN)\n",
        "\n",
        "# Top-k respostas\n",
        "k = 5\n",
        "\n",
        "print(f'\\nQuery:\\n\\t{query}\\n')\n",
        "print(f'Top-{k} Answers: \\n')\n",
        "for i in range(0, k):\n",
        "    print(f'{i+1} docid: {rank[i]:>6} -- text: {docid_to_text[rank[i]]}\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Query:\n",
            "\tWhy are U.S. credit unions not open to everyone?\n",
            "\n",
            "Top-5 Answers: \n",
            "\n",
            "1 docid: 155634 -- text: It's required by law.  12 USC 1759 (b) requires that membership in a credit union be limited to one or more groups with a \"common bond\", or to people within a particular geographic area. For lots more gory details on how this is interpreted and enforced, you can read the manual given to credit unions by the National Credit Union Administration, which is their regulatory agency.\n",
            "\n",
            "2 docid: 269447 -- text: Credit unions are mutually-owned (i.e. customer owned) financial institutions that provide banking services.  They take deposits from their members (customers) and loan them to other members.  Members vote on a board of directors who manage operations.   They are considered not-for-profit, but they pay interest on deposits.  They get some preferential tax treatment and regulation and their deposits are insured by a separate organization if federally accredited.  State-chartered credit unions don't have to maintain deposit insurance at all.   Their charters specify who can join.  They can be regionally based, employer based, or based on some other group with common interests.  Regulators restrict them so that they don't interfere too much with banks.  Otherwise their preferential tax and regulatory treatment would leave banks uncompetitive.   Other organizations with similar limits have gone on to be competitive when the limits were released.  For example, there used to be an insurance company just for government employees, the Government Employees Insurance Company.  You may know it better as GEICO (yes, the one with the gecko advertisements).  Now they offer life and auto insurance all over.   Credit unions would like looser limitations (or no limitations at all), but not enough to give up their preferential tax treatment.  Banks oppose looser limitations and have as much political clout as credit unions.\n",
            "\n",
            "3 docid:   5644 -- text: Your instructor's numbers do not seem to have any basis in current reality. At this page you can see a comparison of interest rates offered by banks and credit unions.  In the most recent table for June 2014, banks paid an average interest rate of 0.12 percent on savings accounts, while credit unions paid an average of 0.13 percent.   If you look back further, you will see that interest rates paid by banks and credit unions are generally comparable.  Credit union rates tend to be a little bit higher, but certainly not 7 times higher. The last time any financial institution paid as much as 15% on a savings account would probably be the early 1980s.  You can see here a historical chart of the \"prime rate\" for lending.  Savings account rates (at either banks or credit unions) would typically be lower. (This is based on the US, in accordance with your tag.  Interest rates in other places, especially developing countries with less stable currencies, can be dramatically different.)\n",
            "\n",
            "4 docid:  16586 -- text: this post offers valuable information we can all use when scouting for frequent flyer credit cards. let's all support this post of my friend, sean travis, by reading and sharing it to all our friends and followers in different social networking sites.\n",
            "\n",
            "5 docid:  20797 -- text: KIRO Studios provides photography services to suit your every need. Enjoy and preserve your next event with stunning Photography Ottawa that will last a lifetime. With KIRO Studios, you can be assured that you are getting the quality photography you seek and peace of mind you deserve.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaJ2pIvnuTYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "dbe961e3-37b6-4abe-8a02-c02e14d2b649"
      },
      "source": [
        "df_labels[df_labels.qid==qid]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>docid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>493</td>\n",
              "      <td>269447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>493</td>\n",
              "      <td>155634</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     qid   docid\n",
              "277  493  269447\n",
              "278  493  155634"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_0nDkgywV7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "c1b52e4d-2a74-42f1-decf-c235781027fa"
      },
      "source": [
        "df_questions[df_questions.qid==qid]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>493</td>\n",
              "      <td>Why are U.S. credit unions not open to everyone?</td>\n",
              "      <td>Feb 19 at 21:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     qid                                          question        timestamp\n",
              "148  493  Why are U.S. credit unions not open to everyone?  Feb 19 at 21:04"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OazQ-1o929se",
        "colab_type": "text"
      },
      "source": [
        "# FIM"
      ]
    }
  ]
}