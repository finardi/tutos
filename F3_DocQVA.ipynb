{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "F3 -  DocQVA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "13xCG52xz3MJzmQ5V2VskOTuvK5XlnTa6",
      "authorship_tag": "ABX9TyO1sJd777r6Afl7aGZCrnJr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49de2a6db52840b096d3dfbe1a6fa1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_28cfe900dfae45a297c384513e1e98b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe04a42e6b454f069ea3ce4de206aba3",
              "IPY_MODEL_6c51f2f276544e2cb07f007916779b98"
            ]
          }
        },
        "28cfe900dfae45a297c384513e1e98b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe04a42e6b454f069ea3ce4de206aba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_95d95ca50f2c4cd8bd562acfac5bede7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2dbdf5270d114306b777e20f3c54e41b"
          }
        },
        "6c51f2f276544e2cb07f007916779b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f7a9205d0654a98bf16a7a515d25468",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 135kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e135e3243aa4738be86d4b906c3258f"
          }
        },
        "95d95ca50f2c4cd8bd562acfac5bede7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2dbdf5270d114306b777e20f3c54e41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f7a9205d0654a98bf16a7a515d25468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e135e3243aa4738be86d4b906c3258f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "781b36b580d04057843d5f9a76e480e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_beb0e27b96d34fbfa931992237e5904b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_732988eb935848319469878478c2e4e4",
              "IPY_MODEL_08d0f66236fa4273b6866455cd9bb78e"
            ]
          }
        },
        "beb0e27b96d34fbfa931992237e5904b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "732988eb935848319469878478c2e4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c34902948114d9ea3cd016bf81c19a1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e204e0c3d19b497ea2e086ec480bd82b"
          }
        },
        "08d0f66236fa4273b6866455cd9bb78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1b2f5a8fad7b4f7294a0cbd8bb7a5263",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 197B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3de7b874ed7b4cf2bf7d163563425378"
          }
        },
        "9c34902948114d9ea3cd016bf81c19a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e204e0c3d19b497ea2e086ec480bd82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b2f5a8fad7b4f7294a0cbd8bb7a5263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3de7b874ed7b4cf2bf7d163563425378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0af49bcba501461e8b6474302d00741a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d7f8d84a065429dbdb4de4188d45308",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4406aafc74c2402999ddb1a8464e7e07",
              "IPY_MODEL_da1d9312749f4438a219d95dd8b1dd01"
            ]
          }
        },
        "7d7f8d84a065429dbdb4de4188d45308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4406aafc74c2402999ddb1a8464e7e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_18be3fc24bbd47b98b03098d68ad1822",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 85,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 85,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b4320f1fb3e4808bc0124e742c68e97"
          }
        },
        "da1d9312749f4438a219d95dd8b1dd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d5d683398a549dd8aa1a5f40bf00c89",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 85.0/85.0 [00:00&lt;00:00, 268B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14de92a6ce45496eaf2038075e47c4d0"
          }
        },
        "18be3fc24bbd47b98b03098d68ad1822": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b4320f1fb3e4808bc0124e742c68e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d5d683398a549dd8aa1a5f40bf00c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14de92a6ce45496eaf2038075e47c4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53251e3f27d44819822d450e016454b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_772d056f8beb4bac80b9ae41056dda92",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d964d7cb0ce244f0b45e18f509054cdf",
              "IPY_MODEL_56dd4f7c166b40099f823adc09af05b1"
            ]
          }
        },
        "772d056f8beb4bac80b9ae41056dda92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d964d7cb0ce244f0b45e18f509054cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7266a77b53bb4f4ba929c88c19fca651",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 765,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 765,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbe49764b04c446aa865f3aca5f3bf02"
          }
        },
        "56dd4f7c166b40099f823adc09af05b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f06f2a4076474809ae08c1318fe21257",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 765/765 [00:00&lt;00:00, 32.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3de5e50af1b46d09e5072ab4417bcf0"
          }
        },
        "7266a77b53bb4f4ba929c88c19fca651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbe49764b04c446aa865f3aca5f3bf02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f06f2a4076474809ae08c1318fe21257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3de5e50af1b46d09e5072ab4417bcf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4f576b01f9340eb816819d3d0a68747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c513a219d1d546ed8c0763b1f617fb5b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b8fbd717f7542b9a3d303c707f78de2",
              "IPY_MODEL_7271e4afbb3d443999f55b0f20c13895"
            ]
          }
        },
        "c513a219d1d546ed8c0763b1f617fb5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b8fbd717f7542b9a3d303c707f78de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27e5859662214100bcf50f70ce265022",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 98614501,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 98614501,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44a15dd7950045aba297394bf83aa0a0"
          }
        },
        "7271e4afbb3d443999f55b0f20c13895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e503d3bbc55b44ba8e070a8e9b14bf10",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 98.6M/98.6M [00:03&lt;00:00, 25.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c1ba722a9ad4649b928d3068d310de0"
          }
        },
        "27e5859662214100bcf50f70ce265022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44a15dd7950045aba297394bf83aa0a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e503d3bbc55b44ba8e070a8e9b14bf10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c1ba722a9ad4649b928d3068d310de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/tutos/blob/master/F3_DocQVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSruUD6mT-5X",
        "outputId": "4d9eb50d-20f1-4e70-f9f6-500d788d16c3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jan  9 06:29:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbYr6Eam-y_4",
        "outputId": "9c741c11-ce77-4a72-8fe4-2d305c834674"
      },
      "source": [
        "%%time\n",
        "!tar -xf /content/drive/MyDrive/Colab\\ Notebooks/Final-project/train.tar.gz \n",
        "!tar -xf /content/drive/MyDrive/Colab\\ Notebooks/Final-project/val.tar.gz \n",
        "!tar -xf /content/drive/MyDrive/Colab\\ Notebooks/Final-project/test.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 411 ms, sys: 68.6 ms, total: 479 ms\n",
            "Wall time: 3min 30s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka8XiM-bicvy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534e9814-2ad8-447d-fcdf-000d5bde497f"
      },
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q hermetrics"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.5MB 13.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 66.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 62.1MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b7BubuuiYRZ"
      },
      "source": [
        "# Python / Básics\n",
        "import os\n",
        "import gc\n",
        "import json\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import collections\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "# Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        " \n",
        "# Transformers \n",
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "from transformers import MobileBertTokenizer, MobileBertForQuestionAnswering"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "49de2a6db52840b096d3dfbe1a6fa1da",
            "28cfe900dfae45a297c384513e1e98b7",
            "fe04a42e6b454f069ea3ce4de206aba3",
            "6c51f2f276544e2cb07f007916779b98",
            "95d95ca50f2c4cd8bd562acfac5bede7",
            "2dbdf5270d114306b777e20f3c54e41b",
            "9f7a9205d0654a98bf16a7a515d25468",
            "4e135e3243aa4738be86d4b906c3258f",
            "781b36b580d04057843d5f9a76e480e3",
            "beb0e27b96d34fbfa931992237e5904b",
            "732988eb935848319469878478c2e4e4",
            "08d0f66236fa4273b6866455cd9bb78e",
            "9c34902948114d9ea3cd016bf81c19a1",
            "e204e0c3d19b497ea2e086ec480bd82b",
            "1b2f5a8fad7b4f7294a0cbd8bb7a5263",
            "3de7b874ed7b4cf2bf7d163563425378",
            "0af49bcba501461e8b6474302d00741a",
            "7d7f8d84a065429dbdb4de4188d45308",
            "4406aafc74c2402999ddb1a8464e7e07",
            "da1d9312749f4438a219d95dd8b1dd01",
            "18be3fc24bbd47b98b03098d68ad1822",
            "6b4320f1fb3e4808bc0124e742c68e97",
            "4d5d683398a549dd8aa1a5f40bf00c89",
            "14de92a6ce45496eaf2038075e47c4d0"
          ]
        },
        "id": "l9oVHkzMUc2m",
        "outputId": "868504dd-704b-43ac-e2a4-e8b56e5ae989"
      },
      "source": [
        "model_checkpoint = 'mrm8488/mobilebert-uncased-finetuned-squadv1'\n",
        "tokenizer = MobileBertTokenizer.from_pretrained(model_checkpoint)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49de2a6db52840b096d3dfbe1a6fa1da",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "781b36b580d04057843d5f9a76e480e3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0af49bcba501461e8b6474302d00741a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=85.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QafApgcKijGp",
        "outputId": "2b2a493e-c4cd-4a5d-ad11-ca235976f0ef"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "manual_seed = 2357 # only primers ;)\n",
        " \n",
        "def deterministic(rep=True):\n",
        "    if rep:\n",
        "        np.random.seed(manual_seed)\n",
        "        torch.manual_seed(manual_seed)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(manual_seed)\n",
        "            torch.cuda.manual_seed_all(manual_seed)\n",
        "        torch.backends.cudnn.enabled = False \n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(f'Experimento deterministico, seed: {manual_seed} -- ', end = '')\n",
        "        print(f'Existe {torch.cuda.device_count()} GPU\\\n",
        " {torch.cuda.get_device_name(0)} disponível.')\n",
        "    else:\n",
        "        print('Experimento randomico')\n",
        "deterministic()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla V100-SXM2-16GB disponível.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42hrfXOL12KB"
      },
      "source": [
        "TRANS_IMG = transforms.Compose([transforms.Resize((640, 480)), transforms.ToTensor()])\n",
        "MAX_LEN = 450 \n",
        "\n",
        "def get_questions_context_answers_and_file_images(path, phase):\n",
        "    with open(path, 'rb') as handle:\n",
        "        dataset = json.loads(handle.read())\n",
        "    \n",
        "    contexts = []\n",
        "    phase = phase+'/'\n",
        "    for i, d in enumerate(dataset['data']):\n",
        "        ocr_file = d['image'].replace('documents', 'ocr_results').replace('.png', '.json')\n",
        "        \n",
        "        with open(phase + ocr_file, 'rb') as f:\n",
        "            ocr = json.loads(f.read())\n",
        "    \n",
        "        lines = ocr['recognitionResults'][0]['lines']\n",
        "    \n",
        "        text = ' '.join([w['text'] for l in lines for w in l['words']])\n",
        "        contexts.append(lines)\n",
        "    \n",
        "    context_samples = []\n",
        "    for i, doc in enumerate(contexts):\n",
        "        test_list_item = []\n",
        "        for item in doc:\n",
        "            test_list_item.append(item['text'])\n",
        "        context_samples.append(' '.join(test_list_item).lower())\n",
        "    \n",
        "    # --> Questions \n",
        "    questions_samples = []\n",
        "    for d in dataset['data']:\n",
        "        questions_samples.append(d['question'].lower())\n",
        "    \n",
        "    # --> Answers\n",
        "    answers_samples = []\n",
        "    for d in dataset['data']:\n",
        "        answers_samples.append(d['answers'][0].lower())\n",
        "    \n",
        "    # --> Images files \n",
        "    img_file_samples = []\n",
        "    for image in dataset['data']:\n",
        "        img_file = image['image']\n",
        "        img_file_samples.append(phase+img_file)        \n",
        "    \n",
        "    questions, contexts, answers, img_files = [], [], [], []\n",
        "    for q,c,a, im_f in zip(questions_samples, context_samples, answers_samples, img_file_samples):\n",
        "        questions.append(q)\n",
        "        contexts.append(c)\n",
        "        answers.append(a)\n",
        "        img_files.append(im_f)\n",
        "    \n",
        "    return questions, contexts, answers, img_files\n",
        "\n",
        "def get_final_data(path, phase, max_len=MAX_LEN):\n",
        "    questions, context, answers, img_files = get_questions_context_answers_and_file_images(path, phase)\n",
        "    data = pd.DataFrame([])\n",
        "    for quest, cont, ans, img_file in zip(questions, context, answers, img_files):\n",
        "        data = data.append(\n",
        "            pd.DataFrame(\n",
        "                {\n",
        "                    'Img_file':img_file,\n",
        "                    'Question': quest,\n",
        "                    'Context': cont,\n",
        "                    'Answer': ans,\n",
        "                }, index=[0]), ignore_index=True)\n",
        "    \n",
        "    start_position_label, end_position_label = [], []\n",
        "    for i, (c, l) in enumerate(zip(\n",
        "        data.Context.to_list(), \n",
        "        data.Answer.to_list()\n",
        "        )):\n",
        "        start_index = c.find(l)\n",
        "        end_index = start_index + len(l)\n",
        "        if start_index != -1: \n",
        "            start_position_label.append(start_index)\n",
        "            end_position_label.append(end_index)\n",
        "        else:\n",
        "            start_position_label.append(None)\n",
        "            end_position_label.append(None)\n",
        "\n",
        "    data = data.assign(start_pos_label = start_position_label)\n",
        "    data = data.assign(end_pos_label = end_position_label)\n",
        "\n",
        "    data_cutted = _apply_cut(data, max_len=MAX_LEN)\n",
        "    \n",
        "    return data_cutted \n",
        "\n",
        "def _apply_cut(df, max_len=MAX_LEN):\n",
        "    df_ = df[~df.start_pos_label.isna()]\n",
        "    df_ = df_[df_.start_pos_label<max_len]\n",
        "    df_ = df_.assign(start_pos_label = df_.start_pos_label.apply(lambda x: int(x)))\n",
        "    df_ = df_.assign(end_pos_label = df_.end_pos_label.apply(lambda x: int(x)))\n",
        "    return df_\n",
        "\n",
        "class DVQADataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len=MAX_LEN, transform=TRANS_IMG):\n",
        "        super().__init__()\n",
        "\n",
        "        data = df.copy()\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.question = data.Question.to_list()\n",
        "        self.context = data.Context.to_list()\n",
        "        self.answer = data.Answer.to_list()\n",
        "        self.start_pos_label = data.start_pos_label.to_list()\n",
        "        self.end_pos_label = data.end_pos_label.to_list()\n",
        "        self.img_files = data.Img_file.to_list()\n",
        "        self.max_len = max_len\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.question)\n",
        "\n",
        "        return image\n",
        "\n",
        "    def _sentinela_mask(self, context, answer, start_label, end_label):\n",
        "        start_char_i = start_label \n",
        "        end_char_i = end_label     \n",
        "        answer_tokens = self.tokenizer.tokenize(answer)\n",
        "        sentinel_str = ' '.join(['[MASK]']*len(answer_tokens))\n",
        "        context_w_sentinel = context[:start_char_i] + sentinel_str + context[end_char_i:]\n",
        "        return answer_tokens, context_w_sentinel\n",
        "\n",
        "    def _tokenize_data(self, question, context, answer, start_label, end_label):\n",
        "        answer_tokens, context_w_sentinel = self._sentinela_mask(context, answer, start_label, end_label)\n",
        "        encoded_dict = self.tokenizer.encode_plus(\n",
        "            question, \n",
        "            context_w_sentinel,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True, \n",
        "            return_tensors = 'pt',      \n",
        "        )\n",
        "        input_ids = encoded_dict['input_ids']\n",
        "        is_mask_token = (input_ids[0] == self.tokenizer.mask_token_id)\n",
        "        mask_token_indeces = is_mask_token.nonzero(as_tuple=False)[:, 0]\n",
        "\n",
        "        assert len(mask_token_indeces) == len(answer_tokens)\n",
        "        \n",
        "        start_index = mask_token_indeces[0]\n",
        "        end_index = mask_token_indeces[-1]\n",
        "\n",
        "        answer_token_ids = self.tokenizer.encode(\n",
        "            answer_tokens, \n",
        "            add_special_tokens=False, \n",
        "            return_tensors='pt'\n",
        "            )\n",
        "\n",
        "        input_ids[0, start_index : end_index + 1] = answer_token_ids\n",
        "        attention_mask = encoded_dict['attention_mask']    \n",
        "        segment_ids = encoded_dict['token_type_ids']\n",
        "    \n",
        "        return input_ids, attention_mask, segment_ids, start_index, end_index\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.img_files[idx]).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        \n",
        "        input_ids, attention_mask, segment_ids, start_index, end_index = self._tokenize_data(\n",
        "            self.question[idx], \n",
        "            self.context[idx], \n",
        "            self.answer[idx], \n",
        "            self.start_pos_label[idx], \n",
        "            self.end_pos_label[idx]\n",
        "            )\n",
        "\n",
        "        return (img, self.question[idx], self.context[idx], self.answer[idx], \n",
        "                input_ids.squeeze(0), attention_mask.squeeze(0), \n",
        "                segment_ids.squeeze(0), start_index, end_index)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwwLfOSnVlHj",
        "outputId": "0124c114-7dc4-42ac-ae7f-94894b9f7fe4"
      },
      "source": [
        "# Test do dataset:\n",
        "\n",
        "paths = {\n",
        "    'val': {\n",
        "        'path': 'val/val_v1.0.json',\n",
        "        'phase': 'val',\n",
        "        },\n",
        "    'train': {\n",
        "        'path': 'train/train_v1.0.json',\n",
        "        'phase': 'train',\n",
        "        }         \n",
        "}\n",
        "\n",
        "df_val = get_final_data(\n",
        "    path=paths['val']['path'], \n",
        "    phase=paths['val']['phase']\n",
        "    )\n",
        "print(f'DF_VAL  : {df_val.shape}')\n",
        "\n",
        "df_train = get_final_data(\n",
        "    path=paths['train']['path'], \n",
        "    phase=paths['train']['phase']\n",
        "    )\n",
        "print(f'DF_TRAIN: {df_train.shape}\\n')\n",
        "\n",
        "ds_train = DVQADataset(\n",
        "    df=df_train,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN,\n",
        "    transform=TRANS_IMG, \n",
        ")\n",
        "\n",
        "img, question, context, answer, input_ids, attention_mask, segment_ids, start_index, end_index = ds_train[-1]\n",
        "outs  = [img, question, context, answer, input_ids, attention_mask, segment_ids, start_index, end_index]\n",
        "names = ['img', 'question', 'context', 'answer', 'input_ids', 'attention_mask', 'segment_ids', 'start_index', 'end_index']\n",
        "for out, name in zip(outs, names):\n",
        "    if type(out) != str and name.find('index') ==-1:\n",
        "        print(name, f':{out.size()}')\n",
        "    else:\n",
        "        print(name,':', out)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DF_VAL  : (3058, 6)\n",
            "DF_TRAIN: (23403, 6)\n",
            "\n",
            "img :torch.Size([3, 640, 480])\n",
            "question : what is the table number ?\n",
            "context : table 4-a relative risk of falling into extreme 20% according to supplementation ingestion and socioeconomic status variable: composite infant scale 15 month mental score sample size (n's) percentages chi-square test performance group total sample low ' med. 2 high tot. low med. high tot. x 2 d.f. 2 supplementation 52 101 24 177 29 57 14 100 27.1 4 2.01 44 157 54 255 17 62 21 100 category : n 5 46 26 77 60 34 100 101 304 104 509 20 60 20 low ses o 23 50 79 29 63 8 100 18.4 4 4.01 22 79 29 130 17 61 22 100 in 28 13 43 5 65 30 100 t 47 157 48 252 19 62 19 high ses 0 27 45 18 90 30 50 20 100 11.7 4 l.05 22 75 25 122 18 61. 20 100 n 3 18 13 34 9 53 38 100 52 138 56 246 21 56 23 1 = lowest pentile 2 = middle 60% of scores 3 = highest pentile source: https://www.industrydocuments.ucsf.edu/docs/yyhd0227\n",
            "answer : 4-a\n",
            "input_ids :torch.Size([450])\n",
            "attention_mask :torch.Size([450])\n",
            "segment_ids :torch.Size([450])\n",
            "start_index : tensor(9)\n",
            "end_index : tensor(11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvD_fdTzFIDf",
        "outputId": "8cf06e57-a815-4a5e-f972-ada16c24dae1"
      },
      "source": [
        "BATCH_SZ = 8\n",
        "\n",
        "# TRAIN Dataset\n",
        "ds_train = DVQADataset(\n",
        "    df=df_train,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN,\n",
        "    transform=TRANS_IMG, \n",
        ")\n",
        "\n",
        "# Debug Dataset (100 samples)\n",
        "ds_debug = DVQADataset(\n",
        "    df=df_train[:100],\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN,\n",
        "    transform=TRANS_IMG, \n",
        ")\n",
        "\n",
        "# VAL Dataset\n",
        "ds_val = DVQADataset(\n",
        "    df=df_val,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN,\n",
        "    transform=TRANS_IMG, \n",
        ")\n",
        "\n",
        "# Dataloaders\n",
        "dataloaders = {\n",
        "    'debug': DataLoader(\n",
        "         ds_debug,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=False,\n",
        "         num_workers=os.cpu_count(),\n",
        "         pin_memory=True\n",
        "         ),\n",
        "    'train': DataLoader(\n",
        "         ds_train,\n",
        "         batch_size=BATCH_SZ,\n",
        "         shuffle=True,\n",
        "         num_workers=os.cpu_count(),\n",
        "         pin_memory=True\n",
        "         ),\n",
        "    'val': DataLoader(\n",
        "         ds_val,\n",
        "         batch_size=BATCH_SZ,\n",
        "         num_workers=os.cpu_count(),\n",
        "         pin_memory=True\n",
        "         ),\n",
        "     }\n",
        " \n",
        "# teste de sanidade\n",
        "_ = {x: len(dataloaders[x]) for x in dataloaders.keys()}\n",
        "_"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'debug': 13, 'train': 2926, 'val': 383}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcDpfio4AEq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a52cc0-5177-44f5-adb6-a0de6d70c951"
      },
      "source": [
        "# Teste do Dataloader \n",
        "img, question, context, answer, input_ids, attention_mask, segment_ids, start_pos, end_pos = next(iter(dataloaders['debug']))\n",
        "print('img.shape:             ', img.shape)\n",
        "print('question:              ', question)\n",
        "print('context:               ', context)\n",
        "print('answer:                ', answer)\n",
        "print('input_ids.shape:       ', input_ids.shape)\n",
        "print('attention_masks.shape: ', attention_mask.shape)\n",
        "print('segment_ids.shape:     ', segment_ids.shape)\n",
        "print('start_positions.shape: ', start_pos)\n",
        "print('end_positions.shape:   ', end_pos)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "img.shape:              torch.Size([8, 3, 640, 480])\n",
            "question:               ['what is the contact person name mentioned in letter?', \"which corporation's letterhead is this?\", 'who is in  cc in this letter?', 'what is the subject of  this letter?', 'what is the date in the letter', 'who sent the letter?', 'which part of virginia is this letter sent from', 'what is the date mentioned in the letter?']\n",
            "context:                ['confidential .. .. rjrt pr approval date : 1/8/13 ru alas proposed release date: for response for release to: contact: p. carter route to initials pate peggy carter ac maura payne david fishel tom griscom diane barrows ed blackmer tow rucker tr return to peggy carter, pr, 16 reynolds building 51142 3977 . . source: https://www.industrydocuments.ucsf.edu/docs/xnb10037', 'b&w brown & williamson tobacco corporation research & development . . . . internal correspondence to: r. h. honeycutt cc: t.f. riehl from: c. j. cook date: may 8. 1995 subject: review of existing brainstorming ideas/483 the major function of the product innovation group is to develop marketable novel products that would be profitable to manufacture and sell. novel is defined as: of a new kind, or different from anything seen or known before. innovation is defined as: something new or different introduced; act of innovating; introduction of new things or methods. the products may ncorporate the latest technologies, materials and know-how available to give then a unique taste or look. the first task of the product innovation group was to assemble, review and categorize a list of existing brainstorming ideas. ideas were grouped into two major categories labeled appearance and taste/aroma. these categories are used for novel products that may differ from a visual and/or taste/aroma point of view compared to conventional cigarettes. other categories include a combination of the above, filters, packaging and brand extensions. appearance this category is used for novel cigarette constructions that yield visually different products with minimal changes in smoke chemistry two cigarettes in one .multi-plug to build your own cigarette. .switchable menthol or non menthol cigarette. future smoking. cigarettes with interspaced perforations to enable smoker to separate unburned section for .short cigarette, tobacco section 30 mm. . extremely fast buming cigarette. -. ..\". \" . . novel cigarette constructions that permit a significant reduction in tobacco weight while maintaining smoking mechanics and visual characteristics. . . . . higher basis weight paper; potential reduction in tobacco weight. . more rigid tobacco column; stiffing agent for tobacco; e.g. starch . colored tow and cigarette papers; seasonal promotions, e.g. pastel colored cigarettes for easter or in an ebony and ivory brand containing a mixture of all black (black paper and tow) and all white cigarettes. 499150498 source: https://www.industrydocuments.ucsf.edu/docs/mxcj0037', 'b&w brown & williamson tobacco corporation research & development . . . . internal correspondence to: r. h. honeycutt cc: t.f. riehl from: c. j. cook date: may 8. 1995 subject: review of existing brainstorming ideas/483 the major function of the product innovation group is to develop marketable novel products that would be profitable to manufacture and sell. novel is defined as: of a new kind, or different from anything seen or known before. innovation is defined as: something new or different introduced; act of innovating; introduction of new things or methods. the products may ncorporate the latest technologies, materials and know-how available to give then a unique taste or look. the first task of the product innovation group was to assemble, review and categorize a list of existing brainstorming ideas. ideas were grouped into two major categories labeled appearance and taste/aroma. these categories are used for novel products that may differ from a visual and/or taste/aroma point of view compared to conventional cigarettes. other categories include a combination of the above, filters, packaging and brand extensions. appearance this category is used for novel cigarette constructions that yield visually different products with minimal changes in smoke chemistry two cigarettes in one .multi-plug to build your own cigarette. .switchable menthol or non menthol cigarette. future smoking. cigarettes with interspaced perforations to enable smoker to separate unburned section for .short cigarette, tobacco section 30 mm. . extremely fast buming cigarette. -. ..\". \" . . novel cigarette constructions that permit a significant reduction in tobacco weight while maintaining smoking mechanics and visual characteristics. . . . . higher basis weight paper; potential reduction in tobacco weight. . more rigid tobacco column; stiffing agent for tobacco; e.g. starch . colored tow and cigarette papers; seasonal promotions, e.g. pastel colored cigarettes for easter or in an ebony and ivory brand containing a mixture of all black (black paper and tow) and all white cigarettes. 499150498 source: https://www.industrydocuments.ucsf.edu/docs/mxcj0037', 'b&w brown & williamson tobacco corporation research & development . . . . internal correspondence to: r. h. honeycutt cc: t.f. riehl from: c. j. cook date: may 8. 1995 subject: review of existing brainstorming ideas/483 the major function of the product innovation group is to develop marketable novel products that would be profitable to manufacture and sell. novel is defined as: of a new kind, or different from anything seen or known before. innovation is defined as: something new or different introduced; act of innovating; introduction of new things or methods. the products may ncorporate the latest technologies, materials and know-how available to give then a unique taste or look. the first task of the product innovation group was to assemble, review and categorize a list of existing brainstorming ideas. ideas were grouped into two major categories labeled appearance and taste/aroma. these categories are used for novel products that may differ from a visual and/or taste/aroma point of view compared to conventional cigarettes. other categories include a combination of the above, filters, packaging and brand extensions. appearance this category is used for novel cigarette constructions that yield visually different products with minimal changes in smoke chemistry two cigarettes in one .multi-plug to build your own cigarette. .switchable menthol or non menthol cigarette. future smoking. cigarettes with interspaced perforations to enable smoker to separate unburned section for .short cigarette, tobacco section 30 mm. . extremely fast buming cigarette. -. ..\". \" . . novel cigarette constructions that permit a significant reduction in tobacco weight while maintaining smoking mechanics and visual characteristics. . . . . higher basis weight paper; potential reduction in tobacco weight. . more rigid tobacco column; stiffing agent for tobacco; e.g. starch . colored tow and cigarette papers; seasonal promotions, e.g. pastel colored cigarettes for easter or in an ebony and ivory brand containing a mixture of all black (black paper and tow) and all white cigarettes. 499150498 source: https://www.industrydocuments.ucsf.edu/docs/mxcj0037', 'philip morris u. s. a. inter-office correspondence richmond, virginia to dr. k. s. houghton date: june 11, 1990 from: ted sanders subject: paper technology update for the week of june 4 reduced sidestream trim short-term plans have been formulated to address customer complaints regarding virginia slims superslims. models will be made which will evaluate lower tobacco density, use of outer wraps coated with potassium phosphate and/or short chain dicarboxylic acids (malonic and succinic), outer wraps containing mixed chalk (albacar and multifex), charcoal filters, increased chalk content in the inner wrap, increased basis weight for the inner wrap, and increased tar delivery (9 mg). a memo has been issued by jeanette hickle outlining the schedule for making these models. a longer term approach directed at improving subjectives is to design an outer wrap using mono potassium phosphate as the fluxing agent but at a porosity higher than has been investigated for full circumference cigarettes. calculations have indicated that the greater effectiveness of the multifex calcium carbonate/mono potassium phosphate system compared to the multifex calcium carbonate/potassium succinate system can allow outer wraps to be designed with coresta porosities of up to 12 and still obtain greater than 70% sidestream reduction for a 17 mm circumference cigarette. a superslims model with 50% of the multifex chalk replaced by albacar chalk in the outer wrap was tested on the mc panel versus a control superslims. no significant differences were seen in any of the attributes. the only analytical difference was the slower burn rate of the 50:50 model. although both of these models were essentially similar in every respect, they were both out of spec with regard to delivery (7 mg tar). consequently, these models will be remade in louisville to the correct tar delivery. lotus the low sidestream panel evaluated full circumference cigarettes with the superslims double wrap system on marlboro blend. one model used 100% multifex chalk, while the other model had a 50:50 multifex/albacar mixture as the inorganic filler. although neither model was judged to be subjectively acceptable, the panel could detect no differences between the models. 2022155886 c90-03066 source: https://www.industrydocuments.ucsf.edu/docs/nhxj0037', 'philip morris u. s. a. inter-office correspondence richmond, virginia to dr. k. s. houghton date: june 11, 1990 from: ted sanders subject: paper technology update for the week of june 4 reduced sidestream trim short-term plans have been formulated to address customer complaints regarding virginia slims superslims. models will be made which will evaluate lower tobacco density, use of outer wraps coated with potassium phosphate and/or short chain dicarboxylic acids (malonic and succinic), outer wraps containing mixed chalk (albacar and multifex), charcoal filters, increased chalk content in the inner wrap, increased basis weight for the inner wrap, and increased tar delivery (9 mg). a memo has been issued by jeanette hickle outlining the schedule for making these models. a longer term approach directed at improving subjectives is to design an outer wrap using mono potassium phosphate as the fluxing agent but at a porosity higher than has been investigated for full circumference cigarettes. calculations have indicated that the greater effectiveness of the multifex calcium carbonate/mono potassium phosphate system compared to the multifex calcium carbonate/potassium succinate system can allow outer wraps to be designed with coresta porosities of up to 12 and still obtain greater than 70% sidestream reduction for a 17 mm circumference cigarette. a superslims model with 50% of the multifex chalk replaced by albacar chalk in the outer wrap was tested on the mc panel versus a control superslims. no significant differences were seen in any of the attributes. the only analytical difference was the slower burn rate of the 50:50 model. although both of these models were essentially similar in every respect, they were both out of spec with regard to delivery (7 mg tar). consequently, these models will be remade in louisville to the correct tar delivery. lotus the low sidestream panel evaluated full circumference cigarettes with the superslims double wrap system on marlboro blend. one model used 100% multifex chalk, while the other model had a 50:50 multifex/albacar mixture as the inorganic filler. although neither model was judged to be subjectively acceptable, the panel could detect no differences between the models. 2022155886 c90-03066 source: https://www.industrydocuments.ucsf.edu/docs/nhxj0037', 'philip morris u. s. a. inter-office correspondence richmond, virginia to dr. k. s. houghton date: june 11, 1990 from: ted sanders subject: paper technology update for the week of june 4 reduced sidestream trim short-term plans have been formulated to address customer complaints regarding virginia slims superslims. models will be made which will evaluate lower tobacco density, use of outer wraps coated with potassium phosphate and/or short chain dicarboxylic acids (malonic and succinic), outer wraps containing mixed chalk (albacar and multifex), charcoal filters, increased chalk content in the inner wrap, increased basis weight for the inner wrap, and increased tar delivery (9 mg). a memo has been issued by jeanette hickle outlining the schedule for making these models. a longer term approach directed at improving subjectives is to design an outer wrap using mono potassium phosphate as the fluxing agent but at a porosity higher than has been investigated for full circumference cigarettes. calculations have indicated that the greater effectiveness of the multifex calcium carbonate/mono potassium phosphate system compared to the multifex calcium carbonate/potassium succinate system can allow outer wraps to be designed with coresta porosities of up to 12 and still obtain greater than 70% sidestream reduction for a 17 mm circumference cigarette. a superslims model with 50% of the multifex chalk replaced by albacar chalk in the outer wrap was tested on the mc panel versus a control superslims. no significant differences were seen in any of the attributes. the only analytical difference was the slower burn rate of the 50:50 model. although both of these models were essentially similar in every respect, they were both out of spec with regard to delivery (7 mg tar). consequently, these models will be remade in louisville to the correct tar delivery. lotus the low sidestream panel evaluated full circumference cigarettes with the superslims double wrap system on marlboro blend. one model used 100% multifex chalk, while the other model had a 50:50 multifex/albacar mixture as the inorganic filler. although neither model was judged to be subjectively acceptable, the panel could detect no differences between the models. 2022155886 c90-03066 source: https://www.industrydocuments.ucsf.edu/docs/nhxj0037', 'philip morris. u. s. a. inter - office correspondence richmond, virginia to : mr. james l. myracle date: april 27, 1990 from : h. l. spielberg subject: flavor. development monthly summary for april, 1990 c90-03267 project art : samples of the gmc, 8842-5 aftercut and pol 0704 models were sent to ard for method development and quantification of gmc on filler and in solution. preliminary analytical data indicate approximately 75% of the target level of gmc is on the filler. additional models were also submitted for analyses. these included the 208 and 408 reduced level, control level and 208 increased level of gmc on filler. the lowest acceptable ov study has been initiated on the 9 mg non- menthol salesman samples. models are complete at 10.8, 11.3, 11.9, 12.7, 13.0 and 13.68 ov. these models will be subjectively evaluated against a control product at 13.08 ov. production of next ks and 100\\'s for the tampa, florida test market began c shift april 23, 1990 at the mc. menthol production is complete and non-menthol production will be complete by the end of the week. evaluations of citric acid stems from single versus double-batched trials have shown promise at the 28 substitution level in pilot rl. after the flavor development panel showed the single to be comparable to double- batched stems, results of the mc panel showed no differences between the control and double-batched test rl in marlboro. similar comparisons at the 58 substitution level in production rcb are in progress . combinations of test rl and rcb will be selected to determine utilization levels. qualification of double-batched stems at specific levels should allow usage of single or half-batched stems being tested at bermuda hundred nippon art concept danchi test to evaluate tar and tipping color variations has been shipped. a second danchi test to evaluate art menthol levels has been shipped. small-scale samples were made to evaluate pm super lights and \"castor\" type flavors. tar/nicotine interaction : subjective studies : a tar/nicotine interaction study to assess 1010 mm models from 3 to 15 mg tar and from 0.3 to 1.58 filler nicotine is in progress. 2022156205 source: https://www.industrydocuments.ucsf.edu/docs/mxxj0037']\n",
            "answer:                 ['p. carter', 'brown & williamson tobacco corporation', 't.f. riehl', 'review of existing brainstorming ideas/483', 'june 11, 1990', 'ted sanders', 'richmond', 'april 27, 1990']\n",
            "input_ids.shape:        torch.Size([8, 450])\n",
            "attention_masks.shape:  torch.Size([8, 450])\n",
            "segment_ids.shape:      torch.Size([8, 450])\n",
            "start_positions.shape:  tensor([44, 14, 38, 60, 34, 38, 23, 38])\n",
            "end_positions.shape:    tensor([46, 18, 44, 69, 37, 39, 23, 41])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEISWYWoyan5"
      },
      "source": [
        "def metric_Levenshtein(seq1, seq2):\n",
        "    lev = Levenshtein()\n",
        "    return lev.distance(seq1, seq2)\n",
        "\n",
        "def normalize_answer(s):\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        " \n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        " \n",
        "    return white_space_fix(lower(s))\n",
        " \n",
        "def get_tokens(s):\n",
        "    if not s: return []\n",
        "    return normalize_answer(s).split()\n",
        " \n",
        "def _compute_exact(a_gold, a_pred):\n",
        "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
        " \n",
        "def _compute_f1(a_gold, a_pred):\n",
        "    gold_toks = get_tokens(a_gold)\n",
        "    pred_toks = get_tokens(a_pred)\n",
        "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "    num_same = sum(common.values())\n",
        "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
        "        return int(gold_toks == pred_toks)\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(pred_toks)\n",
        "    recall = 1.0 * num_same / len(gold_toks)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def train_model(model, device, train_loader, optimizer, scheduler):\n",
        "    size = len(train_loader)    \n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        " \n",
        "    for step, batch in enumerate(train_loader):\n",
        "        model.zero_grad()        \n",
        "        \n",
        "        batch_device = tuple(t.to(device) if type(t) != list else t for t in batch)\n",
        "        b_img, b_question, b_context, b_answer, b_input_ids, b_attention_mask, b_segment_ids, b_start_pos, b_end_pos = batch_device\n",
        "        \n",
        "        outputs = model(\n",
        "            b_input_ids, \n",
        "            attention_mask=b_attention_mask, \n",
        "            token_type_ids = b_segment_ids,\n",
        "            start_positions=b_start_pos,\n",
        "            end_positions=b_end_pos\n",
        "            )\n",
        " \n",
        "        loss = outputs['loss']\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / size            \n",
        " \n",
        "    return avg_train_loss\n",
        " \n",
        "def get_score(model, val_loader, max_len=MAX_LEN):\n",
        "    model.eval()\n",
        "    size = len(val_loader) * BATCH_SZ\n",
        "    trues, preds = [],[]\n",
        "\n",
        "    for step, batch in enumerate(val_loader):\n",
        "        batch_device = tuple(t.to(device) if type(t) != list else t for t in batch)\n",
        "        _, b_question, b_context, b_answer, _, _, _, _, _ = batch_device\n",
        "\n",
        "        for question, context, answer in zip(b_question, b_context, b_answer):\n",
        "            input_ids = tokenizer.encode(\n",
        "                    question, \n",
        "                    context,\n",
        "                    max_length=max_len, \n",
        "                    truncation=True,\n",
        "                    )\n",
        "            sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "            num_seg_a = sep_index + 1\n",
        "            num_seg_b = len(input_ids) - num_seg_a\n",
        "            segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "        \n",
        "            assert len(segment_ids) == len(input_ids)\n",
        "        \n",
        "            with torch.no_grad():        \n",
        "                outputs = model(\n",
        "                    torch.tensor([input_ids]).to(device), \n",
        "                    token_type_ids=torch.tensor([segment_ids]).to(device)) \n",
        "                    \n",
        "            start_logits = outputs['start_logits']\n",
        "            end_logits = outputs['end_logits']\n",
        "            answer_start = torch.argmax(start_logits)\n",
        "            answer_end = torch.argmax(end_logits)\n",
        "        \n",
        "            tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "            pred_answers = tokens[answer_start]\n",
        "        \n",
        "            for i in range(answer_start + 1, answer_end + 1):\n",
        "                if tokens[i][0:2] == '##':\n",
        "                    pred_answers += tokens[i][2:]\n",
        "                else:\n",
        "                    pred_answers += ' ' + tokens[i]\n",
        "            \n",
        "            preds.append(pred_answers)\n",
        "            trues.append(answer)\n",
        "\n",
        "    exact_result = sum([_compute_exact(ans, pred) for ans, pred in zip(trues, preds)]) / size\n",
        "    f1_result = sum([_compute_f1(ans, pred) for ans, pred in zip(trues, preds)]) / size\n",
        "        \n",
        "    return f1_result, exact_result"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H0j5CmBet7j"
      },
      "source": [
        "# Overfit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642,
          "referenced_widgets": [
            "53251e3f27d44819822d450e016454b1",
            "772d056f8beb4bac80b9ae41056dda92",
            "d964d7cb0ce244f0b45e18f509054cdf",
            "56dd4f7c166b40099f823adc09af05b1",
            "7266a77b53bb4f4ba929c88c19fca651",
            "cbe49764b04c446aa865f3aca5f3bf02",
            "f06f2a4076474809ae08c1318fe21257",
            "d3de5e50af1b46d09e5072ab4417bcf0",
            "a4f576b01f9340eb816819d3d0a68747",
            "c513a219d1d546ed8c0763b1f617fb5b",
            "2b8fbd717f7542b9a3d303c707f78de2",
            "7271e4afbb3d443999f55b0f20c13895",
            "27e5859662214100bcf50f70ce265022",
            "44a15dd7950045aba297394bf83aa0a0",
            "e503d3bbc55b44ba8e070a8e9b14bf10",
            "7c1ba722a9ad4649b928d3068d310de0"
          ]
        },
        "id": "0V7HwBvXewDD",
        "outputId": "0781dc17-fcd7-4043-cbce-9cd37e42f0f5"
      },
      "source": [
        "OVERFIT = True\n",
        "\n",
        "if OVERFIT:\n",
        "    deterministic()\n",
        "    N_EPOCHS = 10\n",
        "    try:\n",
        "        del model\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    model = MobileBertForQuestionAnswering.from_pretrained(model_checkpoint, return_dict=True).to(device)\n",
        "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "    total_steps = (len(dataloaders['debug']) * N_EPOCHS)\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=total_steps*0.01, num_training_steps=total_steps)\n",
        "\n",
        "    for epoch_i in range(1, N_EPOCHS+1):\n",
        "        loss_train = train_model(model, device, dataloaders['debug'], optimizer, scheduler)\n",
        "        print(f'\\nEpoca [{epoch_i}/{N_EPOCHS}]: Loss Train: {loss_train:.3f}')\n",
        "        f1_result, exact_result = get_score(model, dataloaders['debug'])\n",
        "        print(f'              Exact Match: {exact_result:.4f} -- F1: {f1_result:.4}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla V100-SXM2-16GB disponível.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53251e3f27d44819822d450e016454b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=765.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4f576b01f9340eb816819d3d0a68747",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=98614501.0, style=ProgressStyle(descrip…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoca [1/10]: Loss Train: 2.141\n",
            "              Exact Match: 0.2019 -- F1: 0.4652\n",
            "\n",
            "Epoca [2/10]: Loss Train: 1.127\n",
            "              Exact Match: 0.2500 -- F1: 0.5132\n",
            "\n",
            "Epoca [3/10]: Loss Train: 0.766\n",
            "              Exact Match: 0.3077 -- F1: 0.5668\n",
            "\n",
            "Epoca [4/10]: Loss Train: 0.449\n",
            "              Exact Match: 0.3462 -- F1: 0.5896\n",
            "\n",
            "Epoca [5/10]: Loss Train: 0.412\n",
            "              Exact Match: 0.3846 -- F1: 0.6018\n",
            "\n",
            "Epoca [6/10]: Loss Train: 0.238\n",
            "              Exact Match: 0.3846 -- F1: 0.5982\n",
            "\n",
            "Epoca [7/10]: Loss Train: 0.154\n",
            "              Exact Match: 0.4038 -- F1: 0.6071\n",
            "\n",
            "Epoca [8/10]: Loss Train: 0.154\n",
            "              Exact Match: 0.4231 -- F1: 0.62\n",
            "\n",
            "Epoca [9/10]: Loss Train: 0.166\n",
            "              Exact Match: 0.4327 -- F1: 0.6248\n",
            "\n",
            "Epoca [10/10]: Loss Train: 0.120\n",
            "              Exact Match: 0.4327 -- F1: 0.6248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSb3SiHJrwJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c769a0-3395-46aa-9672-fd41faaa9997"
      },
      "source": [
        "deterministic()\n",
        "N_EPOCHS = 30\n",
        " \n",
        "try:\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "except:\n",
        "    pass\n",
        " \n",
        "path_save_model = '/content/drive/MyDrive/Colab Notebooks/Final-project/saved_epochs/'\n",
        "\n",
        "model = MobileBertForQuestionAnswering.from_pretrained(model_checkpoint, return_dict=True).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "total_steps = (len(dataloaders['train']) * N_EPOCHS)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=total_steps*0.01, num_training_steps=total_steps)\n",
        "#----------------------------------------------------------------\n",
        "\n",
        "training_stats = []\n",
        "for epoch_i in range(1, N_EPOCHS+1):\n",
        "        \n",
        "    loss_train = train_model(model, device, dataloaders['train'], optimizer, scheduler)\n",
        "    print(f'\\nEpoca [{epoch_i}/{N_EPOCHS}]: Loss Train: {loss_train:.3f}')\n",
        "    \n",
        "    f1_result, exact_result = get_score(model, dataloaders['val'])\n",
        "    print(f'              Exact Match: {exact_result:.4f} -- F1: {f1_result:.4}')\n",
        "\n",
        "    # saving\n",
        "    torch.save(model.state_dict(), path_save_model+'Mobile_F3'+str(epoch_i))\n",
        " \n",
        "    training_stats.append({'epoch': epoch_i, 'Training Loss': loss_train, 'Exact': exact_result, 'F1': f1_result})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experimento deterministico, seed: 2357 -- Existe 1 GPU Tesla V100-SXM2-16GB disponível.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuOEL7zoDdTJ"
      },
      "source": [
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "pd.set_option('precision', 2)\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpwgaOnPEUHT"
      },
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x7GIvNFw7mZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}