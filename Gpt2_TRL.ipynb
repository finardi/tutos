{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/tutos/blob/master/Gpt2_TRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf5CSeNiOYVN"
      },
      "source": [
        "<div style=\"text-align: center\">\n",
        "<img src='https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/gpt2-ctrl-training-setup.png' width='600'>\n",
        "<p style=\"text-align: center;\"> <b>Figure:</b> Experiment setup to tune GPT2. The yellow arrows are outside the scope of this notebook, but the trained models are available through Hugging Face. </p>\n",
        "</div>\n",
        "\n",
        "\n",
        "In this notebook we fine-tune GPT2 (small) to generate positive movie reviews based on the IMDB dataset. The model gets the start of a real review and is tasked to produce positive continuations. To reward positive continuations we use a BERT classifier to analyse the sentiment of the produced sentences and use the classifier's outputs as rewards signals for PPO training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPDrBMJiOZ2B"
      },
      "source": [
        "### Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgKVcbG7OZ2C"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lF1Leuq6OZ2D"
      },
      "outputs": [],
      "source": [
        "%pip install -q transformers trl wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG0z0DsSOZ2E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f7acaa-be4b-4209-9e30-71105f5dfeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experimento deterministico, seed: 2711 -- Existe 1 GPU Tesla T4 disponível.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import gc\n",
        "\n",
        "from transformers import pipeline, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "MANUAL_SEED  = 2711\n",
        "def deterministic(rep=True):\n",
        "    torch.manual_seed(MANUAL_SEED)\n",
        "    if torch.cuda.is_available():\n",
        "            torch.cuda.manual_seed(MANUAL_SEED)\n",
        "            torch.cuda.manual_seed_all(MANUAL_SEED)\n",
        "            torch.backends.cudnn.enabled = False \n",
        "            torch.backends.cudnn.benchmark = False\n",
        "            torch.backends.cudnn.deterministic = True\n",
        "            print(f'Experimento deterministico, seed: {MANUAL_SEED} -- ', end = '')\n",
        "            print(f'Existe {torch.cuda.device_count()} GPU {torch.cuda.get_device_name(0)} disponível.')\n",
        "    else:\n",
        "        print('Device CPU')\n",
        "deterministic()        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu00dpZjOZ2F"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CSGZY8POZ2F"
      },
      "outputs": [],
      "source": [
        "config = PPOConfig(\n",
        "    model_name='/content/drive/MyDrive/LLMs/ckpts/GPT_imdb',\n",
        "    learning_rate=1.41e-5,\n",
        "    log_with=\"wandb\",\n",
        "    batch_size=96,\n",
        "\n",
        ")\n",
        "\n",
        "# sent_pipeline\n",
        "sent_kwargs = {\n",
        "    \"return_all_scores\": True,\n",
        "    \"function_to_apply\": \"none\",\n",
        "    \"batch_size\": 12\n",
        "}\n",
        "\n",
        "model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
        "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(config.model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "PKyeTlXlOZ2G",
        "outputId": "f42b12fe-6d10-466b-fd8b-41dd6cf6c118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpfinardi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230315_023338-0nfei1py</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pfinardi/uncategorized/runs/0nfei1py' target=\"_blank\">fanciful-deluge-30</a></strong> to <a href='https://wandb.ai/pfinardi/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/pfinardi/uncategorized' target=\"_blank\">https://wandb.ai/pfinardi/uncategorized</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/pfinardi/uncategorized/runs/0nfei1py' target=\"_blank\">https://wandb.ai/pfinardi/uncategorized/runs/0nfei1py</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/pfinardi/uncategorized/runs/0nfei1py?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f7bf49d3d00>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSUMOeUyOZ2G"
      },
      "source": [
        "You can see that we load a GPT2 model called `gpt2_imdb`. This model was additionally fine-tuned on the IMDB dataset for 1 epoch with the huggingface [script](https://github.com/huggingface/transformers/blob/master/examples/run_language_modeling.py) (no special settings). The other parameters are mostly taken from the original paper [\"Fine-Tuning Language Models from Human Preferences\"](\n",
        "https://arxiv.org/pdf/1909.08593.pdf). This model as well as the BERT model is available in the Huggingface model zoo [here](https://huggingface.co/models). The following code should automatically download the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM_OTANwOZ2H"
      },
      "source": [
        "## Load data and models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TFrucY9OZ2H"
      },
      "source": [
        "### Load IMDB dataset\n",
        "The IMDB dataset contains 50k movie review annotated with \"positive\"/\"negative\" feedback indicating the sentiment.  We load the IMDB dataset into a DataFrame and filter for comments that are at least 200 characters. Then we tokenize each text and cut it to random size with the `LengthSampler`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsePQUz38ua3",
        "outputId": "e142438e-2c3e-4dd6-cda9-f7ca285fe018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset imdb_pt (/root/.cache/huggingface/datasets/maritaca-ai___imdb_pt/plain_text/1.0.0/93713e4fbbbd544d1c09fb6072e3d18fedd347bfc32206b4e2d98b27444ebd5a)\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/maritaca-ai___imdb_pt/plain_text/1.0.0/93713e4fbbbd544d1c09fb6072e3d18fedd347bfc32206b4e2d98b27444ebd5a/cache-ad6f35e13c4e9e3d.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['review', 'label'],\n",
              "    num_rows: 15428\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "ds = load_dataset(\"maritaca-ai/imdb_pt\", split='train')\n",
        "ds = ds.rename_columns({'text': 'review'})\n",
        "ds = ds.filter(lambda x: (len(x[\"review\"].split())>30) and (len(x[\"review\"].split())<200))\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_query(sample, n_words=4):\n",
        "    sample[\"input_ids\"] = tokenizer.encode((' ').join(sample[\"review\"].split()[:n_words]))\n",
        "    sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
        "    return sample\n",
        "\n",
        "def collator(data):\n",
        "    # toma as keys em data[0]: review, label, input_ids, query\n",
        "    # para cada key em todo data cria os objetos key [lista de elel]\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])    \n",
        "\n",
        "\n",
        "data = ds.map(create_query, batched=False)\n",
        "data = data.filter(lambda x: len(x[\"input_ids\"])<10)\n",
        "data = data.remove_columns([\"review\"])\n",
        "\n",
        "data.set_format(type='torch', output_all_columns=True)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJK1O0ojwTZg",
        "outputId": "9e25de95-b668-4a38-88cb-c08b3f53b95a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/maritaca-ai___imdb_pt/plain_text/1.0.0/93713e4fbbbd544d1c09fb6072e3d18fedd347bfc32206b4e2d98b27444ebd5a/cache-1ec6d91bb2e8a800.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/maritaca-ai___imdb_pt/plain_text/1.0.0/93713e4fbbbd544d1c09fb6072e3d18fedd347bfc32206b4e2d98b27444ebd5a/cache-830219889f333a18.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['label', 'input_ids', 'query'],\n",
              "    num_rows: 12205\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rok6d0Rc1f2X",
        "outputId": "0ce320e6-e942-49f5-9b29-16429736b35b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': tensor(0),\n",
              " 'input_ids': tensor([ 4653,  2471,   268,   292, 31215,   819,  7940]),\n",
              " 'query': 'Se apenas para evitar'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_trainer = PPOTrainer(config, model, ref_model, tokenizer, dataset=data, data_collator=collator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "cc60c5b0e15b407084bea335225779e8",
            "99bc4b93d3544ed89dc37143a6d1c2e2",
            "b00fbc6a55724f7d86f71028c4100a74",
            "925471d93fe945fe97cbad31b42251a6",
            "0421c208180f4d2a82b4707accdb047e",
            "19ff583b4d1b4842bcb1d3246edd80b1",
            "3e1c1e3d47484eefb611d3dd4f46e0e1",
            "4e85040716a142f39c6beddf3d72c4cf"
          ]
        },
        "id": "MJpor1hWydg-",
        "outputId": "4ead3b2b-867b-4673-dc61-82d7298a4ec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:0nfei1py) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc60c5b0e15b407084bea335225779e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fanciful-deluge-30</strong> at: <a href='https://wandb.ai/pfinardi/uncategorized/runs/0nfei1py' target=\"_blank\">https://wandb.ai/pfinardi/uncategorized/runs/0nfei1py</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230315_023338-0nfei1py/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:0nfei1py). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230315_023343-qc3xysni</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pfinardi/trl/runs/qc3xysni' target=\"_blank\">youthful-sunset-27</a></strong> to <a href='https://wandb.ai/pfinardi/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/pfinardi/trl' target=\"_blank\">https://wandb.ai/pfinardi/trl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/pfinardi/trl/runs/qc3xysni' target=\"_blank\">https://wandb.ai/pfinardi/trl/runs/qc3xysni</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(ppo_trainer.dataloader))\n",
        "print(batch.keys())\n",
        "print(len(batch['label']))\n",
        "# batch['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jekcg50mz3ex",
        "outputId": "db4a8be6-ad73-46d1-fa0a-af964bfb5494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['label', 'input_ids', 'query'])\n",
            "96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_KnGwVYOZ2L"
      },
      "source": [
        "### Load BERT classifier\n",
        "We load a BERT classifier fine-tuned on the IMDB dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpddQEk7OZ2M"
      },
      "outputs": [],
      "source": [
        "if ppo_trainer.accelerator.num_processes == 1:\n",
        "   device = 0 if torch.cuda.is_available() else \"cpu\" # to avoid a `pipeline` bug\n",
        "\n",
        "sentiment_pipe = pipeline(\"sentiment-analysis\", model=\"/content/drive/MyDrive/LLMs/ckpts/BERT_imdb/\", device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHTmCdV4OZ2M"
      },
      "source": [
        "The model outputs are the logits for the negative and positive class. We will use the logits for positive class as a reward signal for the language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oWNrAox9SDp",
        "outputId": "6d1c2a72-3e02-49c2-ffff-5192ddd1b305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'LABEL_0', 'score': 3.0385935306549072},\n",
              "  {'label': 'LABEL_1', 'score': -3.26000714302063}]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "text = 'Esse filme foi ruim!!'\n",
        "sentiment_pipe(text, **sent_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkS6-jeV9SDq",
        "outputId": "b5beba6e-1f85-4802-e39a-73ec36545319"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'LABEL_0', 'score': -2.3053135871887207},\n",
              "  {'label': 'LABEL_1', 'score': 2.1447975635528564}]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "text = 'Esse filme foi bom!!'\n",
        "sentiment_pipe(text, **sent_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyt3T48qOZ2N"
      },
      "source": [
        "### Generation settings\n",
        "For the response generation we just use sampling and make sure top-k and nucleus sampling are turned off as well as a minimal length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQxTgAJwOZ2N"
      },
      "outputs": [],
      "source": [
        "gen_kwargs = {\n",
        "    \"min_length\":-1,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCzdOPcjOZ2N"
      },
      "source": [
        "## Optimize model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W41pVo9OZ2N"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4rWtG6_OZ2N"
      },
      "source": [
        "The training loop consists of the following main steps:\n",
        "1. Get the query responses from the policy network (GPT-2)\n",
        "2. Get sentiments for query/responses from BERT\n",
        "3. Optimize policy with PPO using the (query, response, reward) triplet\n",
        "\n",
        "**Training time**\n",
        "\n",
        "This step takes **~2h** on a V100 GPU with the above specified settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b409d9acb3474ae1b5076c482a088e4b",
            "59f52107653a46979e4bb092f02d5dac",
            "3ccff80161a34fc2ab2e340eef6a70c1",
            "1a77ada8d187467a9fd6eafedecb7505",
            "2f188eec42ff4b049e9eeee849dd824f",
            "41f3fc612d2145fbba37a20ccd151c83",
            "d6c17ef046c2499da27e7f750534ff05",
            "ab3dfad06a364d4598b9ae3d0df03914",
            "b081c2123a80499d9aedd576c0e9856f",
            "ef350441e78d439486d39da939400f27",
            "64c43d68ba28459f9e29f362b2968760"
          ]
        },
        "id": "40kx__nDOZ2N",
        "outputId": "073a3bff-d90b-4d7e-a50a-e2b06d845d90"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b409d9acb3474ae1b5076c482a088e4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/127 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0 -- mean_reward: (-0.28) -- decoding 5 rand samples:\n",
            "\t0: Este filme é uma                    ->  comédia, talvez o filme mais                      -- Reward: 2.85                                    \n",
            "\t1: O que você espera                   ->  deste filme é um palantar medíocre                -- Reward: -2.33                                   \n",
            "\t2: Receio ter que discordar            ->  de muitas outras classificaçõ                     -- Reward: -0.105                                  \n",
            "\t3: Como sempre, fui assistir           ->  Bloody Petty (filme the Sickest Movie) quando     -- Reward: -1.3                                    \n",
            "\t4: A atuação é uma                     ->  obrigação típica de uma                           -- Reward: -0.12                                   \n",
            "\n",
            "step 1 -- mean_reward: (-0.295) -- decoding 5 rand samples:\n",
            "\t0: Eu me deparei com                   ->  este filme quando assisti ao trailer deste        -- Reward: 0.854                                   \n",
            "\t1: Eu só assisti a                     ->  este filme ridiculamente emocionante sem          -- Reward: -0.65                                   \n",
            "\t2: Stefan é um X-Con                   ->  \"pulso do período 2: Scar Bras                    -- Reward: -1.55                                   \n",
            "\t3: O olhar intransigente em            ->  torno do poderoso Timothy Dalton nunca foi        -- Reward: 2.32                                    \n",
            "\t4: Sempre que um filme                 ->  pode ter um histórico ou uma                      -- Reward: 0.351                                   \n",
            "\n",
            "step 2 -- mean_reward: (-0.0139) -- decoding 5 rand samples:\n",
            "\t0: Que bagunça confusa. Eu             ->  tinha muitas expectativas durante minha           -- Reward: -3.09                                   \n",
            "\t1: Adorei este filme e                 -> , enquanto estava na Antuérpia,                    -- Reward: 3.04                                    \n",
            "\t2: Eu vi este filme                    ->  antes de verSimon e Garbo e tornece               -- Reward: -1.61                                   \n",
            "\t3: O produtor Joel Schumacher,         ->  então com 21 anos, comprou junto com              -- Reward: 1.01                                    \n",
            "\t4: Como este filme foi                 ->  na mente, acho que deveria ter al                 -- Reward: -3.08                                   \n",
            "\n",
            "step 3 -- mean_reward: (-0.262) -- decoding 5 rand samples:\n",
            "\t0: Embora este não seja                ->  um bom filme, o filme é refrescante               -- Reward: -0.863                                  \n",
            "\t1: Este filme foi um                   ->  pouco agitado. Eu pensei                          -- Reward: -1.21                                   \n",
            "\t2: O inventor Wayne Szalinsky          ->  escreveu uma história impecável                   -- Reward: 2.26                                    \n",
            "\t3: Em seu primeiro papel               ->  nas \"aurorais\", Brad Pitt em sua vast             -- Reward: 1.13                                    \n",
            "\t4: Não acredito que a                  ->  maioria das pessoas odeie                         -- Reward: -0.392                                  \n",
            "\n",
            "step 4 -- mean_reward: (-0.338) -- decoding 5 rand samples:\n",
            "\t0: Eu estava esperando um              ->  filme, valeu a 1, mas nada                        -- Reward: -2.48                                   \n",
            "\t1: Um olhar diferente sobre            ->  John Boorman é levado para trás, de assist        -- Reward: 2.38                                    \n",
            "\t2: Sem dúvida, Frank Sinatra           ->  fez este ter sido um ótimo document               -- Reward: 0.845                                   \n",
            "\t3: Se filmes como Ghoulies             ->  estão indo. Como este é uma visão                 -- Reward: -1.95                                   \n",
            "\t4: Cusack faz o seu                    ->  melhor com dezenove vezes de cor para c           -- Reward: 1.48                                    \n",
            "\n",
            "step 5 -- mean_reward: (-0.345) -- decoding 5 rand samples:\n",
            "\t0: Este filme é tão                    ->  ruim, é horrivelmente ruim e                      -- Reward: -3.29                                   \n",
            "\t1: Este é um documentário              ->  excelente de quase todas as maneir                -- Reward: 3.14                                    \n",
            "\t2: Há muito o problema                 ->  com este filme de Hollywood depois de ser movido  -- Reward: -1.64                                   \n",
            "\t3: Primeiro de tudo, como              ->  já disse para Ariel e Vanesa, os cine             -- Reward: 0.494                                   \n",
            "\t4: Carlos Mencia foi excelente,        ->  absolutamente impressionante. Veja bem            -- Reward: 1.65                                    \n",
            "\n",
            "step 6 -- mean_reward: (-0.0839) -- decoding 5 rand samples:\n",
            "\t0: de assistir isso quando             ->  ele está sendo oferecido por sua                  -- Reward: -1.83                                   \n",
            "\t1: A direção por trás                  ->  de Pat Morita também tem alguns rec               -- Reward: -1.18                                   \n",
            "\t2: Eu descobri este filme              ->  no outono de 2006 e leu \"Doc Bookrence            -- Reward: 1.13                                    \n",
            "\t3: Este fim de semana                  ->  do matin às 10:30 da manhã                        -- Reward: -0.698                                  \n",
            "\t4: Esse show é doloroso                ->  que eu cheguei às vésperas                        -- Reward: -2.43                                   \n",
            "\n",
            "step 7 -- mean_reward: (-0.212) -- decoding 5 rand samples:\n",
            "\t0: A entrega de algumas                ->  das características que delicamente o             -- Reward: 2.21                                    \n",
            "\t1: Eu vi o filme                       ->  quando criança e achei uma bob                    -- Reward: 1.5                                     \n",
            "\t2: Se você quiser conferir             ->  um show inteiro de grau C com aquel               -- Reward: -0.0901                                 \n",
            "\t3: Este filme foi uma                  ->  altura de jantar para pelo menos qual             -- Reward: -1.05                                   \n",
            "\t4: Já houve um filme                   ->  acidentalmente perturbado que seria inte          -- Reward: -2.61                                   \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/pipelines/base.py:1045: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 8 -- mean_reward: (-0.325) -- decoding 5 rand samples:\n",
            "\t0: Se a sua idéia                      ->  de que todo personagem infantil que não           -- Reward: -0.447                                  \n",
            "\t1: É difícil acreditar que             ->  este filme é um dos mais extensos e               -- Reward: -0.411                                  \n",
            "\t2: Ok, então eu entendi.               ->  É bastante tarde, mas... francamente,             -- Reward: -1.29                                   \n",
            "\t3: Citizen X conta ao                  ->  cidadão geneticamente deficiente D cometendo c    -- Reward: -0.745                                  \n",
            "\t4: Eu vi esse filme                    ->  dizendo que era o filme mais engra                -- Reward: 0.251                                   \n",
            "\n",
            "step 9 -- mean_reward: (-0.278) -- decoding 5 rand samples:\n",
            "\t0: Eu estava preocupado que            ->  havia sacos caminhando em todo o                  -- Reward: -0.849                                  \n",
            "\t1: Fido é uma história                 ->  na tela grande de Sam Puzo. Tent                  -- Reward: 0.3                                     \n",
            "\t2: Bem, devo dizer que                 ->  esse é o filme;Na prática                         -- Reward: 1.17                                    \n",
            "\t3: Este filme tem tão                  ->  sentimental nem atmosfera descaradamente int      -- Reward: -1.78                                   \n",
            "\t4: Este filme é muito                  ->  ruim. Concordo que ninguém tinha                  -- Reward: -3.46                                   \n",
            "\n",
            "step 10 -- mean_reward: (-0.0762) -- decoding 5 rand samples:\n",
            "\t0: Filme excelente sem diálogo         ->  de diabo nem bons atores nem poucos               -- Reward: -0.742                                  \n",
            "\t1: Este foi de longe                   ->  o sufhiro antes de Shoguang.                      -- Reward: -0.22                                   \n",
            "\t2: Se você gosta de                    ->  filmes de propaganda sombria, como o massacre     -- Reward: -0.373                                  \n",
            "\t3: Para impedir que seu                ->  nome combine com a magia de um dos artist         -- Reward: -2.22                                   \n",
            "\t4: Olha, não há nada                   ->  diferente aqui, teria que parar                   -- Reward: -1.44                                   \n",
            "\n",
            "step 11 -- mean_reward: (-0.21) -- decoding 5 rand samples:\n",
            "\t0: Este filme ganhou cada              ->  2 estrelas. Recebeu 2 indicaç                     -- Reward: 0.453                                   \n",
            "\t1: Neste filme de 1943,                ->  em qualquer cultura de Battlesti, tive            -- Reward: -0.374                                  \n",
            "\t2: Este é o único                      ->  filme que já vi nos 100 melhores dos              -- Reward: -1.45                                   \n",
            "\t3: Um filme doce e                     ->  idealizador. Na verdade, o cri                    -- Reward: 2.13                                    \n",
            "\t4: Este filme parecia ser              ->  o caminho para as reações                         -- Reward: -2.49                                   \n",
            "\n",
            "step 12 -- mean_reward: (-0.106) -- decoding 5 rand samples:\n",
            "\t0: Não posso dizer se                  ->  estivesse em desuso, sim, catalis                 -- Reward: 0.0594                                  \n",
            "\t1: Este é um fio                       ->  redentor do nascimento e ningué                   -- Reward: -1.12                                   \n",
            "\t2: OK. Eu sei que                      ->  foi o filme mais assustador da ang                -- Reward: -1.91                                   \n",
            "\t3: Este é um grande                    ->  teste de qualquer pesadelo do Tínham              -- Reward: -0.402                                  \n",
            "\t4: Esta parcela faz com                ->  que só o Império Classico nas noites              -- Reward: -0.203                                  \n",
            "\n",
            "step 13 -- mean_reward: (-0.136) -- decoding 5 rand samples:\n",
            "\t0: Foi lançado na França               ->  com um DVD de 2 horas, ninguém                    -- Reward: 0.933                                   \n",
            "\t1: Não consigo descobrir quem          ->  é este filme, mas apoiará menos                   -- Reward: -1.36                                   \n",
            "\t2: O filme original, Man               -> os nã! é um filme hilário                          -- Reward: -1.99                                   \n",
            "\t3: Como você pode errar                ->  com um soletrado de cem linhas de                 -- Reward: -1.26                                   \n",
            "\t4: \"Algie, The Miner\" é                ->  um dos melhores filmes Cillian para lhe           -- Reward: 2.39                                    \n",
            "\n",
            "step 14 -- mean_reward: (0.0383) -- decoding 5 rand samples:\n",
            "\t0: Meu amigo comprou o                 ->  DVD do Gov. Yasu Katsu em 1979 com is             -- Reward: -0.744                                  \n",
            "\t1: De vez em quando,                   ->  o herói imortal e su Desi Arnaz                   -- Reward: 1.26                                    \n",
            "\t2: Comparar essa miséria com           -> o um diário: a polícia branca                      -- Reward: -0.589                                  \n",
            "\t3: .... Depois de 16                   ->  anos de muitos votos, coroou                      -- Reward: 0.106                                   \n",
            "\t4: Este é provavelmente o              ->  filme mais legítimo que já vi                     -- Reward: -0.386                                  \n",
            "\n",
            "step 15 -- mean_reward: (0.0769) -- decoding 5 rand samples:\n",
            "\t0: O nome apenas diz                   ->  respeito do esportivo: camarão,                   -- Reward: 0.0751                                  \n",
            "\t1: De alguma forma, eles               ->  parecem apresentar os 15. Eu                      -- Reward: -0.978                                  \n",
            "\t2: Este filme é uma                    ->  grande emoção em relação a                        -- Reward: 2.68                                    \n",
            "\t3: Sem lixo - não                      ->  é uma criança em que pode ver.                    -- Reward: -0.474                                  \n",
            "\t4: Este é definitivamente um           ->  dos melhores shows de todos os tempos.            -- Reward: 2.31                                    \n",
            "\n",
            "step 16 -- mean_reward: (0.107) -- decoding 5 rand samples:\n",
            "\t0: Este é apenas um                    ->  dos ótimos musicais da Ásia                       -- Reward: 2.63                                    \n",
            "\t1: \"Broken Bow\" nos leva               ->  você ao sucesso de Hollywood e um dos             -- Reward: 2.35                                    \n",
            "\t2: Este é um dos                       ->  meus favoritos do time do beisebol.               -- Reward: 1.79                                    \n",
            "\t3: Uma excelente interpretação do      ->  filme do ano em sons da cultura art dé            -- Reward: 2.67                                    \n",
            "\t4: Os assassinatos estão ocorrendo     ->  no sul da Nigéria desde 1971. Embora              -- Reward: 0.58                                    \n",
            "\n",
            "step 17 -- mean_reward: (0.394) -- decoding 5 rand samples:\n",
            "\t0: Eu pensei que o                     ->  filme estava me explicando imediatament           -- Reward: -1.91                                   \n",
            "\t1: Depois de revisar esse              ->  imprecisão tarde na noite da casa                 -- Reward: -2.27                                   \n",
            "\t2: Houve momentos durante o            ->  show quando Harriet se apaixonou, e qu            -- Reward: 0.454                                   \n",
            "\t3: Os Muppets de Jim                   ->  Carpe de Sam Rock são um grupo de be              -- Reward: -0.692                                  \n",
            "\t4: Aluguei e assistiu a                ->  este filme ontem. Desenhado com uma               -- Reward: -0.874                                  \n",
            "\n",
            "step 18 -- mean_reward: (-0.0347) -- decoding 5 rand samples:\n",
            "\t0: Perdi os 10 primeiros               ->  10 minutos de filmes e achei uma                  -- Reward: -2.93                                   \n",
            "\t1: Na verdade, paguei para             ->  Miami e nos dias em que esperavam ser             -- Reward: -0.609                                  \n",
            "\t2: Outro daqueles filmes que           ->  vale um 4 em cinco, este filme                    -- Reward: 0.86                                    \n",
            "\t3: Eu vi este filme                    ->  na TV na Austrália em 1999, quando                -- Reward: 1.43                                    \n",
            "\t4: Estou cansado de pessoas            ->  denunciarem ostensivamente os ó                   -- Reward: -0.92                                   \n",
            "\n",
            "step 19 -- mean_reward: (0.344) -- decoding 5 rand samples:\n",
            "\t0: Com base na recomendação            ->  papal de Otto Preminger para relatar de \"         -- Reward: 0.0609                                  \n",
            "\t1: Eu li sobre este                    ->  filme em uma biblioteca da faculd                 -- Reward: -0.893                                  \n",
            "\t2: Este filme realmente merece         ->  apreciar em todos os melhores performances que    -- Reward: 2.68                                    \n",
            "\t3: É tão raro encontrar                ->  crianças fazendo treinamentos de                  -- Reward: 0.708                                   \n",
            "\t4: A excelente qualidade da            ->  produção deste filme de 35 mm na Nor              -- Reward: 1.79                                    \n",
            "\n",
            "step 20 -- mean_reward: (0.219) -- decoding 5 rand samples:\n",
            "\t0: Uau, este filme sugou               ->  que meu avô fez um dos maiores                    -- Reward: -2.82                                   \n",
            "\t1: Este tem que ser                    ->  um dos piores filmes já feitos.                   -- Reward: -3.39                                   \n",
            "\t2: Minha parte favorita foi            ->  Amy Adams quando criança. O trabalho              -- Reward: 1.98                                    \n",
            "\t3: Body Slam (1987) é                  ->  um filme lírico sobre um homem                    -- Reward: 1.69                                    \n",
            "\t4: Acabei de terminar este             ->  filme em mim, tendo falhado sobre                 -- Reward: -2.09                                   \n",
            "\n",
            "step 21 -- mean_reward: (0.0918) -- decoding 5 rand samples:\n",
            "\t0: Eu vi uma exibição                  ->  no Reino Unido em Londres de 1986,                -- Reward: 0.355                                   \n",
            "\t1: Para pedir emprestado a             -> o filme inteir (veja este pedido                   -- Reward: -1.62                                   \n",
            "\t2: Este não é o                        ->  melhor dos melhores filhos de Johnny Weiss        -- Reward: 2.08                                    \n",
            "\t3: Eu amo este filme,                  ->  considerando filmes como o'velho tipo             -- Reward: 2.84                                    \n",
            "\t4: O filme é muito                     ->  desviado como uma peça de filme                   -- Reward: -2.4                                    \n",
            "\n",
            "step 22 -- mean_reward: (0.0685) -- decoding 5 rand samples:\n",
            "\t0: Cinco anos depois dos               ->  filmes de Govaz de Harilal, que fo                -- Reward: 0.31                                    \n",
            "\t1: Eu dei a este                       ->  filme um dos piores filmes que já vi              -- Reward: -3.46                                   \n",
            "\t2: Paul Reiser é uma                   ->  das personalidades do cinema duplo mais popul     -- Reward: 1.65                                    \n",
            "\t3: Tive o privilégio de                ->  ver este filme em um teatro na Flór               -- Reward: 1.84                                    \n",
            "\t4: Esta é uma tentativa,               ->  no papel de Viennois, de gostar                   -- Reward: -2.4                                    \n",
            "\n",
            "step 23 -- mean_reward: (0.168) -- decoding 5 rand samples:\n",
            "\t0: Não há necessidade de               ->  agradecer ao povo nos setores de su               -- Reward: -1.74                                   \n",
            "\t1: Prova de que nem                    ->  a chave do show é no UNEMAN. Es                   -- Reward: -2.42                                   \n",
            "\t2: Este é um dos                       ->  melhores locais da Amazônia. Dest                 -- Reward: 1.79                                    \n",
            "\t3: A história é bastante               ->  robusta, a história da série c                    -- Reward: 1.47                                    \n",
            "\t4: Achei este filme chato,             ->  o eletrônico e subestimado                        -- Reward: -3.1                                    \n",
            "\n",
            "step 24 -- mean_reward: (0.154) -- decoding 5 rand samples:\n",
            "\t0: Um dos slashers mais                ->  narcotraficantes do mundo hoje, o                 -- Reward: -0.963                                  \n",
            "\t1: O pior filme que                    ->  já vi do teatro do ano. Uma                       -- Reward: -3.37                                   \n",
            "\t2: O The Invaders é                    ->  um filme japonês de estimação                     -- Reward: 0.677                                   \n",
            "\t3: Jim Belushi está tendo              ->  desenvolvido caminhos desde m                     -- Reward: 0.987                                   \n",
            "\t4: Meu filme favorito do               ->  meu tempo. Meus 34 anos vendo est                 -- Reward: 1.72                                    \n",
            "\n",
            "step 25 -- mean_reward: (0.122) -- decoding 5 rand samples:\n",
            "\t0: Não me interpretem mal,             ->  mas é um filme, inovador e um excel               -- Reward: 2.74                                    \n",
            "\t1: O número de vezes                   ->  que vi o filme foi um dos 12 primei               -- Reward: 0.141                                   \n",
            "\t2: Acabei de ver os                    ->  filmes de Walsh dos anos 80 e só pos              -- Reward: -0.0283                                 \n",
            "\t3: Eu sempre senti que                 ->  razão pela qualidade de Mike está                 -- Reward: -0.07                                   \n",
            "\t4: Este Hearkens de volta              ->  para crescer...... este filme é uma               -- Reward: 1.23                                    \n",
            "\n",
            "step 26 -- mean_reward: (0.392) -- decoding 5 rand samples:\n",
            "\t0: Este filme é uma                    ->  das melhores imagens e vê todos                   -- Reward: 2.96                                    \n",
            "\t1: Depois de assistir isso,            ->  este filme estar muito aterrorizado               -- Reward: -1.84                                   \n",
            "\t2: Eu vi o Big                         ->  Brother em 2001, na Noruega, quando e             -- Reward: 0.455                                   \n",
            "\t3: Eu vi isso pela                     ->  primeira vez na Virgin, em 1937 ainda era         -- Reward: 1.14                                    \n",
            "\t4: Eu peguei isso em                   ->  uma exibição em Nova Orleans, onde                -- Reward: 1.52                                    \n",
            "\n",
            "step 27 -- mean_reward: (-0.0657) -- decoding 5 rand samples:\n",
            "\t0: Coloque a culpa do                  ->  escritor e diretor da capa da capa                -- Reward: -2.14                                   \n",
            "\t1: Não vi nenhum dos                   ->  filmes onde sim, mas, mas é justific              -- Reward: -1.35                                   \n",
            "\t2: Não me lembro quando                ->  a maioria de tudo está na a ma                    -- Reward: 0.595                                   \n",
            "\t3: Vi isso na TV.                      ->  Vi o filme no canal há cerca de                   -- Reward: 1.33                                    \n",
            "\t4: A peça de Leslie                    ->  Brooks dá um assunto de emergênc                  -- Reward: 0.554                                   \n",
            "\n",
            "step 28 -- mean_reward: (0.443) -- decoding 5 rand samples:\n",
            "\t0: Um filme fabuloso. Com              ->  construções de cinema absolutament                -- Reward: 2.87                                    \n",
            "\t1: Este filme consiste em              ->  um elenco de cinco talentos expressiv             -- Reward: 1.3                                     \n",
            "\t2: O pôster anterior obviamente        ->  do Giallo, está no vídeo que                      -- Reward: 0.66                                    \n",
            "\t3: UAU!O que - A                       ->  unidade entre a vítima de v                       -- Reward: -0.146                                  \n",
            "\t4: Eu queria ler os                    ->  comentários sobre este filme. Come                -- Reward: -1.49                                   \n",
            "\n",
            "step 29 -- mean_reward: (0.487) -- decoding 5 rand samples:\n",
            "\t0: Tom Hanks como você                 ->  teve grandes amigos que conseguir                 -- Reward: -0.178                                  \n",
            "\t1: Eu estava hospedado em              ->  um museu em Nova York. Além dos film              -- Reward: -0.716                                  \n",
            "\t2: Existem filmes que são              ->  surpreendentemente praturos, mas                  -- Reward: 0.0489                                  \n",
            "\t3: No México, este filme               ->  foi um dos filmes mais bonitos e                  -- Reward: 2.24                                    \n",
            "\t4: Então, no total, achei              ->  um filme muito bonito, mas elog                   -- Reward: -1.74                                   \n",
            "\n",
            "step 30 -- mean_reward: (0.161) -- decoding 5 rand samples:\n",
            "\t0: Recentemente mostrado na TV         ->  Brave na TV nas cores que posso desenhar no       -- Reward: 1.05                                    \n",
            "\t1: Este filme merece 10                ->  em 10 para cada 10. Existem designs que           -- Reward: 2.25                                    \n",
            "\t2: \"O dia final\" é                     ->  uma comédia nobre da unidade                      -- Reward: 0.926                                   \n",
            "\t3: Este filme foi muito                ->  um melhor filme em três ex-p                      -- Reward: 0.811                                   \n",
            "\t4: Este filme foi feito                ->  para a multidão. Ele traz uma vis                 -- Reward: 0.778                                   \n",
            "\n",
            "step 31 -- mean_reward: (0.45) -- decoding 5 rand samples:\n",
            "\t0: Como você não pode                  ->  estar assistindo filmes que ocorrem em            -- Reward: -1.72                                   \n",
            "\t1: Algum filme pode se                 ->  passar nas jovens criaturas que t                 -- Reward: -2.03                                   \n",
            "\t2: Eu vi a série                       ->  Colombo no Grand National. Ele é um dos cora      -- Reward: 1.08                                    \n",
            "\t3: Nova York nunca parecia             ->  mais um grande shopping do que oCHormalment       -- Reward: 0.136                                   \n",
            "\t4: Eu tenho que dizer                  ->  o mesmo por qualidade que este filme.             -- Reward: 1.18                                    \n",
            "\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "except:\n",
        "    pass\n",
        "\n",
        "generation_kwargs = {\n",
        "    \"min_length\":-1,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id\n",
        "}\n",
        "\n",
        "\n",
        "MAX_LEN_OUTPUT = 12\n",
        "N_SAMPLES = 5\n",
        "loop = tqdm(ppo_trainer.dataloader, leave=True)\n",
        "\n",
        "for step, batch in enumerate(loop):\n",
        "    query_tensors = batch['input_ids']\n",
        "\n",
        "    #### Get response from gpt2\n",
        "    response_tensors = []\n",
        "    for query in query_tensors:\n",
        "        gen_len = MAX_LEN_OUTPUT\n",
        "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
        "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
        "        response_tensors.append(response.squeeze()[-gen_len:])\n",
        "    batch['response'] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
        "\n",
        "    #### Compute sentiment score\n",
        "    texts = [q + r for q, r in zip(batch['query'], batch['response'])]\n",
        "    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)\n",
        "    rewards = [torch.tensor(output[1][\"score\"]) for output in pipe_outputs]\n",
        "\n",
        "    #### Run PPO step \n",
        "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
        "    ppo_trainer.log_stats(stats, batch, rewards)\n",
        "    \n",
        "    #### Get N_SAMPLES to check\n",
        "    sample_N = torch.multinomial(\n",
        "        torch.arange(config.batch_size, dtype=torch.float), num_samples=N_SAMPLES\n",
        "        )\n",
        "    response_tensors = torch.stack(response_tensors)\n",
        "    \n",
        "    query_sampled    = [tokenizer.decode(query_tensors[s]) for s in sample_N]\n",
        "    gen_text_sampled = [tokenizer.decode(e) for e in response_tensors[sample_N]]\n",
        "    rewards_sampled  = torch.stack(rewards)[sample_N]\n",
        "\n",
        "    print(f'step {step} -- mean_reward: ({torch.tensor(rewards).mean():.3}) -- decoding {N_SAMPLES} rand samples:')\n",
        "    for ix, (q,a,r) in enumerate(zip(query_sampled, gen_text_sampled, rewards_sampled)):\n",
        "        print(f'\\t{ix}: {q:<35} -> {a:<50} -- Reward: {r.item():<40.3}')\n",
        "    print()\n",
        "\n",
        "    loop.set_description(f'mean rewards: {torch.tensor(rewards).mean():.3}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cudiJUPAOZ2O"
      },
      "source": [
        "### Training progress\n",
        "If you are tracking the training progress with Weights&Biases you should see a plot similar to the one below. Check out the interactive sample report on wandb.ai: [link](https://app.wandb.ai/lvwerra/trl-showcase/runs/1jtvxb1m/).\n",
        "\n",
        "<div style=\"text-align: center\">\n",
        "<img src='https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/gpt2_tuning_progress.png' width='800'>\n",
        "<p style=\"text-align: center;\"> <b>Figure:</b> Reward mean and distribution evolution during training. </p>\n",
        "</div>\n",
        "\n",
        "One can observe how the model starts to generate more positive outputs after a few optimisation steps.\n",
        "\n",
        "> Note: Investigating the KL-divergence will probably show that at this point the model has not converged to the target KL-divergence, yet. To get there would require longer training or starting with a higher inital coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH6dkGhGOZ2O"
      },
      "source": [
        "## Model inspection\n",
        "Let's inspect some examples from the IMDB dataset. We can use `model_ref` to compare the tuned model `model` against the model before optimisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UJNPRsxOZ2O"
      },
      "outputs": [],
      "source": [
        "#### get a batch from the dataset\n",
        "bs = 12\n",
        "game_data = dict()\n",
        "data.set_format(\"pandas\")\n",
        "df_batch = data[:].sample(bs)\n",
        "game_data['query'] = df_batch['query'].tolist()\n",
        "query_tensors = df_batch['input_ids'].tolist()\n",
        "\n",
        "response_tensors_ref, response_tensors = [], []\n",
        "\n",
        "#### get response from gpt2 and gpt2_ref\n",
        "for i in range(bs):\n",
        "    gen_len = MAX_LEN_OUTPUT\n",
        "    output = ref_model.generate(torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n",
        "                                     max_new_tokens=gen_len, **gen_kwargs).squeeze()[-gen_len:]\n",
        "    response_tensors_ref.append(output)\n",
        "    output = model.generate(torch.tensor(query_tensors[i]).unsqueeze(dim=0).to(device),\n",
        "                                 max_new_tokens=gen_len, **gen_kwargs).squeeze()[-gen_len:]\n",
        "    response_tensors.append(output)\n",
        "\n",
        "#### decode responses\n",
        "game_data['response (before)'] = [tokenizer.decode(response_tensors_ref[i]) for i in range(bs)]\n",
        "game_data['response (after)'] = [tokenizer.decode(response_tensors[i]) for i in range(bs)]\n",
        "\n",
        "#### sentiment analysis of query/response pairs before/after\n",
        "texts = [q + r for q,r in zip(game_data['query'], game_data['response (before)'])]\n",
        "game_data['rewards (before)'] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
        "\n",
        "texts = [q + r for q,r in zip(game_data['query'], game_data['response (after)'])]\n",
        "game_data['rewards (after)'] = [output[1][\"score\"] for output in sentiment_pipe(texts, **sent_kwargs)]\n",
        "\n",
        "# store results in a dataframe\n",
        "import pandas as pd\n",
        "df_results = pd.DataFrame(game_data)\n",
        "df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwZ2YP4VOZ2P"
      },
      "source": [
        "Looking at the reward mean/median of the generated sequences we observe a significant difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uMhQJ6dOZ2P"
      },
      "outputs": [],
      "source": [
        "print('mean:')\n",
        "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].mean())\n",
        "print()\n",
        "print('median:')\n",
        "display(df_results[[\"rewards (before)\", \"rewards (after)\"]].median())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "524M03W8OZ2P"
      },
      "source": [
        "## Save model\n",
        "Finally, we save the model and push it to the Hugging Face for later usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCXQjzrmOZ2Q"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(    '/content/drive/MyDrive/LLMs/ckpts/gpt2-PTBR_imdb-pos-v2', push_to_hub=False)\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/LLMs/ckpts/gpt2-PTBR_imdb-pos-v2', push_to_hub=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJw79dIlOZ2Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1MIe9sFTzRjHtdBxu6xB3UQggPg6JEcaO",
      "authorship_tag": "ABX9TyNk8CCPiPhTVatb++ksC9w5",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc60c5b0e15b407084bea335225779e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99bc4b93d3544ed89dc37143a6d1c2e2",
              "IPY_MODEL_b00fbc6a55724f7d86f71028c4100a74"
            ],
            "layout": "IPY_MODEL_925471d93fe945fe97cbad31b42251a6"
          }
        },
        "99bc4b93d3544ed89dc37143a6d1c2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0421c208180f4d2a82b4707accdb047e",
            "placeholder": "​",
            "style": "IPY_MODEL_19ff583b4d1b4842bcb1d3246edd80b1",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "b00fbc6a55724f7d86f71028c4100a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e1c1e3d47484eefb611d3dd4f46e0e1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e85040716a142f39c6beddf3d72c4cf",
            "value": 1
          }
        },
        "925471d93fe945fe97cbad31b42251a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0421c208180f4d2a82b4707accdb047e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19ff583b4d1b4842bcb1d3246edd80b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e1c1e3d47484eefb611d3dd4f46e0e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e85040716a142f39c6beddf3d72c4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b409d9acb3474ae1b5076c482a088e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59f52107653a46979e4bb092f02d5dac",
              "IPY_MODEL_3ccff80161a34fc2ab2e340eef6a70c1",
              "IPY_MODEL_1a77ada8d187467a9fd6eafedecb7505"
            ],
            "layout": "IPY_MODEL_2f188eec42ff4b049e9eeee849dd824f"
          }
        },
        "59f52107653a46979e4bb092f02d5dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f3fc612d2145fbba37a20ccd151c83",
            "placeholder": "​",
            "style": "IPY_MODEL_d6c17ef046c2499da27e7f750534ff05",
            "value": "mean rewards: 0.45:  25%"
          }
        },
        "3ccff80161a34fc2ab2e340eef6a70c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab3dfad06a364d4598b9ae3d0df03914",
            "max": 127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b081c2123a80499d9aedd576c0e9856f",
            "value": 32
          }
        },
        "1a77ada8d187467a9fd6eafedecb7505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef350441e78d439486d39da939400f27",
            "placeholder": "​",
            "style": "IPY_MODEL_64c43d68ba28459f9e29f362b2968760",
            "value": " 32/127 [26:55&lt;1:18:21, 49.49s/it]"
          }
        },
        "2f188eec42ff4b049e9eeee849dd824f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f3fc612d2145fbba37a20ccd151c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6c17ef046c2499da27e7f750534ff05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab3dfad06a364d4598b9ae3d0df03914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b081c2123a80499d9aedd576c0e9856f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef350441e78d439486d39da939400f27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c43d68ba28459f9e29f362b2968760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}