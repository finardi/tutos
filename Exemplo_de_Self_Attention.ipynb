{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exemplo de Self Attention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNe6YgwxJiXCPObHdw21dEt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finardi/tutos/blob/master/Exemplo_de_Self_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdXdt1fRs52A",
        "colab_type": "text"
      },
      "source": [
        "# Exemplo de self attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8tpHOAtMz-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQNdgEQ3MIy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a15acfce-1ebd-46b7-b4fb-9b119adb7efd"
      },
      "source": [
        "# 00 -- ENTRADA:\n",
        "text = 'Quero um cartão'\n",
        "text_tokens = ['Quero', 'um', 'cartão']\n",
        "\n",
        "# 01 -- IDs:\n",
        "text_ids = [27,11,83]\n",
        "VOCAB = 100 # Quantidade de palavras\n",
        "\n",
        "# 02 -- DIMENSÃO DOS EMBEDDINGS = 4:\n",
        "D = 4\n",
        "\n",
        "# 03 -- COMPRIMENTO DA SEQUÊNCIA:\n",
        "L = 3\n",
        "\n",
        "# 04 -- MATRIZ DE EMBEDDINGS LxD:\n",
        "text_emb = torch.tensor([\n",
        "                         [0,1,2,0], \n",
        "                         [1,0,1,1],\n",
        "                         [1,0,1,2],\n",
        "                        ]).long()\n",
        "\n",
        "# 05 -- PRINT - SANITY CHECK:\n",
        "for i in zip(text_tokens, text_ids, text_emb):\n",
        "    print(f'Palavra: {i[0] :<6} -- ID: {i[1]} -- Embedding: {i[2]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Palavra: Quero  -- ID: 27 -- Embedding: tensor([0, 1, 2, 0])\n",
            "Palavra: um     -- ID: 11 -- Embedding: tensor([1, 0, 1, 1])\n",
            "Palavra: cartão -- ID: 83 -- Embedding: tensor([1, 0, 1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tnY8t3RROt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 06 -- USAR O nn.EMBEDDING PyTorch para CONSTRUIR AS MATRIZ DE PESOS Q, K, V:\n",
        "\n",
        "# embs  = torch.nn.Embedding(VOCAB, D)\n",
        "\n",
        "# # tensor com zeros_like\n",
        "# embeddings = torch.zeros(len(text_ids) * D).reshape(len(text_ids), D) \n",
        "\n",
        "# print(f'Shape da matriz de embeddings: {embeddings.shape}\\n')\n",
        "\n",
        "# print('Texto\\t\\t\\t     Matriz de embeddings\\n')\n",
        "# for i , token in enumerate(text_ids):\n",
        "#     embeddings[i] = embs(torch.tensor(token))\n",
        "# embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FBA15gsMIwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 06 -- MATRIZ DE PESOS, Q, K, V --> DxD (INICIADOS ARBITRARIAMENTE):\n",
        "\n",
        "Qw = torch.tensor([\n",
        "                   [1,  0, -1,  1], \n",
        "                   [0,  1,  0, -2],\n",
        "                   [3,  1, -2,  0],\n",
        "                   [0, -2,  1,  3],\n",
        "                ])\n",
        "\n",
        "Kw = torch.tensor([\n",
        "                   [3, -1,  0, -1], \n",
        "                   [0,  1, -1,  0],\n",
        "                   [3,  1,  0, -1],\n",
        "                   [-1, 0,  1,  3],\n",
        "                 ])\n",
        "\n",
        "Vw = torch.tensor([\n",
        "                   [-2, 0,  3,  0], \n",
        "                   [-1, 1, -2, -1],\n",
        "                   [-2, 1,  2,  3],\n",
        "                   [3,  2,  1, -2],\n",
        "                 ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS5NVaPXMItv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bc873ef-f495-4b95-f8a2-71342d223ab6"
      },
      "source": [
        "# 07 -- OBTER Q, K e V:\n",
        "print(f'Shape da entrada: {text_emb.size()} -- Shape das Matrizes de pesos Qw, Kw e Vw: {Qw.size()}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape da entrada: torch.Size([3, 4]) -- Shape das Matrizes de pesos Qw, Kw e Vw: torch.Size([4, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daPRGnNWMIq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K =  torch.einsum('ab, bc -> ac', text_emb, Kw) # text_emb @ Kw\n",
        "V =  torch.einsum('ab, bc -> ac', text_emb, Vw) # text_emb @ Vw\n",
        "Q =  torch.einsum('ab, bc -> ac', text_emb, Qw) # text_emb @ Qw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY7HNYRTMIoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d0e1008e-b57f-488b-bffe-f289a98fc7d2"
      },
      "source": [
        "K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6,  3, -1, -2],\n",
              "        [ 5,  0,  1,  1],\n",
              "        [ 4,  0,  2,  4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgEZOvSZMIl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "12a58067-7cab-4f45-cbf9-93140eb6bf9f"
      },
      "source": [
        "V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5,  3,  2,  5],\n",
              "        [-1,  3,  6,  1],\n",
              "        [ 2,  5,  7, -1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSj4Xs47MIjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "785a749c-f60d-4b80-c1fb-7d356b1c7258"
      },
      "source": [
        "Q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6,  3, -4, -2],\n",
              "        [ 4, -1, -2,  4],\n",
              "        [ 4, -3, -1,  7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss7IYIZFMIgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "eaf5f4e7-e494-4f3a-9830-05577281dd1a"
      },
      "source": [
        "# 08 -- CALCULAR O SCORE:\n",
        "QKT = torch.einsum('ab, cb -> ac', Q, K) # Q @ K.T\n",
        "QKT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[53, 24,  8],\n",
              "        [15, 22, 28],\n",
              "        [ 2, 26, 42]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyFL9sryMIeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b1db8d73-f7af-4e82-b035-25ded812d39e"
      },
      "source": [
        "# 09 -- SOFTMAX:\n",
        "S = torch.nn.Softmax(dim=-1)\n",
        "S(QKT.float())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 2.5437e-13, 2.8625e-20],\n",
              "        [2.2547e-06, 2.4726e-03, 9.9753e-01],\n",
              "        [4.2484e-18, 1.1254e-07, 1.0000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upZSHypsMIbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 10 -- SIMPLIFICAR S - POR SIMPLICIDADE DE ENTENDIMENTO:\n",
        "Softmax  = torch.tensor([\n",
        "                         [1,    0,    0  ], \n",
        "                         [0.01, 0.09, 0.9],\n",
        "                         [0,    0,    1  ],\n",
        "                 ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjbUXARcYveN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9ba6add3-ef29-4014-f011-52fc97444bc8"
      },
      "source": [
        "# 11 -- SOFTMAX * V (EXTRATOR DE FEAT):\n",
        "SV = torch.einsum('ab, bc -> ac', Softmax,V.float())\n",
        "SV "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5.0000,  3.0000,  2.0000,  5.0000],\n",
              "        [ 1.6600,  4.8000,  6.8600, -0.7600],\n",
              "        [ 2.0000,  5.0000,  7.0000, -1.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjxQz4s8Yvbh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f74e69bc-a53d-4abb-d637-2c1794fa58f2"
      },
      "source": [
        "# 12 -- MULTIPLICAR PELA MATRIZ DE PROJEÇÃO Wo\n",
        "\n",
        "# PESOS DA Wo (INICIADOS ARBITRARIAMENTE)\n",
        "Wo = torch.tensor([\n",
        "                   [2,  0, -1,  1], \n",
        "                   [1, -1, -2,  1],\n",
        "                   [2,  0,  1,  0],\n",
        "                   [0, -2,  1, -1],\n",
        "                 ])\n",
        "Wo.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkXnSgXwb29Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "912cadb0-54ee-448c-801b-7c5dc2cff0de"
      },
      "source": [
        "## 13 -- SV @ Wo = MATRIZ DE ATENÇÃO:\n",
        "\n",
        "ATT = torch.einsum('ab, bc -> ac', SV, Wo.float()) # SV @ Wo\n",
        "ATT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -3.0000, -13.0000,   6.0000,  -7.0000],\n",
              "        [ 21.8400,  -3.2800,  -5.1600,   7.2200],\n",
              "        [ 23.0000,  -3.0000,  -6.0000,   8.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5EI8ia0gLJK",
        "colab_type": "text"
      },
      "source": [
        "# Fim do Notebook"
      ]
    }
  ]
}